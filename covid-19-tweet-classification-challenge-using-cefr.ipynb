{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport random\nimport numpy as np\n\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, random_split\nfrom transformers import (\n    AdamW,\n    Trainer,\n    TrainingArguments,\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    get_cosine_schedule_with_warmup,\n)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-31T13:25:41.467227Z","iopub.execute_input":"2022-08-31T13:25:41.468099Z","iopub.status.idle":"2022-08-31T13:25:41.485119Z","shell.execute_reply.started":"2022-08-31T13:25:41.468033Z","shell.execute_reply":"2022-08-31T13:25:41.483421Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"model_name = \"roberta-large\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, ignore_mismatched_sizes=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:41.491601Z","iopub.execute_input":"2022-08-31T13:25:41.495252Z","iopub.status.idle":"2022-08-31T13:25:49.547818Z","shell.execute_reply.started":"2022-08-31T13:25:41.495183Z","shell.execute_reply":"2022-08-31T13:25:49.543558Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"Could not locate the tokenizer configuration file, will try to use the model config instead.\nhttps://huggingface.co/roberta-large/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp71izsqv4\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/482 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbc8672050bd4011b252d13dad7321f8"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/roberta-large/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\ncreating metadata file for /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nhttps://huggingface.co/roberta-large/resolve/main/vocab.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpnk9j4bx2\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f854cb5733e485ea78a4cfae70845e0"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/roberta-large/resolve/main/vocab.json in cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\ncreating metadata file for /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\nhttps://huggingface.co/roberta-large/resolve/main/merges.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpzemt85uq\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d03da16b88494de6a2c4c6a79ac4bf7f"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/roberta-large/resolve/main/merges.txt in cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\ncreating metadata file for /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nhttps://huggingface.co/roberta-large/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmput6qd8dt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea602aeea0514f6bb8c8f6abc96fd32b"}},"metadata":{}},{"name":"stderr","text":"storing https://huggingface.co/roberta-large/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\ncreating metadata file for /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\nloading file https://huggingface.co/roberta-large/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/7c1ba2435b05451bc3b4da073c8dec9630b22024a65f6c41053caccf2880eb8f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\nloading file https://huggingface.co/roberta-large/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/20b5a00a80e27ae9accbe25672aba42ad2d4d4cb2c4b9359b50ca8e34e107d6d.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\nloading file https://huggingface.co/roberta-large/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/e16a2590deb9e6d73711d6e05bf27d832fa8c1162d807222e043ca650a556964.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\nloading file https://huggingface.co/roberta-large/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/roberta-large/resolve/main/special_tokens_map.json from cache at None\nloading file https://huggingface.co/roberta-large/resolve/main/tokenizer_config.json from cache at None\nloading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"lr = 2e-5\nepochs =  6\nbatch_size = 5\nmax_seq_len = 75\n\ntest_frac = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.556550Z","iopub.execute_input":"2022-08-31T13:25:49.558015Z","iopub.status.idle":"2022-08-31T13:25:49.572544Z","shell.execute_reply.started":"2022-08-31T13:25:49.557959Z","shell.execute_reply":"2022-08-31T13:25:49.571064Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef set_seed(seed=106052):\n    \"\"\"Set seed for reproducibility.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.576022Z","iopub.execute_input":"2022-08-31T13:25:49.577921Z","iopub.status.idle":"2022-08-31T13:25:49.596702Z","shell.execute_reply.started":"2022-08-31T13:25:49.577807Z","shell.execute_reply":"2022-08-31T13:25:49.595091Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class CEFRDataset(Dataset):\n    \"\"\"Classification dataset, built on top of pytorch dataset object\n    \"\"\"\n    \n    def __init__(self, texts, labels):\n        \n        self.encoder = LabelEncoder()\n        print(self.encoder.__dict__)\n        self.texts = texts\n        self.labels = self.encoder.fit_transform(labels)\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        label = self.labels[index]\n        encoded_text = tokenizer(\n            text,\n            padding=\"max_length\",\n            max_length=max_seq_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        encoded_text[\"input_ids\"] = encoded_text[\"input_ids\"].squeeze()\n        encoded_text[\"attention_mask\"] = encoded_text[\"attention_mask\"].squeeze()\n        label = torch.tensor(label)\n\n        return {\n            \"input_ids\": encoded_text[\"input_ids\"],\n            \"attention_mask\": encoded_text[\"attention_mask\"],\n            \"labels\": label,\n        }\n\n    def get_labels(self):\n        return self.labels","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.599816Z","iopub.execute_input":"2022-08-31T13:25:49.601425Z","iopub.status.idle":"2022-08-31T13:25:49.614111Z","shell.execute_reply.started":"2022-08-31T13:25:49.601379Z","shell.execute_reply":"2022-08-31T13:25:49.612590Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def train(train_set, valid_set, epochs=10, warmup_size=0.1, lr=1e-3, batch_size=16):\n    model = get_model(model_name)\n    optim = AdamW(model.parameters(), lr=lr)\n    scheduler = get_scheduler(\n        optim, warmup_size, round(len(train_set) / batch_size * epochs)\n    )\n    training_args = get_training_args(epochs, batch_size)\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_set,\n        eval_dataset=valid_set,\n        optimizers=[optim, scheduler],\n        compute_metrics=compute_accuracy\n    )\n    trainer.train()\n    trainer.save_model()\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.616329Z","iopub.execute_input":"2022-08-31T13:25:49.617362Z","iopub.status.idle":"2022-08-31T13:25:49.628608Z","shell.execute_reply.started":"2022-08-31T13:25:49.617319Z","shell.execute_reply":"2022-08-31T13:25:49.626699Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def get_model(pretrained_checkpoint):\n    model = AutoModelForSequenceClassification.from_pretrained(\n        pretrained_checkpoint, num_labels=2, ignore_mismatched_sizes=True\n    )\n    return model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.630301Z","iopub.execute_input":"2022-08-31T13:25:49.631548Z","iopub.status.idle":"2022-08-31T13:25:49.647145Z","shell.execute_reply.started":"2022-08-31T13:25:49.631489Z","shell.execute_reply":"2022-08-31T13:25:49.645335Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"\n\n\ndef get_scheduler(optimizer, warmup_size, total_steps):\n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=round(total_steps * warmup_size),\n        num_training_steps=total_steps,\n    )\n    return scheduler\n\n\ndef get_training_args(epochs, batch_size):\n    return TrainingArguments(\n        output_dir=\"./b\",\n        num_train_epochs=epochs,\n        per_device_train_batch_size=batch_size,\n        logging_steps=50,\n        fp16=False,\n        evaluation_strategy=\"epoch\",\n        eval_accumulation_steps=1,\n        report_to=None,\n#         save_total_limit=1,\n#         load_best_model_at_end=True,\n        save_strategy = 'epoch'\n    )\n\n\ndef compute_accuracy(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.650460Z","iopub.execute_input":"2022-08-31T13:25:49.651714Z","iopub.status.idle":"2022-08-31T13:25:49.663563Z","shell.execute_reply.started":"2022-08-31T13:25:49.651673Z","shell.execute_reply":"2022-08-31T13:25:49.661686Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"lr = 2e-5\nepochs =  8\nbatch_size = 8\nmax_seq_len = 512","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.665709Z","iopub.execute_input":"2022-08-31T13:25:49.667008Z","iopub.status.idle":"2022-08-31T13:25:49.677823Z","shell.execute_reply.started":"2022-08-31T13:25:49.666967Z","shell.execute_reply":"2022-08-31T13:25:49.676317Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def split_valid(df, frac=0.1):\n    \n    val = pd.DataFrame()\n    val[\"text\"] = \"\"\n    val[\"label\"] = -1\n    \n    for i in df.label.unique():\n        val = pd.concat([val, df[df.label == i].sample(frac=frac)])\n        \n    return df[~df.index.isin(val.index)].reset_index(drop=True) , val.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.680412Z","iopub.execute_input":"2022-08-31T13:25:49.681683Z","iopub.status.idle":"2022-08-31T13:25:49.692038Z","shell.execute_reply.started":"2022-08-31T13:25:49.681637Z","shell.execute_reply":"2022-08-31T13:25:49.690495Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"train_set_df = pd.read_csv(\"../input/covid19-tweet-classification-challenge-by-zindi/updated_train.csv\")\ntrain_set_df.drop(\"ID\", axis=1, inplace=True)\ntrain_set_df = train_set_df.reset_index(drop=True)\ntrain_set_df.columns=[\"text\",\"label\"]\ntrain_set_df = train_set_df[train_set_df.label != \"-\"]\ntrain_set_df = train_set_df[[\"text\", \"label\"]]","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.699524Z","iopub.execute_input":"2022-08-31T13:25:49.700027Z","iopub.status.idle":"2022-08-31T13:25:49.728055Z","shell.execute_reply.started":"2022-08-31T13:25:49.699993Z","shell.execute_reply":"2022-08-31T13:25:49.726737Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"train_set_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.729653Z","iopub.execute_input":"2022-08-31T13:25:49.731161Z","iopub.status.idle":"2022-08-31T13:25:49.743866Z","shell.execute_reply.started":"2022-08-31T13:25:49.731117Z","shell.execute_reply":"2022-08-31T13:25:49.742239Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"0    2746\n1    2541\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\ntrain_set_df.text = train_set_df.text.apply(lambda x: x.replace(\"\\r\", \"\").replace(\"\\n\", \" \"))\n\n# extra_df = pd.read_csv(\"../input/frenchcefr/french_mike_june.csv\")\n# extra_df.columns = [\"text\", \"label\", \"label_\"]\n# extra_df = extra_df[[\"text\", \"label\"]]\n# extra_df.text = extra_df.text.astype(str)\n#train_set_df = pd.concat([train_set_df, extra_df]).reset_index(drop=True)\n\ntrain_set_df, valid_set_df = split_valid(train_set_df)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.746808Z","iopub.execute_input":"2022-08-31T13:25:49.747380Z","iopub.status.idle":"2022-08-31T13:25:49.769502Z","shell.execute_reply.started":"2022-08-31T13:25:49.747336Z","shell.execute_reply":"2022-08-31T13:25:49.768247Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"train_set_df.label = le.fit_transform(train_set_df.label)\nvalid_set_df.label = le.transform(valid_set_df.label)","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.771857Z","iopub.execute_input":"2022-08-31T13:25:49.773421Z","iopub.status.idle":"2022-08-31T13:25:49.782231Z","shell.execute_reply.started":"2022-08-31T13:25:49.773373Z","shell.execute_reply":"2022-08-31T13:25:49.780910Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"valid_set_df","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.786441Z","iopub.execute_input":"2022-08-31T13:25:49.787442Z","iopub.status.idle":"2022-08-31T13:25:49.804176Z","shell.execute_reply.started":"2022-08-31T13:25:49.787401Z","shell.execute_reply":"2022-08-31T13:25:49.802258Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"                                                  text  label\n0    All empty during a show at the Max Stadium bef...      1\n1    ki saru 41 donated 2cr to mumbai police in thi...      1\n2    Soft water soft skin Looking for water softene...      1\n3    Hospitals get paid more if patients listed as ...      1\n4    Italian politician Vittorio Sgarbi reports in ...      1\n..                                                 ...    ...\n524  Stephon Marbury says Larry Brown tried to kick...      0\n525  He left it on the table Unfinished All the spo...      0\n526  In these tough times the best way to grow is t...      0\n527  poole Lib Dem Leader Fasts for Holy Ramadan in...      0\n528  Italian Prime Minister Giuseppe Conte gave the...      0\n\n[529 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>All empty during a show at the Max Stadium bef...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ki saru 41 donated 2cr to mumbai police in thi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Soft water soft skin Looking for water softene...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hospitals get paid more if patients listed as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Italian politician Vittorio Sgarbi reports in ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>524</th>\n      <td>Stephon Marbury says Larry Brown tried to kick...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>525</th>\n      <td>He left it on the table Unfinished All the spo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>In these tough times the best way to grow is t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>527</th>\n      <td>poole Lib Dem Leader Fasts for Holy Ramadan in...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>528</th>\n      <td>Italian Prime Minister Giuseppe Conte gave the...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>529 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm \n\ndef predict(model, text):\n    \n    preds = []\n    \n    for i in tqdm(range(len(text))):\n        tokenized = tokenizer(text[i:i+1], return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n        pred = model(**tokenized)\n        preds.append(pred.logits.argmax(-1).item())\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.808540Z","iopub.execute_input":"2022-08-31T13:25:49.810135Z","iopub.status.idle":"2022-08-31T13:25:49.819707Z","shell.execute_reply.started":"2022-08-31T13:25:49.810094Z","shell.execute_reply":"2022-08-31T13:25:49.818222Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"train_set = CEFRDataset(train_set_df[\"text\"], train_set_df[\"label\"])\nvalid_set = CEFRDataset(valid_set_df[\"text\"], valid_set_df[\"label\"])\n\n\ntrainer_second = train(train_set, valid_set, epochs=epochs, warmup_size=0.2, lr=lr, batch_size=batch_size)\nmodel = trainer_second.model","metadata":{"execution":{"iopub.status.busy":"2022-08-31T13:25:49.822396Z","iopub.execute_input":"2022-08-31T13:25:49.823246Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"{}\n{}\n","output_type":"stream"},{"name":"stderr","text":"loading configuration file https://huggingface.co/roberta-large/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/dea67b44b38d504f2523f3ddb6acb601b23d67bee52c942da336fa1283100990.94cae8b3a8dbab1d59b9d4827f7ce79e73124efa6bb970412cd503383a95f373\nModel config RobertaConfig {\n  \"_name_or_path\": \"roberta-large\",\n  \"architectures\": [\n    \"RobertaForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"bos_token_id\": 0,\n  \"classifier_dropout\": null,\n  \"eos_token_id\": 2,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 1024,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 4096,\n  \"layer_norm_eps\": 1e-05,\n  \"max_position_embeddings\": 514,\n  \"model_type\": \"roberta\",\n  \"num_attention_heads\": 16,\n  \"num_hidden_layers\": 24,\n  \"pad_token_id\": 1,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 1,\n  \"use_cache\": true,\n  \"vocab_size\": 50265\n}\n\nhttps://huggingface.co/roberta-large/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpt5t6l385\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6056d51938045689c0d9dfb588b84c7"}},"metadata":{}}]},{"cell_type":"code","source":"class CEFRDatasettest(Dataset):\n    \"\"\"Classification dataset, built on top of pytorch dataset object\n    \"\"\"\n    \n    def __init__(self, texts):\n        \n        self.encoder = LabelEncoder()\n        print(self.encoder.__dict__)\n        self.texts = texts\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        encoded_text = tokenizer(\n            text,\n            padding=\"max_length\",\n            max_length=max_seq_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        encoded_text[\"input_ids\"] = encoded_text[\"input_ids\"].squeeze()\n        encoded_text[\"attention_mask\"] = encoded_text[\"attention_mask\"].squeeze()\n\n        return {\n            \"input_ids\": encoded_text[\"input_ids\"],\n            \"attention_mask\": encoded_text[\"attention_mask\"],\n        }\n\n    def get_labels(self):\n        return self.labels","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-tweet-classification-challenge-by-zindi/updated_test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=predict(model, test.text.to_list())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub=pd.read_csv(\"../input/covid19-tweet-classification-challenge-by-zindi/updated_ss.csv\")\nsub.target=preds\nsub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\ndef create_submission(submission_file, submission_name):\n    submission_file.to_csv(submission_name+\".csv\",index=False)\n    return FileLink(submission_name+\".csv\")\ncreate_submission(sub, \"submission\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}}]}