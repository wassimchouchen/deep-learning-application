{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport random\nimport numpy as np\n\nimport pandas as pd\nimport torch\nfrom torch.utils.data import Dataset, random_split\nfrom transformers import (\n    AdamW,\n    Trainer,\n    TrainingArguments,\n    AutoTokenizer,\n    AutoModelForSequenceClassification,\n    get_cosine_schedule_with_warmup,\n)\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-29T10:31:31.525070Z","iopub.execute_input":"2022-08-29T10:31:31.525636Z","iopub.status.idle":"2022-08-29T10:31:31.534747Z","shell.execute_reply.started":"2022-08-29T10:31:31.525591Z","shell.execute_reply":"2022-08-29T10:31:31.533411Z"},"trusted":true},"execution_count":168,"outputs":[]},{"cell_type":"code","source":"model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name, ignore_mismatched_sizes=True)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:31.540814Z","iopub.execute_input":"2022-08-29T10:31:31.541253Z","iopub.status.idle":"2022-08-29T10:31:35.144011Z","shell.execute_reply.started":"2022-08-29T10:31:31.541216Z","shell.execute_reply":"2022-08-29T10:31:35.143032Z"},"trusted":true},"execution_count":169,"outputs":[{"name":"stderr","text":"loading configuration file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d9226eeac7b8b96d83ebc327cdd670490866d8c999505c1f83b6ef206ccb1604.a34960b447312b0727cb670d710444fcb41a6156eddcba062a19b3fc05d95251\nModel config BertConfig {\n  \"_name_or_path\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n  \"_num_labels\": 5,\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"finetuning_task\": \"sentiment-analysis\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"1 star\",\n    \"1\": \"2 stars\",\n    \"2\": \"3 stars\",\n    \"3\": \"4 stars\",\n    \"4\": \"5 stars\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"1 star\": 0,\n    \"2 stars\": 1,\n    \"3 stars\": 2,\n    \"4 stars\": 3,\n    \"5 stars\": 4\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 105879\n}\n\nloading file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/d893db6e58fdc9c39ecb49aaba0fc940780c179e1fff5bfe27e322e1599c191f.92022aa29ab6663b0b4254744f28ab43e6adf4deebe0f26651e6c61f28f69d8b\nloading file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/tokenizer.json from cache at None\nloading file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/added_tokens.json from cache at None\nloading file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/special_tokens_map.json from cache at /root/.cache/huggingface/transformers/ed85e7bfaa7dfcf9924004400478a6426fcab28d3e427960549371a1729115d1.dd8bd9bfd3664b530ea4e645105f557769387b3da9f79bdb55ed556bdd80611d\nloading file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/4d1409805ace1b4cc209352f82a0f0c59a015433d0a58e655394ffe7bbb755e9.13a045cad07359e6844c4f487af8e6323ad2308cac6357692d2359f1a9711443\nloading configuration file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d9226eeac7b8b96d83ebc327cdd670490866d8c999505c1f83b6ef206ccb1604.a34960b447312b0727cb670d710444fcb41a6156eddcba062a19b3fc05d95251\nModel config BertConfig {\n  \"_name_or_path\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n  \"_num_labels\": 5,\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"finetuning_task\": \"sentiment-analysis\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"1 star\",\n    \"1\": \"2 stars\",\n    \"2\": \"3 stars\",\n    \"3\": \"4 stars\",\n    \"4\": \"5 stars\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"1 star\": 0,\n    \"2 stars\": 1,\n    \"3 stars\": 2,\n    \"4 stars\": 3,\n    \"5 stars\": 4\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 105879\n}\n\nloading configuration file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d9226eeac7b8b96d83ebc327cdd670490866d8c999505c1f83b6ef206ccb1604.a34960b447312b0727cb670d710444fcb41a6156eddcba062a19b3fc05d95251\nModel config BertConfig {\n  \"_name_or_path\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n  \"_num_labels\": 5,\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"finetuning_task\": \"sentiment-analysis\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"id2label\": {\n    \"0\": \"1 star\",\n    \"1\": \"2 stars\",\n    \"2\": \"3 stars\",\n    \"3\": \"4 stars\",\n    \"4\": \"5 stars\"\n  },\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"label2id\": {\n    \"1 star\": 0,\n    \"2 stars\": 1,\n    \"3 stars\": 2,\n    \"4 stars\": 3,\n    \"5 stars\": 4\n  },\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 105879\n}\n\n","output_type":"stream"}]},{"cell_type":"code","source":"lr = 2e-5\nepochs =  6\nbatch_size = 5\nmax_seq_len = 75\n\ntest_frac = 0.1","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.146252Z","iopub.execute_input":"2022-08-29T10:31:35.146633Z","iopub.status.idle":"2022-08-29T10:31:35.154035Z","shell.execute_reply.started":"2022-08-29T10:31:35.146596Z","shell.execute_reply":"2022-08-29T10:31:35.152971Z"},"trusted":true},"execution_count":170,"outputs":[]},{"cell_type":"code","source":"import os\n\ndef set_seed(seed=106052):\n    \"\"\"Set seed for reproducibility.\n    \"\"\"\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    \n    os.environ['PYTHONHASHSEED'] = str(seed)\n    \nset_seed()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.155561Z","iopub.execute_input":"2022-08-29T10:31:35.156179Z","iopub.status.idle":"2022-08-29T10:31:35.163808Z","shell.execute_reply.started":"2022-08-29T10:31:35.156139Z","shell.execute_reply":"2022-08-29T10:31:35.162890Z"},"trusted":true},"execution_count":171,"outputs":[]},{"cell_type":"code","source":"class CEFRDataset(Dataset):\n    \"\"\"Classification dataset, built on top of pytorch dataset object\n    \"\"\"\n    \n    def __init__(self, texts, labels):\n        \n        self.encoder = LabelEncoder()\n        print(self.encoder.__dict__)\n        self.texts = texts\n        self.labels = self.encoder.fit_transform(labels)\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        label = self.labels[index]\n        encoded_text = tokenizer(\n            text,\n            padding=\"max_length\",\n            max_length=max_seq_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        encoded_text[\"input_ids\"] = encoded_text[\"input_ids\"].squeeze()\n        encoded_text[\"attention_mask\"] = encoded_text[\"attention_mask\"].squeeze()\n        label = torch.tensor(label)\n\n        return {\n            \"input_ids\": encoded_text[\"input_ids\"],\n            \"attention_mask\": encoded_text[\"attention_mask\"],\n            \"labels\": label,\n        }\n\n    def get_labels(self):\n        return self.labels","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.166932Z","iopub.execute_input":"2022-08-29T10:31:35.167307Z","iopub.status.idle":"2022-08-29T10:31:35.177162Z","shell.execute_reply.started":"2022-08-29T10:31:35.167281Z","shell.execute_reply":"2022-08-29T10:31:35.176247Z"},"trusted":true},"execution_count":172,"outputs":[]},{"cell_type":"code","source":"def train(train_set, valid_set, epochs=10, warmup_size=0.1, lr=1e-3, batch_size=16):\n    model = get_model(model_name)\n    optim = AdamW(model.parameters(), lr=lr)\n    scheduler = get_scheduler(\n        optim, warmup_size, round(len(train_set) / batch_size * epochs)\n    )\n    training_args = get_training_args(epochs, batch_size)\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_set,\n        eval_dataset=valid_set,\n        optimizers=[optim, scheduler],\n        compute_metrics=compute_accuracy\n    )\n    trainer.train()\n    trainer.save_model()\n    return trainer","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.178547Z","iopub.execute_input":"2022-08-29T10:31:35.179647Z","iopub.status.idle":"2022-08-29T10:31:35.191665Z","shell.execute_reply.started":"2022-08-29T10:31:35.179612Z","shell.execute_reply":"2022-08-29T10:31:35.190645Z"},"trusted":true},"execution_count":173,"outputs":[]},{"cell_type":"code","source":"def get_model(pretrained_checkpoint):\n    model = AutoModelForSequenceClassification.from_pretrained(\n        pretrained_checkpoint, num_labels=2, ignore_mismatched_sizes=True\n    )\n    return model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.193378Z","iopub.execute_input":"2022-08-29T10:31:35.194187Z","iopub.status.idle":"2022-08-29T10:31:35.202663Z","shell.execute_reply.started":"2022-08-29T10:31:35.194144Z","shell.execute_reply":"2022-08-29T10:31:35.201741Z"},"trusted":true},"execution_count":174,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"\n\n\ndef get_scheduler(optimizer, warmup_size, total_steps):\n    scheduler = get_cosine_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=round(total_steps * warmup_size),\n        num_training_steps=total_steps,\n    )\n    return scheduler\n\n\ndef get_training_args(epochs, batch_size):\n    return TrainingArguments(\n        output_dir=\"./b\",\n        num_train_epochs=epochs,\n        per_device_train_batch_size=batch_size,\n        logging_steps=50,\n        fp16=False,\n        evaluation_strategy=\"epoch\",\n        eval_accumulation_steps=1,\n        report_to=None,\n#         save_total_limit=1,\n#         load_best_model_at_end=True,\n        save_strategy = 'epoch'\n    )\n\n\ndef compute_accuracy(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    acc = accuracy_score(labels, preds)\n    return {\"accuracy\": acc}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.204336Z","iopub.execute_input":"2022-08-29T10:31:35.205046Z","iopub.status.idle":"2022-08-29T10:31:35.214905Z","shell.execute_reply.started":"2022-08-29T10:31:35.205009Z","shell.execute_reply":"2022-08-29T10:31:35.213952Z"},"trusted":true},"execution_count":175,"outputs":[]},{"cell_type":"code","source":"lr = 2e-5\nepochs =  4\nbatch_size = 8\nmax_seq_len = 512","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.216400Z","iopub.execute_input":"2022-08-29T10:31:35.217214Z","iopub.status.idle":"2022-08-29T10:31:35.227456Z","shell.execute_reply.started":"2022-08-29T10:31:35.217099Z","shell.execute_reply":"2022-08-29T10:31:35.226509Z"},"trusted":true},"execution_count":176,"outputs":[]},{"cell_type":"code","source":"def split_valid(df, frac=0.1):\n    \n    val = pd.DataFrame()\n    val[\"text\"] = \"\"\n    val[\"label\"] = -1\n    \n    for i in df.label.unique():\n        val = pd.concat([val, df[df.label == i].sample(frac=frac)])\n        \n    return df[~df.index.isin(val.index)].reset_index(drop=True) , val.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.229143Z","iopub.execute_input":"2022-08-29T10:31:35.229900Z","iopub.status.idle":"2022-08-29T10:31:35.237734Z","shell.execute_reply.started":"2022-08-29T10:31:35.229864Z","shell.execute_reply":"2022-08-29T10:31:35.236745Z"},"trusted":true},"execution_count":177,"outputs":[]},{"cell_type":"code","source":"train_set_df = pd.read_csv(\"../input/covid19-tweet-classification-challenge-by-zindi/updated_train.csv\")\ntrain_set_df.drop(\"ID\", axis=1, inplace=True)\ntrain_set_df = train_set_df.reset_index(drop=True)\ntrain_set_df.columns=[\"text\",\"label\"]\ntrain_set_df = train_set_df[train_set_df.label != \"-\"]\ntrain_set_df = train_set_df[[\"text\", \"label\"]]","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.241966Z","iopub.execute_input":"2022-08-29T10:31:35.242227Z","iopub.status.idle":"2022-08-29T10:31:35.263744Z","shell.execute_reply.started":"2022-08-29T10:31:35.242203Z","shell.execute_reply":"2022-08-29T10:31:35.262926Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"train_set_df.label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.264971Z","iopub.execute_input":"2022-08-29T10:31:35.265877Z","iopub.status.idle":"2022-08-29T10:31:35.274733Z","shell.execute_reply.started":"2022-08-29T10:31:35.265841Z","shell.execute_reply":"2022-08-29T10:31:35.273743Z"},"trusted":true},"execution_count":179,"outputs":[{"execution_count":179,"output_type":"execute_result","data":{"text/plain":"0    2746\n1    2541\nName: label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\n\ntrain_set_df.text = train_set_df.text.apply(lambda x: x.replace(\"\\r\", \"\").replace(\"\\n\", \" \"))\n\n# extra_df = pd.read_csv(\"../input/frenchcefr/french_mike_june.csv\")\n# extra_df.columns = [\"text\", \"label\", \"label_\"]\n# extra_df = extra_df[[\"text\", \"label\"]]\n# extra_df.text = extra_df.text.astype(str)\n#train_set_df = pd.concat([train_set_df, extra_df]).reset_index(drop=True)\n\ntrain_set_df, valid_set_df = split_valid(train_set_df)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.276087Z","iopub.execute_input":"2022-08-29T10:31:35.277208Z","iopub.status.idle":"2022-08-29T10:31:35.292599Z","shell.execute_reply.started":"2022-08-29T10:31:35.277172Z","shell.execute_reply":"2022-08-29T10:31:35.291538Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"train_set_df.label = le.fit_transform(train_set_df.label)\nvalid_set_df.label = le.transform(valid_set_df.label)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.294090Z","iopub.execute_input":"2022-08-29T10:31:35.294577Z","iopub.status.idle":"2022-08-29T10:31:35.300774Z","shell.execute_reply.started":"2022-08-29T10:31:35.294539Z","shell.execute_reply":"2022-08-29T10:31:35.299788Z"},"trusted":true},"execution_count":181,"outputs":[]},{"cell_type":"code","source":"valid_set_df","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.302110Z","iopub.execute_input":"2022-08-29T10:31:35.303113Z","iopub.status.idle":"2022-08-29T10:31:35.317032Z","shell.execute_reply.started":"2022-08-29T10:31:35.303076Z","shell.execute_reply":"2022-08-29T10:31:35.315940Z"},"trusted":true},"execution_count":182,"outputs":[{"execution_count":182,"output_type":"execute_result","data":{"text/plain":"                                                  text  label\n0    All empty during a show at the Max Stadium bef...      1\n1    ki saru 41 donated 2cr to mumbai police in thi...      1\n2    Soft water soft skin Looking for water softene...      1\n3    Hospitals get paid more if patients listed as ...      1\n4    Italian politician Vittorio Sgarbi reports in ...      1\n..                                                 ...    ...\n524  Stephon Marbury says Larry Brown tried to kick...      0\n525  He left it on the table Unfinished All the spo...      0\n526  In these tough times the best way to grow is t...      0\n527  poole Lib Dem Leader Fasts for Holy Ramadan in...      0\n528  Italian Prime Minister Giuseppe Conte gave the...      0\n\n[529 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>All empty during a show at the Max Stadium bef...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ki saru 41 donated 2cr to mumbai police in thi...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Soft water soft skin Looking for water softene...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hospitals get paid more if patients listed as ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Italian politician Vittorio Sgarbi reports in ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>524</th>\n      <td>Stephon Marbury says Larry Brown tried to kick...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>525</th>\n      <td>He left it on the table Unfinished All the spo...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>526</th>\n      <td>In these tough times the best way to grow is t...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>527</th>\n      <td>poole Lib Dem Leader Fasts for Holy Ramadan in...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>528</th>\n      <td>Italian Prime Minister Giuseppe Conte gave the...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>529 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from tqdm import tqdm \n\ndef predict(model, text):\n    \n    preds = []\n    \n    for i in tqdm(range(len(text))):\n        tokenized = tokenizer(text[i:i+1], return_tensors=\"pt\", truncation=True, max_length=512).to(\"cuda\")\n        pred = model(**tokenized)\n        preds.append(pred.logits.argmax(-1).item())\n\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.318659Z","iopub.execute_input":"2022-08-29T10:31:35.319166Z","iopub.status.idle":"2022-08-29T10:31:35.326927Z","shell.execute_reply.started":"2022-08-29T10:31:35.319129Z","shell.execute_reply":"2022-08-29T10:31:35.325884Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"code","source":"train_set = CEFRDataset(train_set_df[\"text\"], train_set_df[\"label\"])\nvalid_set = CEFRDataset(valid_set_df[\"text\"], valid_set_df[\"label\"])\n\n\ntrainer_second = train(train_set, valid_set, epochs=epochs, warmup_size=0.2, lr=lr, batch_size=batch_size)\nmodel = trainer_second.model","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:31:35.328375Z","iopub.execute_input":"2022-08-29T10:31:35.328829Z","iopub.status.idle":"2022-08-29T10:39:19.449196Z","shell.execute_reply.started":"2022-08-29T10:31:35.328793Z","shell.execute_reply":"2022-08-29T10:39:19.447048Z"},"trusted":true},"execution_count":184,"outputs":[{"name":"stdout","text":"{}\n{}\n","output_type":"stream"},{"name":"stderr","text":"loading configuration file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/d9226eeac7b8b96d83ebc327cdd670490866d8c999505c1f83b6ef206ccb1604.a34960b447312b0727cb670d710444fcb41a6156eddcba062a19b3fc05d95251\nModel config BertConfig {\n  \"_name_or_path\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n  \"_num_labels\": 5,\n  \"architectures\": [\n    \"BertForSequenceClassification\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"directionality\": \"bidi\",\n  \"finetuning_task\": \"sentiment-analysis\",\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_past\": true,\n  \"pad_token_id\": 0,\n  \"pooler_fc_size\": 768,\n  \"pooler_num_attention_heads\": 12,\n  \"pooler_num_fc_layers\": 3,\n  \"pooler_size_per_head\": 128,\n  \"pooler_type\": \"first_token_transform\",\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.20.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 105879\n}\n\nloading weights file https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/c3020f16ae496cb8ba53cdb83e08cca88c008e5c4263884ecdc4a8a6000e8751.2da3f39deb1fb7ac0e8bd6c41b5ded28013a75c0d779d283a57e6b0fe34d4091\nAll model checkpoint weights were used when initializing BertForSequenceClassification.\n\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at nlptown/bert-base-multilingual-uncased-sentiment and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([5, 768]) in the checkpoint and torch.Size([2, 768]) in the model instantiated\n- classifier.bias: found shape torch.Size([5]) in the checkpoint and torch.Size([2]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nUsing the `WAND_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n***** Running training *****\n  Num examples = 4758\n  Num Epochs = 4\n  Instantaneous batch size per device = 8\n  Total train batch size (w. parallel, distributed & accumulation) = 8\n  Gradient Accumulation steps = 1\n  Total optimization steps = 2380\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='981' max='2380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 981/2380 07:40 < 10:57, 2.13 it/s, Epoch 1.65/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.286900</td>\n      <td>0.302374</td>\n      <td>0.890359</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"***** Running Evaluation *****\n  Num examples = 529\n  Batch size = 8\nSaving model checkpoint to ./b/checkpoint-595\nConfiguration saved in ./b/checkpoint-595/config.json\nModel weights saved in ./b/checkpoint-595/pytorch_model.bin\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_17/3888882614.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainer_second\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer_second\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_17/3849566149.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_set, valid_set, epochs, warmup_size, lr, batch_size)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     )\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1411\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1413\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1414\u001b[0m         )\n\u001b[1;32m   1415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1649\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1651\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1653\u001b[0m                 if (\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# valid_set_df[\"preds\"] = train_set.encoder(predict(model, valid_set_df.text.tolist()))\n# valid_set_df.columns = [\"text\", \"cefr\", \"preds\",] ","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:39:19.450504Z","iopub.status.idle":"2022-08-29T10:39:19.451027Z","shell.execute_reply.started":"2022-08-29T10:39:19.450750Z","shell.execute_reply":"2022-08-29T10:39:19.450775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CEFRDatasettest(Dataset):\n    \"\"\"Classification dataset, built on top of pytorch dataset object\n    \"\"\"\n    \n    def __init__(self, texts):\n        \n        self.encoder = LabelEncoder()\n        print(self.encoder.__dict__)\n        self.texts = texts\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, index):\n        text = self.texts[index]\n        encoded_text = tokenizer(\n            text,\n            padding=\"max_length\",\n            max_length=max_seq_len,\n            truncation=True,\n            return_tensors=\"pt\",\n        )\n        encoded_text[\"input_ids\"] = encoded_text[\"input_ids\"].squeeze()\n        encoded_text[\"attention_mask\"] = encoded_text[\"attention_mask\"].squeeze()\n\n        return {\n            \"input_ids\": encoded_text[\"input_ids\"],\n            \"attention_mask\": encoded_text[\"attention_mask\"],\n        }\n\n    def get_labels(self):\n        return self.labels","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-08-29T10:39:19.452380Z","iopub.status.idle":"2022-08-29T10:39:19.452794Z","shell.execute_reply.started":"2022-08-29T10:39:19.452609Z","shell.execute_reply":"2022-08-29T10:39:19.452629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-tweet-classification-challenge-by-zindi/updated_test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:39:19.454515Z","iopub.status.idle":"2022-08-29T10:39:19.456056Z","shell.execute_reply.started":"2022-08-29T10:39:19.455801Z","shell.execute_reply":"2022-08-29T10:39:19.455827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=predict(model, test.text.to_list())","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:39:19.457523Z","iopub.status.idle":"2022-08-29T10:39:19.458368Z","shell.execute_reply.started":"2022-08-29T10:39:19.458099Z","shell.execute_reply":"2022-08-29T10:39:19.458124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub=pd.read_csv(\"../input/covid19-tweet-classification-challenge-by-zindi/updated_ss.csv\")\nsub.target=preds\nsub","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:39:19.459823Z","iopub.status.idle":"2022-08-29T10:39:19.460600Z","shell.execute_reply.started":"2022-08-29T10:39:19.460327Z","shell.execute_reply":"2022-08-29T10:39:19.460363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\ndef create_submission(submission_file, submission_name):\n    submission_file.to_csv(submission_name+\".csv\",index=False)\n    return FileLink(submission_name+\".csv\")\ncreate_submission(sub, \"submission\")","metadata":{"execution":{"iopub.status.busy":"2022-08-29T10:39:19.462017Z","iopub.status.idle":"2022-08-29T10:39:19.462820Z","shell.execute_reply.started":"2022-08-29T10:39:19.462544Z","shell.execute_reply":"2022-08-29T10:39:19.462569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}}]}