{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:10.138648Z","iopub.status.busy":"2020-11-26T10:25:10.137837Z","iopub.status.idle":"2020-11-26T10:25:10.140895Z","shell.execute_reply":"2020-11-26T10:25:10.140371Z"},"id":"To9ENLU90WGl","outputId":"14dd2472-1164-451a-f8df-0552b5ed8f74","papermill":{"duration":0.019719,"end_time":"2020-11-26T10:25:10.141002","exception":false,"start_time":"2020-11-26T10:25:10.121283","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import accuracy_score\n\nimport torch\nimport transformers as ppb\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:10.173448Z","iopub.status.busy":"2020-11-26T10:25:10.172699Z","iopub.status.idle":"2020-11-26T10:25:19.666291Z","shell.execute_reply":"2020-11-26T10:25:19.665666Z"},"id":"fvFvBLJV0Dkv","papermill":{"duration":9.512248,"end_time":"2020-11-26T10:25:19.666418","exception":false,"start_time":"2020-11-26T10:25:10.15417","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Download data <a class=\"anchor\" id=\"2\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.013355,"end_time":"2020-11-26T10:25:19.694002","exception":false,"start_time":"2020-11-26T10:25:19.680647","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df = pd.read_csv('../input/nlp-reports-news-classification/water_problem_nlp_ua_for_Kaggle_100.csv', delimiter=';', \n                 header=0, encoding='cp1251')\ndf = df.fillna(0)\n\nconvert_dict = {'text': str, \n                'env_problems': int,\n                'pollution': int, \n                'treatment': int,\n                'climate': int,\n                'biomonitoring': int} \n  \ndf = df.astype(convert_dict)\ndf","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:19.729053Z","iopub.status.busy":"2020-11-26T10:25:19.728142Z","iopub.status.idle":"2020-11-26T10:25:19.760147Z","shell.execute_reply":"2020-11-26T10:25:19.760636Z"},"id":"cyoj29J24hPX","papermill":{"duration":0.053039,"end_time":"2020-11-26T10:25:19.760763","exception":false,"start_time":"2020-11-26T10:25:19.707724","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:19.805211Z","iopub.status.busy":"2020-11-26T10:25:19.804425Z","iopub.status.idle":"2020-11-26T10:25:19.814152Z","shell.execute_reply":"2020-11-26T10:25:19.814575Z"},"papermill":{"duration":0.038293,"end_time":"2020-11-26T10:25:19.8147","exception":false,"start_time":"2020-11-26T10:25:19.776407","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. BERT: Data Prepairing and Modeling <a class=\"anchor\" id=\"3\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"papermill":{"duration":0.017716,"end_time":"2020-11-26T10:25:19.850433","exception":false,"start_time":"2020-11-26T10:25:19.832717","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# For pre-trained DistilBERT:\nmodel_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-multilingual-cased')\n\n# Other models: https://huggingface.co/transformers/pretrained_models.html\n\n# Load pretrained model/tokenizer\ntokenizer = tokenizer_class.from_pretrained(pretrained_weights)\nmodel = model_class.from_pretrained(pretrained_weights)","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:19.889029Z","iopub.status.busy":"2020-11-26T10:25:19.888133Z","iopub.status.idle":"2020-11-26T10:25:29.517055Z","shell.execute_reply":"2020-11-26T10:25:29.516459Z"},"id":"q1InADgf5xm2","outputId":"617463db-c0e5-4108-cdbb-54ad428e5b54","papermill":{"duration":9.648298,"end_time":"2020-11-26T10:25:29.51717","exception":false,"start_time":"2020-11-26T10:25:19.868872","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tokenization the sentences - break them up into word and subwords in the format BERT is comfortable with\ntokenized = df['text'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n\nmax_len = 0\nfor i in tokenized.values:\n    if len(i) > max_len:\n        max_len = len(i)\n\npadded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\nnp.array(padded).shape","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:29.591433Z","iopub.status.busy":"2020-11-26T10:25:29.581254Z","iopub.status.idle":"2020-11-26T10:25:29.68357Z","shell.execute_reply":"2020-11-26T10:25:29.684075Z"},"id":"Dg82ndBA5xlN","papermill":{"duration":0.148918,"end_time":"2020-11-26T10:25:29.684209","exception":false,"start_time":"2020-11-26T10:25:29.535291","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creation variable to ignore (mask) the data padding\nattention_mask = np.where(padded != 0, 1, 0)\nprint(attention_mask.shape)\nattention_mask","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:29.726957Z","iopub.status.busy":"2020-11-26T10:25:29.72596Z","iopub.status.idle":"2020-11-26T10:25:29.731963Z","shell.execute_reply":"2020-11-26T10:25:29.731482Z"},"id":"4K_iGRNa_Ozc","outputId":"8ae6d28e-055b-4bcd-8129-87ba07251e3e","papermill":{"duration":0.029521,"end_time":"2020-11-26T10:25:29.732066","exception":false,"start_time":"2020-11-26T10:25:29.702545","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeling\ninput_ids = torch.tensor(padded).to(torch.int64)\nattention_mask = torch.tensor(attention_mask).to(torch.int64)\n\nwith torch.no_grad():\n    last_hidden_states = model(input_ids, attention_mask=attention_mask)","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:29.775822Z","iopub.status.busy":"2020-11-26T10:25:29.775113Z","iopub.status.idle":"2020-11-26T10:25:36.59138Z","shell.execute_reply":"2020-11-26T10:25:36.590723Z"},"id":"39UVjAV56PJz","papermill":{"duration":6.84034,"end_time":"2020-11-26T10:25:36.591492","exception":false,"start_time":"2020-11-26T10:25:29.751152","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Last hidden states\nfeatures = last_hidden_states[0][:,0,:].numpy()","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:36.634228Z","iopub.status.busy":"2020-11-26T10:25:36.633572Z","iopub.status.idle":"2020-11-26T10:25:36.637547Z","shell.execute_reply":"2020-11-26T10:25:36.637081Z"},"id":"C9t60At16PVs","papermill":{"duration":0.0269,"end_time":"2020-11-26T10:25:36.637655","exception":false,"start_time":"2020-11-26T10:25:36.610755","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Text Classification and Prediction <a class=\"anchor\" id=\"4\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{"id":"iaoEvM2evRx1","papermill":{"duration":0.018744,"end_time":"2020-11-26T10:25:36.675734","exception":false,"start_time":"2020-11-26T10:25:36.65699","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def target_prediction(df, features, target, test_size=0.2):\n    # Text classification model and prediction for given feature \"target\" (with labels) in df\n    \n    # Target\n    labels = df[target]\n    \n    # EDA\n    print()\n    # Extracting the number of examples of each class\n    Relevant_len = df[df[target] == 1].shape[0]\n    Not_len = df[df[target] == 0].shape[0]\n    # Draw bar plot\n    plt.rcParams['figure.figsize'] = (7, 5)\n    plt.bar(10, Relevant_len, 3, label=\"Relevant\", color='green')\n    plt.bar(15, Not_len, 3, label=\"Not\", color='red')\n    plt.legend(loc='upper center')\n    plt.ylabel('Number of examples')\n    plt.title('Propertion of examples for ' + target)\n    plt.show()\n    \n    # Train, test split \n    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=test_size)\n    \n    # Train a simple model\n    print(f'Classification for {col}:')\n    parameters = {'C': np.linspace(0.0001, 100, 20)}\n    model = GridSearchCV(LogisticRegression(), parameters)\n    model.fit(train_features, train_labels)\n\n    print('best parameters: ', model.best_params_)\n    print('best scores: ', model.best_score_)\n    \n    # Test prediction\n    test_pred = model.predict(test_features)\n    print('Score of the test prediction -', accuracy_score(test_labels, test_pred),'\\n\\n')","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:36.726216Z","iopub.status.busy":"2020-11-26T10:25:36.725449Z","iopub.status.idle":"2020-11-26T10:25:36.729449Z","shell.execute_reply":"2020-11-26T10:25:36.728975Z"},"papermill":{"duration":0.034856,"end_time":"2020-11-26T10:25:36.729549","exception":false,"start_time":"2020-11-26T10:25:36.694693","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List of the target features in df\ncols = df.columns.tolist()[1:]\nprint('Target columns:', cols)","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:36.773312Z","iopub.status.busy":"2020-11-26T10:25:36.772468Z","iopub.status.idle":"2020-11-26T10:25:36.775821Z","shell.execute_reply":"2020-11-26T10:25:36.776766Z"},"papermill":{"duration":0.028111,"end_time":"2020-11-26T10:25:36.776926","exception":false,"start_time":"2020-11-26T10:25:36.748815","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Solving NLP Classification tasks\nprint('Solving NLP Classification tasks')\nfor col in cols:\n    target_prediction(df, features, col, test_size=0.4)","metadata":{"execution":{"iopub.execute_input":"2020-11-26T10:25:36.821016Z","iopub.status.busy":"2020-11-26T10:25:36.820399Z","iopub.status.idle":"2020-11-26T10:25:51.410916Z","shell.execute_reply":"2020-11-26T10:25:51.410372Z"},"papermill":{"duration":14.614665,"end_time":"2020-11-26T10:25:51.411041","exception":false,"start_time":"2020-11-26T10:25:36.796376","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I hope you find this kernel useful and enjoyable.","metadata":{"papermill":{"duration":0.027293,"end_time":"2020-11-26T10:25:51.466851","exception":false,"start_time":"2020-11-26T10:25:51.439558","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Your comments and feedback are most welcome.","metadata":{"papermill":{"duration":0.027062,"end_time":"2020-11-26T10:25:51.52109","exception":false,"start_time":"2020-11-26T10:25:51.494028","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"[Go to Top](#0)","metadata":{"papermill":{"duration":0.026839,"end_time":"2020-11-26T10:25:51.575363","exception":false,"start_time":"2020-11-26T10:25:51.548524","status":"completed"},"tags":[]}}]}