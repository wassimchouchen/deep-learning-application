{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"},"papermill":{"default_parameters":{},"duration":32.950154,"end_time":"2023-01-24T21:58:58.644056","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-01-24T21:58:25.693902","version":"2.3.4"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -U sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:58:43.718677Z","iopub.execute_input":"2023-01-26T19:58:43.719555Z","iopub.status.idle":"2023-01-26T19:59:00.356399Z","shell.execute_reply.started":"2023-01-26T19:58:43.719514Z","shell.execute_reply":"2023-01-26T19:59:00.354697Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting sentence-transformers\n  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m903.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.20.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (4.64.0)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.11.0+cpu)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.12.0+cpu)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.21.6)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.0.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (1.7.3)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (3.8.1)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.1.97)\nRequirement already satisfied: huggingface-hub>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from sentence-transformers) (0.10.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.1.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.7.1)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.28.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (8.1.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk->sentence-transformers) (1.0.1)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->sentence-transformers) (9.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.14)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3)\nBuilding wheels for collected packages: sentence-transformers\n  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125938 sha256=aee675a78cffeda555624443124d7ebe120f287bc518e0cff94c72cda2f8eef2\n  Stored in directory: /root/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\nSuccessfully built sentence-transformers\nInstalling collected packages: sentence-transformers\nSuccessfully installed sentence-transformers-2.2.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import style\nstyle.use(\"ggplot\")\nfrom sklearn.decomposition import PCA\nfrom mpl_toolkits.mplot3d import Axes3D\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\nfrom nltk.stem import WordNetLemmatizer \nnltk.download('wordnet')\nfrom sentence_transformers import SentenceTransformer\nfrom sklearn.cluster import AgglomerativeClustering","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:59:00.358950Z","iopub.execute_input":"2023-01-26T19:59:00.359956Z","iopub.status.idle":"2023-01-26T19:59:03.153247Z","shell.execute_reply.started":"2023-01-26T19:59:00.359911Z","shell.execute_reply":"2023-01-26T19:59:03.151906Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{"papermill":{"duration":0.008274,"end_time":"2023-01-24T21:58:36.572321","exception":false,"start_time":"2023-01-24T21:58:36.564047","status":"completed"},"tags":[]}},{"cell_type":"code","source":"data = pd.read_excel('/kaggle/input/basket-analysis/Basket Analysis - Data.xlsx')\ndata.head()","metadata":{"papermill":{"duration":3.354897,"end_time":"2023-01-24T21:58:39.935793","exception":false,"start_time":"2023-01-24T21:58:36.580896","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:59:03.155037Z","iopub.execute_input":"2023-01-26T19:59:03.156282Z","iopub.status.idle":"2023-01-26T19:59:06.435004Z","shell.execute_reply.started":"2023-01-26T19:59:03.156239Z","shell.execute_reply":"2023-01-26T19:59:06.433638Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"  Transaction Date  Customer ID Product Description\n0       2014-01-01         1249        citrus fruit\n1       2014-01-01         1249              coffee\n2       2014-01-01         1249     italian sausage\n3       2014-01-01         1249             sausage\n4       2014-01-01         1381                curd","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Transaction Date</th>\n      <th>Customer ID</th>\n      <th>Product Description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2014-01-01</td>\n      <td>1249</td>\n      <td>citrus fruit</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-01-01</td>\n      <td>1249</td>\n      <td>coffee</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014-01-01</td>\n      <td>1249</td>\n      <td>italian sausage</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014-01-01</td>\n      <td>1249</td>\n      <td>sausage</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014-01-01</td>\n      <td>1381</td>\n      <td>curd</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data[\"Customer ID\"].nunique(),data[\"Customer ID\"].unique()","metadata":{"papermill":{"duration":0.026579,"end_time":"2023-01-24T21:58:39.971834","exception":false,"start_time":"2023-01-24T21:58:39.945255","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:59:06.438239Z","iopub.execute_input":"2023-01-26T19:59:06.439009Z","iopub.status.idle":"2023-01-26T19:59:06.456943Z","shell.execute_reply.started":"2023-01-26T19:59:06.438969Z","shell.execute_reply":"2023-01-26T19:59:06.455778Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(3898, array([1249, 1381, 1440, ..., 4755, 1963, 4565]))"},"metadata":{}}]},{"cell_type":"code","source":"data[\"Product Description\"].nunique()","metadata":{"papermill":{"duration":0.02297,"end_time":"2023-01-24T21:58:40.003769","exception":false,"start_time":"2023-01-24T21:58:39.980799","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:59:06.458552Z","iopub.execute_input":"2023-01-26T19:59:06.459085Z","iopub.status.idle":"2023-01-26T19:59:06.470162Z","shell.execute_reply.started":"2023-01-26T19:59:06.459054Z","shell.execute_reply":"2023-01-26T19:59:06.469136Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"170"},"metadata":{}}]},{"cell_type":"code","source":"ID=data[\"Customer ID\"].unique()\nID.tolist()\nID.sort()","metadata":{"papermill":{"duration":0.018886,"end_time":"2023-01-24T21:58:40.031647","exception":false,"start_time":"2023-01-24T21:58:40.012761","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:59:06.471340Z","iopub.execute_input":"2023-01-26T19:59:06.471916Z","iopub.status.idle":"2023-01-26T19:59:06.478923Z","shell.execute_reply.started":"2023-01-26T19:59:06.471883Z","shell.execute_reply":"2023-01-26T19:59:06.477479Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"item=data.groupby('Customer ID')['Product Description'].apply(list)\nitems=[]\nfor i in range(3898):\n    items.append(item.iloc[i])\nbasket=pd.DataFrame({\"item\":ID,\"products\":items})\nbasket['products'] = basket['products'].astype(str)\nregex = r'[\\[\\]/,]'\nbasket['products'] = basket['products'].apply(lambda x: re.sub(regex, '', x))\nbasket.head(2)","metadata":{"papermill":{"duration":0.161487,"end_time":"2023-01-24T21:58:40.202068","exception":false,"start_time":"2023-01-24T21:58:40.040581","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:59:06.480502Z","iopub.execute_input":"2023-01-26T19:59:06.480918Z","iopub.status.idle":"2023-01-26T19:59:06.636017Z","shell.execute_reply.started":"2023-01-26T19:59:06.480863Z","shell.execute_reply":"2023-01-26T19:59:06.634927Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   item                                           products\n0  1000  'pastry' 'salty snack' 'small milk' 'med milk'...\n1  1001  'rollsbuns' 'sausage' 'small milk' 'med milk' ...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item</th>\n      <th>products</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>'pastry' 'salty snack' 'small milk' 'med milk'...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>'rollsbuns' 'sausage' 'small milk' 'med milk' ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#concatenate multi-word product names together\nbasket['products'] = basket['products'].apply(lambda x: re.sub(r'(\\w+)\\s(\\w+)', r'\\1_\\2', x))\nbasket","metadata":{"papermill":{"duration":0.1087,"end_time":"2023-01-24T21:58:40.320003","exception":false,"start_time":"2023-01-24T21:58:40.211303","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:59:06.637509Z","iopub.execute_input":"2023-01-26T19:59:06.637844Z","iopub.status.idle":"2023-01-26T19:59:06.733110Z","shell.execute_reply.started":"2023-01-26T19:59:06.637807Z","shell.execute_reply":"2023-01-26T19:59:06.731969Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"      item                                           products\n0     1000  'pastry' 'salty_snack' 'small_milk' 'med_milk'...\n1     1001  'rollsbuns' 'sausage' 'small_milk' 'med_milk' ...\n2     1002  'frozen_vegetables' 'other_vegetables' 'butter...\n3     1003  'dental_care' 'frozen_meals' 'sauces' 'rollsbu...\n4     1004  'med_milk' 'pip_fruit' 'tropical_fruit' 'cling...\n...    ...                                                ...\n3893  4996  'salty_snack' 'tropical_fruit' 'bottled_beer' ...\n3894  4997  'canned_beer' 'italian_sausage' 'large_milk' '...\n3895  4998                                 'curd' 'rollsbuns'\n3896  4999  'herbs' 'newspapers' 'semi-finished_bread' 'de...\n3897  5000  'fruitvegetable_juice' 'onions' 'bottled_beer'...\n\n[3898 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>item</th>\n      <th>products</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000</td>\n      <td>'pastry' 'salty_snack' 'small_milk' 'med_milk'...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1001</td>\n      <td>'rollsbuns' 'sausage' 'small_milk' 'med_milk' ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1002</td>\n      <td>'frozen_vegetables' 'other_vegetables' 'butter...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1003</td>\n      <td>'dental_care' 'frozen_meals' 'sauces' 'rollsbu...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1004</td>\n      <td>'med_milk' 'pip_fruit' 'tropical_fruit' 'cling...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3893</th>\n      <td>4996</td>\n      <td>'salty_snack' 'tropical_fruit' 'bottled_beer' ...</td>\n    </tr>\n    <tr>\n      <th>3894</th>\n      <td>4997</td>\n      <td>'canned_beer' 'italian_sausage' 'large_milk' '...</td>\n    </tr>\n    <tr>\n      <th>3895</th>\n      <td>4998</td>\n      <td>'curd' 'rollsbuns'</td>\n    </tr>\n    <tr>\n      <th>3896</th>\n      <td>4999</td>\n      <td>'herbs' 'newspapers' 'semi-finished_bread' 'de...</td>\n    </tr>\n    <tr>\n      <th>3897</th>\n      <td>5000</td>\n      <td>'fruitvegetable_juice' 'onions' 'bottled_beer'...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3898 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\n\ndef preprocess(data):\n    preprocessed_data = []\n    for products in data:\n        products = products.split()\n        products = [lemmatizer.lemmatize(p) for p in products if p not in stop_words]\n        preprocessed_data.append(\" \".join(products))\n    return preprocessed_data\n    \nbasket['products'] = preprocess(basket['products'])\n","metadata":{"papermill":{"duration":1.965772,"end_time":"2023-01-24T21:58:42.295843","exception":false,"start_time":"2023-01-24T21:58:40.330071","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:59:06.735558Z","iopub.execute_input":"2023-01-26T19:59:06.735953Z","iopub.status.idle":"2023-01-26T19:59:09.076485Z","shell.execute_reply.started":"2023-01-26T19:59:06.735920Z","shell.execute_reply":"2023-01-26T19:59:09.075142Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{"papermill":{"duration":0.009037,"end_time":"2023-01-24T21:58:42.314363","exception":false,"start_time":"2023-01-24T21:58:42.305326","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Modeling","metadata":{"papermill":{"duration":0.009011,"end_time":"2023-01-24T21:58:42.332750","exception":false,"start_time":"2023-01-24T21:58:42.323739","status":"completed"},"tags":[]}},{"cell_type":"code","source":"model = SentenceTransformer('all-MiniLM-L6-v2')\nembeddings = model.encode(basket['products'])","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:59:09.079828Z","iopub.execute_input":"2023-01-26T19:59:09.080261Z","iopub.status.idle":"2023-01-26T20:00:22.746361Z","shell.execute_reply.started":"2023-01-26T19:59:09.080225Z","shell.execute_reply":"2023-01-26T20:00:22.744906Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5667946281b740fb8e75894595644694"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26fcdd07eaec460e80c35e2dd7891bdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e57b5aacbe145ae8e8a60af3d8600e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c6086a1e46834720b67c87047f510041"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6228f3556c864bbca8689f9c6d155bc9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aba14cc28c3a410285553095e9f0dc17"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38a2aae0630c4c9cb963c89c2be4d944"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"316f75da08c5497583a5659b5ea9a23c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52a8b1cc26f144a88a2e8bce74d17cde"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35e34025398c4804b6e3fd7d8d994617"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab6bb02d726f4143929fd9a53d3d7d24"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f96f7506d1144c4885a78f081f6304e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25dd29070d604ad5a6745406a67eb3cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"660941155f634c87a1409b511c5d2474"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/122 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"302accb25ae34d2c8999ca0c065f39b1"}},"metadata":{}}]},{"cell_type":"code","source":"embeddings.shape","metadata":{"execution":{"iopub.status.busy":"2023-01-26T20:00:22.751536Z","iopub.execute_input":"2023-01-26T20:00:22.751989Z","iopub.status.idle":"2023-01-26T20:00:22.762182Z","shell.execute_reply.started":"2023-01-26T20:00:22.751949Z","shell.execute_reply":"2023-01-26T20:00:22.760683Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"(3898, 384)"},"metadata":{}}]},{"cell_type":"code","source":"# Normalize the embeddings to unit length\nembeddings = embeddings /  np.linalg.norm(embeddings, axis=1, keepdims=True)","metadata":{"execution":{"iopub.status.busy":"2023-01-26T20:00:40.773429Z","iopub.execute_input":"2023-01-26T20:00:40.774494Z","iopub.status.idle":"2023-01-26T20:00:40.785384Z","shell.execute_reply.started":"2023-01-26T20:00:40.774439Z","shell.execute_reply":"2023-01-26T20:00:40.783888Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Perform AgglomerativeClustering \nagg =AgglomerativeClustering(n_clusters=None, distance_threshold=5.5)\nagg.fit(embeddings)\n\nsilhouette_avg = silhouette_score(embeddings, agg.labels_)\nprint(\"For n_clusters =\", len(np.unique(agg.labels_)), \"The average silhouette_score is :\", silhouette_avg,\"\\n\\n\")\n\nunique_labels = np.unique(agg.labels_)\nprod_cluster={}\nfor i in unique_labels:\n    indices = np.where(agg.labels_ == i)[0]\n    prod_cluster[i+1]=np.array(basket[\"products\"])[indices].tolist()\n#     print(\"Cluster {}: {}\".format(i+1, ', '.join(np.array(basket[\"products\"])[indices].tolist())))\n#     print(\"\\n\\n\")\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:14:06.939222Z","iopub.execute_input":"2023-01-26T22:14:06.939620Z","iopub.status.idle":"2023-01-26T22:14:09.708524Z","shell.execute_reply.started":"2023-01-26T22:14:06.939589Z","shell.execute_reply":"2023-01-26T22:14:09.707058Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"For n_clusters = 4 The average silhouette_score is : 0.010999403 \n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Reduce the dimensionality of the data to 2D\n# pca = PCA(n_components=2)\n# pca_result = pca.fit_transform(embeddings)\n\n# # Plot the results\n# plt.figure(figsize=(12,8))\n\n# for i in unique_labels:\n#     indices = np.where(agg.labels_ == i)[0]\n#     plt.scatter(basket.iloc[indices,\"items\"], basket.iloc[indices,\"items\"], label=f'Cluster {i+1}')\n# plt.legend()\n# plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T22:17:11.359386Z","iopub.execute_input":"2023-01-26T22:17:11.361049Z","iopub.status.idle":"2023-01-26T22:17:11.367323Z","shell.execute_reply.started":"2023-01-26T22:17:11.360978Z","shell.execute_reply":"2023-01-26T22:17:11.365685Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"\n# # Calculate pairwise distances\n# distance_matrix = pairwise_distances(embeddings)\n\n# # Print the top 10 nearest products for each product\n# for i in range(distance_matrix.shape[0]):\n#     nearest_indices = np.argsort(distance_matrix[i])[:10]\n#     print(\"Top 10 nearest products for product\", i+1)\n#     for index in nearest_indices:\n#         print(basket.iloc[index]['products'])\n","metadata":{"execution":{"iopub.status.busy":"2023-01-26T19:56:07.331055Z","iopub.status.idle":"2023-01-26T19:56:07.331534Z","shell.execute_reply.started":"2023-01-26T19:56:07.331317Z","shell.execute_reply":"2023-01-26T19:56:07.331347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def jaccard_similarity(matrix):\n#     # Compute the Jaccard similarity between all pairs of products\n#     n_products = matrix.shape[1]\n#     jaccard_similarities = np.zeros((n_products, n_products))\n#     for i in range(n_products):\n#         for j in range(i, n_products):\n#             intersection = np.sum(matrix[:, i] & matrix[:, j])\n#             union = np.sum(matrix[:, i] | matrix[:, j])\n#             jaccard_similarities[i, j] = intersection / union\n#             jaccard_similarities[j, i] = jaccard_similarities[i, j]\n#     return jaccard_similarities","metadata":{"papermill":{"duration":0.021191,"end_time":"2023-01-24T21:58:42.420612","exception":false,"start_time":"2023-01-24T21:58:42.399421","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:56:07.332998Z","iopub.status.idle":"2023-01-26T19:56:07.333439Z","shell.execute_reply.started":"2023-01-26T19:56:07.333229Z","shell.execute_reply":"2023-01-26T19:56:07.333250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Vectorize the data\n# tfidf = TfidfVectorizer()\n# tfidf_matrix = tfidf.fit_transform(basket['products']).toarray()\n# features = tfidf.get_feature_names_out()\n# tfidf_data = pd.DataFrame(tfidf_matrix, columns=features)\n# # Convert the tf-idf matrix to a binary matrix\n# binary_matrix = tfidf_matrix > 0\n# # Compute the Jaccard similarity between products\n# products_similarities = jaccard_similarity(binary_matrix)\n\n# from sklearn.cluster import AgglomerativeClustering\n# # n_clusters = 2\n\n# # Perform Hierarchical Clustering\n# agg =AgglomerativeClustering(n_clusters=None, distance_threshold=2.1)\n# agg.fit(products_similarities)\n\n# unique_labels = np.unique(agg.labels_)\n# print(len(unique_labels), \"\\n\")\n\n# silhouette_avg =silhouette_score(tfidf_matrix.T, agg.labels_)\n# print(\"For n_clusters =\", len(unique_labels), \"The average silhouette_score is :\", silhouette_avg,\"\\n\\n\")\n\n\n# # for i in unique_labels:\n# #     indices = np.where(agg.labels_ == i)[0]\n# #     print(\"Cluster {}: {}\".format(i+1, ', '.join(np.array(tfidf.get_feature_names())[indices].tolist())))\n# #     print(\"\\n\\n\")","metadata":{"papermill":{"duration":0.858556,"end_time":"2023-01-24T21:58:43.288856","exception":false,"start_time":"2023-01-24T21:58:42.430300","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:56:07.336341Z","iopub.status.idle":"2023-01-26T19:56:07.336853Z","shell.execute_reply.started":"2023-01-26T19:56:07.336595Z","shell.execute_reply":"2023-01-26T19:56:07.336616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Reduce the dimensionality of the data to 2D\n# pca = PCA(n_components=2)\n# pca_result = pca.fit_transform(tfidf_matrix.T)\n\n# # Plot the results\n# plt.figure(figsize=(12,8))\n\n# for i in unique_labels:\n#     indices = np.where(agg.labels_ == i)[0]\n#     plt.scatter(pca_result[indices, 0], pca_result[indices, 1], label=f'Cluster {i+1}')\n# #     for j, product in enumerate(np.array(tfidf.get_feature_names())[indices.tolist()]):\n# #         plt.annotate(product, (pca_result[indices, 0][j], pca_result[indices, 1][j]))\n# plt.legend()\n# plt.show()","metadata":{"papermill":{"duration":0.678526,"end_time":"2023-01-24T21:58:43.991340","exception":false,"start_time":"2023-01-24T21:58:43.312814","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:56:07.338244Z","iopub.status.idle":"2023-01-26T19:56:07.338733Z","shell.execute_reply.started":"2023-01-26T19:56:07.338480Z","shell.execute_reply":"2023-01-26T19:56:07.338500Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import plotly.colors\n# import plotly.graph_objs as go\n# # Reduce the dimensionality of the data to 2D\n# pca = PCA(n_components=3)\n# pca_result = pca.fit_transform(tfidf_matrix.T)\n# fig = plt.figure(figsize=(12,7))\n# ax = fig.add_subplot(111, projection='3d')\n# offset = 0.1\n# data = []\n# for i in unique_labels:\n#     indices = np.where(agg.labels_ == i)[0]\n#     trace = go.Scatter3d(x=pca_result[indices, 0], y=pca_result[indices, 1], z=pca_result[indices, 2], mode='markers',\n#     marker=dict(size=10, color=plotly.colors.DEFAULT_PLOTLY_COLORS[i]),\n#     text=[tfidf.get_feature_names()[i] for i in indices],\n#     name=f'Cluster {i+1}')\n#     data.append(trace)\n\n\n# layout = go.Layout(title='3D Plot',scene=dict(xaxis=dict(title='PC1'), yaxis=dict(title='PC2'), zaxis=dict(title='PC3')))\n# fig = go.Figure(data=data, layout=layout)\n# fig.show()","metadata":{"papermill":{"duration":0.617229,"end_time":"2023-01-24T21:58:44.618935","exception":false,"start_time":"2023-01-24T21:58:44.001706","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2023-01-26T19:56:07.340408Z","iopub.status.idle":"2023-01-26T19:56:07.340888Z","shell.execute_reply.started":"2023-01-26T19:56:07.340666Z","shell.execute_reply":"2023-01-26T19:56:07.340690Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{"papermill":{"duration":0.010725,"end_time":"2023-01-24T21:58:44.640915","exception":false,"start_time":"2023-01-24T21:58:44.630190","status":"completed"},"tags":[]}}]}