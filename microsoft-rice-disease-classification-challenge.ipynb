{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport shutil\nimport tensorflow as tf\nimport pathlib\nimport PIL\nimport time\nimport zipfile\nimport random\nfrom tensorflow import keras as ks\nfrom tensorflow.keras.layers import *\nfrom keras.utils.np_utils import to_categorical \nfrom keras.models import Sequential\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')\nfrom fastai.vision.all import *","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-08T11:47:17.749281Z","iopub.execute_input":"2022-08-08T11:47:17.749768Z","iopub.status.idle":"2022-08-08T11:47:17.760060Z","shell.execute_reply.started":"2022-08-08T11:47:17.749729Z","shell.execute_reply":"2022-08-08T11:47:17.759038Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv(\"../input/microsoft-rice-disease-classification-challenge/Train (6).csv\")\ntest_df=pd.read_csv(\"../input/microsoft-rice-disease-classification-challenge/Test (8).csv\")\nsub=pd.read_csv(\"../input/microsoft-rice-disease-classification-challenge/SampleSubmission (4).csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.197671Z","iopub.execute_input":"2022-08-08T11:47:19.198185Z","iopub.status.idle":"2022-08-08T11:47:19.227322Z","shell.execute_reply.started":"2022-08-08T11:47:19.198119Z","shell.execute_reply":"2022-08-08T11:47:19.226367Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.231947Z","iopub.execute_input":"2022-08-08T11:47:19.234295Z","iopub.status.idle":"2022-08-08T11:47:19.251503Z","shell.execute_reply.started":"2022-08-08T11:47:19.234257Z","shell.execute_reply":"2022-08-08T11:47:19.250592Z"},"trusted":true},"execution_count":100,"outputs":[{"execution_count":100,"output_type":"execute_result","data":{"text/plain":"                   Image_id\n0         id_00vl5wvxq3.jpg\n1     id_00vl5wvxq3_rgn.jpg\n2         id_01hu05mtch.jpg\n3     id_01hu05mtch_rgn.jpg\n4         id_030ln10ewn.jpg\n...                     ...\n2285  id_ztvp2l9k3h_rgn.jpg\n2286      id_zwwcma7hlt.jpg\n2287  id_zwwcma7hlt_rgn.jpg\n2288      id_zyo7m4fj8h.jpg\n2289  id_zyo7m4fj8h_rgn.jpg\n\n[2290 rows x 1 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_00vl5wvxq3.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_00vl5wvxq3_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_01hu05mtch.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_01hu05mtch_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_030ln10ewn.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2285</th>\n      <td>id_ztvp2l9k3h_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>2286</th>\n      <td>id_zwwcma7hlt.jpg</td>\n    </tr>\n    <tr>\n      <th>2287</th>\n      <td>id_zwwcma7hlt_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>2288</th>\n      <td>id_zyo7m4fj8h.jpg</td>\n    </tr>\n    <tr>\n      <th>2289</th>\n      <td>id_zyo7m4fj8h_rgn.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>2290 rows × 1 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.255958Z","iopub.execute_input":"2022-08-08T11:47:19.258358Z","iopub.status.idle":"2022-08-08T11:47:19.276578Z","shell.execute_reply.started":"2022-08-08T11:47:19.258315Z","shell.execute_reply":"2022-08-08T11:47:19.275656Z"},"trusted":true},"execution_count":101,"outputs":[{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"                   Image_id  Label\n0         id_004wknd7qd.jpg  blast\n1     id_004wknd7qd_rgn.jpg  blast\n2         id_005sitfgr2.jpg  brown\n3     id_005sitfgr2_rgn.jpg  brown\n4         id_00stp9t6m6.jpg  blast\n...                     ...    ...\n5335  id_zz6gzk7p97_rgn.jpg  brown\n5336      id_zz8ca2p67e.jpg  blast\n5337  id_zz8ca2p67e_rgn.jpg  blast\n5338      id_zzt8y9q0x0.jpg  brown\n5339  id_zzt8y9q0x0_rgn.jpg  brown\n\n[5340 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_id</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_004wknd7qd.jpg</td>\n      <td>blast</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_004wknd7qd_rgn.jpg</td>\n      <td>blast</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_005sitfgr2.jpg</td>\n      <td>brown</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_005sitfgr2_rgn.jpg</td>\n      <td>brown</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_00stp9t6m6.jpg</td>\n      <td>blast</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5335</th>\n      <td>id_zz6gzk7p97_rgn.jpg</td>\n      <td>brown</td>\n    </tr>\n    <tr>\n      <th>5336</th>\n      <td>id_zz8ca2p67e.jpg</td>\n      <td>blast</td>\n    </tr>\n    <tr>\n      <th>5337</th>\n      <td>id_zz8ca2p67e_rgn.jpg</td>\n      <td>blast</td>\n    </tr>\n    <tr>\n      <th>5338</th>\n      <td>id_zzt8y9q0x0.jpg</td>\n      <td>brown</td>\n    </tr>\n    <tr>\n      <th>5339</th>\n      <td>id_zzt8y9q0x0_rgn.jpg</td>\n      <td>brown</td>\n    </tr>\n  </tbody>\n</table>\n<p>5340 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Id=test_df[\"Image_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.281961Z","iopub.execute_input":"2022-08-08T11:47:19.284254Z","iopub.status.idle":"2022-08-08T11:47:19.290535Z","shell.execute_reply.started":"2022-08-08T11:47:19.284218Z","shell.execute_reply":"2022-08-08T11:47:19.289506Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"train_df.Label.unique()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.295587Z","iopub.execute_input":"2022-08-08T11:47:19.298440Z","iopub.status.idle":"2022-08-08T11:47:19.310202Z","shell.execute_reply.started":"2022-08-08T11:47:19.298397Z","shell.execute_reply":"2022-08-08T11:47:19.308830Z"},"trusted":true},"execution_count":103,"outputs":[{"execution_count":103,"output_type":"execute_result","data":{"text/plain":"array(['blast', 'brown', 'healthy'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"train_df.Label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.314917Z","iopub.execute_input":"2022-08-08T11:47:19.315609Z","iopub.status.idle":"2022-08-08T11:47:19.330493Z","shell.execute_reply.started":"2022-08-08T11:47:19.315570Z","shell.execute_reply":"2022-08-08T11:47:19.329396Z"},"trusted":true},"execution_count":104,"outputs":[{"execution_count":104,"output_type":"execute_result","data":{"text/plain":"blast      2988\nbrown      1532\nhealthy     820\nName: Label, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# dls = ImageDataLoaders.from_df(train_df,bs=32, path='../input/microsoft-rice-disease-classification-challenge/Images (1)/', num_workers=-1) # See the docs for adding augmentations etc\n# dls.show_batch() \n","metadata":{"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-08-08T11:47:19.334729Z","iopub.execute_input":"2022-08-08T11:47:19.335086Z","iopub.status.idle":"2022-08-08T11:47:19.341179Z","shell.execute_reply.started":"2022-08-08T11:47:19.335051Z","shell.execute_reply":"2022-08-08T11:47:19.339783Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"path='../input/microsoft-rice-disease-classification-challenge/Images (1)/'\nimg_paths = []\nfor i in train_df.Image_id:\n    img_paths.append(path + i)\ntrain_df['path'] = img_paths","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.342675Z","iopub.execute_input":"2022-08-08T11:47:19.343362Z","iopub.status.idle":"2022-08-08T11:47:19.355275Z","shell.execute_reply.started":"2022-08-08T11:47:19.343326Z","shell.execute_reply":"2022-08-08T11:47:19.354272Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.360272Z","iopub.execute_input":"2022-08-08T11:47:19.363082Z","iopub.status.idle":"2022-08-08T11:47:19.383876Z","shell.execute_reply.started":"2022-08-08T11:47:19.363045Z","shell.execute_reply":"2022-08-08T11:47:19.382902Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"                   Image_id  Label  \\\n0         id_004wknd7qd.jpg  blast   \n1     id_004wknd7qd_rgn.jpg  blast   \n2         id_005sitfgr2.jpg  brown   \n3     id_005sitfgr2_rgn.jpg  brown   \n4         id_00stp9t6m6.jpg  blast   \n...                     ...    ...   \n5335  id_zz6gzk7p97_rgn.jpg  brown   \n5336      id_zz8ca2p67e.jpg  blast   \n5337  id_zz8ca2p67e_rgn.jpg  blast   \n5338      id_zzt8y9q0x0.jpg  brown   \n5339  id_zzt8y9q0x0_rgn.jpg  brown   \n\n                                                                                           path  \n0         ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd.jpg  \n1     ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd_rgn.jpg  \n2         ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2.jpg  \n3     ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2_rgn.jpg  \n4         ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_00stp9t6m6.jpg  \n...                                                                                         ...  \n5335  ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz6gzk7p97_rgn.jpg  \n5336      ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e.jpg  \n5337  ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e_rgn.jpg  \n5338      ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0.jpg  \n5339  ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0_rgn.jpg  \n\n[5340 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_id</th>\n      <th>Label</th>\n      <th>path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_004wknd7qd.jpg</td>\n      <td>blast</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd.jpg</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_004wknd7qd_rgn.jpg</td>\n      <td>blast</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_005sitfgr2.jpg</td>\n      <td>brown</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2.jpg</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_005sitfgr2_rgn.jpg</td>\n      <td>brown</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_00stp9t6m6.jpg</td>\n      <td>blast</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_00stp9t6m6.jpg</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5335</th>\n      <td>id_zz6gzk7p97_rgn.jpg</td>\n      <td>brown</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz6gzk7p97_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>5336</th>\n      <td>id_zz8ca2p67e.jpg</td>\n      <td>blast</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e.jpg</td>\n    </tr>\n    <tr>\n      <th>5337</th>\n      <td>id_zz8ca2p67e_rgn.jpg</td>\n      <td>blast</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e_rgn.jpg</td>\n    </tr>\n    <tr>\n      <th>5338</th>\n      <td>id_zzt8y9q0x0.jpg</td>\n      <td>brown</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0.jpg</td>\n    </tr>\n    <tr>\n      <th>5339</th>\n      <td>id_zzt8y9q0x0_rgn.jpg</td>\n      <td>brown</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0_rgn.jpg</td>\n    </tr>\n  </tbody>\n</table>\n<p>5340 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc=OneHotEncoder()\n\ntrain_df= pd.get_dummies(train_df, columns = [\"Label\"])","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.389395Z","iopub.execute_input":"2022-08-08T11:47:19.391676Z","iopub.status.idle":"2022-08-08T11:47:19.404278Z","shell.execute_reply.started":"2022-08-08T11:47:19.391639Z","shell.execute_reply":"2022-08-08T11:47:19.403137Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.506198Z","iopub.execute_input":"2022-08-08T11:47:19.506532Z","iopub.status.idle":"2022-08-08T11:47:19.525233Z","shell.execute_reply.started":"2022-08-08T11:47:19.506501Z","shell.execute_reply":"2022-08-08T11:47:19.524228Z"},"trusted":true},"execution_count":109,"outputs":[{"execution_count":109,"output_type":"execute_result","data":{"text/plain":"                   Image_id  \\\n0         id_004wknd7qd.jpg   \n1     id_004wknd7qd_rgn.jpg   \n2         id_005sitfgr2.jpg   \n3     id_005sitfgr2_rgn.jpg   \n4         id_00stp9t6m6.jpg   \n...                     ...   \n5335  id_zz6gzk7p97_rgn.jpg   \n5336      id_zz8ca2p67e.jpg   \n5337  id_zz8ca2p67e_rgn.jpg   \n5338      id_zzt8y9q0x0.jpg   \n5339  id_zzt8y9q0x0_rgn.jpg   \n\n                                                                                           path  \\\n0         ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd.jpg   \n1     ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd_rgn.jpg   \n2         ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2.jpg   \n3     ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2_rgn.jpg   \n4         ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_00stp9t6m6.jpg   \n...                                                                                         ...   \n5335  ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz6gzk7p97_rgn.jpg   \n5336      ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e.jpg   \n5337  ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e_rgn.jpg   \n5338      ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0.jpg   \n5339  ../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0_rgn.jpg   \n\n      Label_blast  Label_brown  Label_healthy  \n0               1            0              0  \n1               1            0              0  \n2               0            1              0  \n3               0            1              0  \n4               1            0              0  \n...           ...          ...            ...  \n5335            0            1              0  \n5336            1            0              0  \n5337            1            0              0  \n5338            0            1              0  \n5339            0            1              0  \n\n[5340 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image_id</th>\n      <th>path</th>\n      <th>Label_blast</th>\n      <th>Label_brown</th>\n      <th>Label_healthy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>id_004wknd7qd.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>id_004wknd7qd_rgn.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_004wknd7qd_rgn.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>id_005sitfgr2.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>id_005sitfgr2_rgn.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_005sitfgr2_rgn.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>id_00stp9t6m6.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_00stp9t6m6.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5335</th>\n      <td>id_zz6gzk7p97_rgn.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz6gzk7p97_rgn.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5336</th>\n      <td>id_zz8ca2p67e.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5337</th>\n      <td>id_zz8ca2p67e_rgn.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zz8ca2p67e_rgn.jpg</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5338</th>\n      <td>id_zzt8y9q0x0.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5339</th>\n      <td>id_zzt8y9q0x0_rgn.jpg</td>\n      <td>../input/microsoft-rice-disease-classification-challenge/Images (1)/id_zzt8y9q0x0_rgn.jpg</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5340 rows × 5 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_datagenerator = ImageDataGenerator(\n    featurewise_std_normalization=False,\n    samplewise_std_normalization=False,\n    rescale=1./255, \n    rotation_range=40, \n    width_shift_range=0.2, \n    height_shift_range=0.2, \n    shear_range=.2, \n    zoom_range=0.2,\n    horizontal_flip=True, \n    fill_mode='nearest',\n    validation_split=0.1)","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.699570Z","iopub.execute_input":"2022-08-08T11:47:19.699957Z","iopub.status.idle":"2022-08-08T11:47:19.706843Z","shell.execute_reply.started":"2022-08-08T11:47:19.699923Z","shell.execute_reply":"2022-08-08T11:47:19.705661Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagenerator.flow_from_dataframe(\n    train_df, \n    x_col='path', \n    y_col=['Label_blast',\"Label_brown\",\"Label_healthy\"],\n    target_size=(120, 120), \n    color_mode='rgb', \n    class_mode='raw', \n    batch_size=32, \n    shuffle=True, \n    seed=1,\n    subset='training')\nvalidation_generator = train_datagenerator.flow_from_dataframe(\n    train_df , \n    x_col='path',\n    y_col=['Label_blast',\"Label_brown\",\"Label_healthy\"],\n    target_size=(120, 120),\n    color_mode='rgb', \n    class_mode='raw', \n    batch_size=4, \n    shuffle=True,\n    seed=1, \n    subset='validation')","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:19.970517Z","iopub.execute_input":"2022-08-08T11:47:19.970870Z","iopub.status.idle":"2022-08-08T11:47:22.152955Z","shell.execute_reply.started":"2022-08-08T11:47:19.970838Z","shell.execute_reply":"2022-08-08T11:47:22.151955Z"},"trusted":true},"execution_count":111,"outputs":[{"name":"stdout","text":"Found 4806 validated image filenames.\nFound 534 validated image filenames.\n","output_type":"stream"}]},{"cell_type":"code","source":"plt.figure(figsize=(12, 12))\nfor i in range(0, 6):\n    plt.subplot(2, 3, i+1)\n    for X_batch, Y_batch in validation_generator:\n        image = X_batch[0]\n        plt.imshow(image)\n        break\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-08-08T11:47:22.155143Z","iopub.execute_input":"2022-08-08T11:47:22.155803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=train_df.drop(\"Image_id\", axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# def focal_loss(gamma=2., alpha=4.):\n#      gamma = float(gamma)\n#      alpha = float(alpha)\n#      def focal_loss_fixed(y_true, y_pred):\n#          \"\"\"Focal loss for multi-classification\n#          FL(p_t)=-alpha(1-p_t)^{gamma}ln(p_t)\n#          Notice: y_pred is probability after softmax\n#          gradient is d(Fl)/d(p_t) not d(Fl)/d(x) as described in paper\n#          d(Fl)/d(p_t) * [p_t(1-p_t)] = d(Fl)/d(x)\n#          Focal Loss for Dense Object Detection\n#          https://arxiv.org/abs/1708.02002\n#          Arguments:\n#              y_true {tensor} -- ground truth labels, shape of [batch_size, num_cls]\n#              y_pred {tensor} -- model's output, shape of [batch_size, num_cls]\n#          Keyword Arguments:\n#              gamma {float} -- (default: {2.0})\n#              alpha {float} -- (default: {4.0})\n#          Returns:\n#              [tensor] -- loss.\n#          \"\"\"\n#          epsilon = 1.e-9\n#          y_true = tf.convert_to_tensor(y_true, tf.float32)\n#          y_pred = tf.convert_to_tensor(y_pred, tf.float32)\n#          model_out = tf.add(y_pred, epsilon)\n#          ce = tf.multiply(y_true, -tf.log(model_out))\n#          weight = tf.multiply(y_true, tf.pow(tf.subtract(1., model_out), gamma))\n#          fl = tf.multiply(alpha, tf.multiply(weight, ce))\n#          reduced_fl = tf.reduce_max(fl, axis=1)\n#          return tf.reduce_mean(reduced_fl)\n#      return focal_loss_fixed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow_addons as tfa\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = ks.models.Sequential()\n\n# model.add(ks.layers.Dense(4, input_shape=(120, 120, 3)))\n\n# model.add(ks.layers.Conv2D(64, (3, 3), activation='relu'))\n# model.add(ks.layers.MaxPooling2D(2, 2))\n\n# model.add(ks.layers.Conv2D(128, (3, 3), activation='relu'))\n# model.add(ks.layers.MaxPooling2D(2, 2))\n\n\n# model.add(ks.layers.Conv2D(256, (3, 3), activation='relu'))\n# model.add(ks.layers.MaxPooling2D(2, 2))\n\n# model.add(ks.layers.Conv2D(512, (3, 3), activation='relu'))\n# model.add(ks.layers.MaxPooling2D(2, 2))\n# model.add(ks.layers.Dropout(0.2))\n\n        \n# model.add(ks.layers.Flatten())\n        \n# model.add(ks.layers.Dense(1024, activation='relu'))\n\n# model.add(ks.layers.Dense(3, activation='softmax'))\n\n# model.compile(optimizer='adam',\n#               loss=tfa.losses.SigmoidFocalCrossEntropy(),\n#               metrics=['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.layers import Input, Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Flatten\nfrom keras.models import Model\n\n_input = Input((120, 120, 3)) \n\nconv1  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(_input)\nconv2  = Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv1)\npool1  = MaxPooling2D((2, 2))(conv2)\n\nconv3  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool1)\nconv4  = Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv3)\npool2  = MaxPooling2D((2, 2))(conv4)\n\nconv5  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool2)\nconv6  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv5)\nconv7  = Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv6)\npool3  = MaxPooling2D((2, 2))(conv7)\n\nconv8  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool3)\nconv9  = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv8)\nconv10 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv9)\npool4  = MaxPooling2D((2, 2))(conv10)\n\nconv11 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(pool4)\nconv12 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv11)\nconv13 = Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\")(conv12)\npool5  = MaxPooling2D((2, 2))(conv13)\n\nflat   = Flatten()(pool5)\ndense1 = Dense(4096, activation=\"relu\")(flat)\ndense2 = Dense(4096, activation=\"relu\")(dense1)\noutput = Dense(3, activation=\"softmax\")(dense2)\n\nvgg16_model  = Model(inputs=_input, outputs=output)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg16_model.compile(optimizer='adam',\n              loss=\"categorical_crossentropy\",\n              metrics=['acc'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Use focal loss","metadata":{}},{"cell_type":"code","source":"batch_size=15\nFAST_RUN = False\nepochs=5 if FAST_RUN else 20\nhistory = vgg16_model.fit_generator(\n    train_generator, \n    epochs=epochs,\n    validation_data=validation_generator\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nL=[]\nL0=[]\nL1=[]\nL2=[]\nfor i in range(test_df.shape[0]//2):\n    index=i*2\n    img_path = test_df.loc[index,\"Image_id\"]\n    path = \"../input/microsoft-rice-disease-classification-challenge/Images (1)/\" + img_path\n    img = np.array(Image.open(path).resize((120,120))).reshape((1, 120, 120, 3))\n    out = vgg16_model(img)\n#     print(out)\n#     print(tf.get_static_value(tf.math.argmax(out, axis=1)))\n    L.append(tf.get_static_value(tf.math.argmax(out, axis=1)))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in L :\n        if i ==1 :\n            L0.append(1)\n            L0.append(1)\n            L1.append(0)\n            L1.append(0)\n            L2.append(0)\n            L2.append(0)\n        elif i ==1 :\n            L0.append(0)\n            L0.append(0)\n            L1.append(1)\n            L1.append(1)\n            L2.append(0)\n            L2.append(0)\n        else :\n            L0.append(0)\n            L0.append(0)\n            L1.append(0)\n            L1.append(0)\n            L2.append(1)\n            L2.append(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.DataFrame({\"Image_id\":Id,\"blast\":L0,\"brown\":L1,\"healthy\":L2})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"sub2.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}