{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Python libraries","metadata":{}},{"cell_type":"code","source":"!pip install flwr","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:42:32.812993Z","iopub.execute_input":"2023-05-20T15:42:32.813382Z","iopub.status.idle":"2023-05-20T15:42:42.178047Z","shell.execute_reply.started":"2023-05-20T15:42:32.813346Z","shell.execute_reply":"2023-05-20T15:42:42.176803Z"},"trusted":true},"execution_count":87,"outputs":[{"name":"stdout","text":"Requirement already satisfied: flwr in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: iterators<0.0.3,>=0.0.2 in /opt/conda/lib/python3.7/site-packages (from flwr) (0.0.2)\nRequirement already satisfied: protobuf<4.0.0,>=3.19.0 in /opt/conda/lib/python3.7/site-packages (from flwr) (3.20.3)\nRequirement already satisfied: importlib-metadata<5.0.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from flwr) (4.11.4)\nRequirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.48.2 in /opt/conda/lib/python3.7/site-packages (from flwr) (1.51.1)\nRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from flwr) (1.21.6)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->flwr) (3.11.0)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->flwr) (4.4.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow.compat.v1 as tf\nsess = tf.Session()\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"../input\"))\nimport errno\nimport tensorflow as tf\nimport csv\nfrom keras import backend as K\nimport sklearn\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom keras.layers import Conv1D, MaxPool1D\nfrom keras.optimizers import Adam\nimport random\nimport pandas as pd\nimport numpy as np\nimport math\nimport os\nimport flwr as fl\nimport array\nfrom scipy.stats import dirichlet\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\n\nfrom imblearn.over_sampling import SMOTE","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-05-20T15:42:42.180108Z","iopub.execute_input":"2023-05-20T15:42:42.180428Z","iopub.status.idle":"2023-05-20T15:42:42.197847Z","shell.execute_reply.started":"2023-05-20T15:42:42.180396Z","shell.execute_reply":"2023-05-20T15:42:42.195846Z"},"trusted":true},"execution_count":88,"outputs":[{"name":"stdout","text":"['adult-census-income']\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install aif360 ","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:42:42.199388Z","iopub.execute_input":"2023-05-20T15:42:42.199773Z","iopub.status.idle":"2023-05-20T15:42:51.734704Z","shell.execute_reply.started":"2023-05-20T15:42:42.199714Z","shell.execute_reply":"2023-05-20T15:42:51.731049Z"},"trusted":true},"execution_count":89,"outputs":[{"name":"stdout","text":"Requirement already satisfied: aif360 in /opt/conda/lib/python3.7/site-packages (0.5.0)\nRequirement already satisfied: numpy>=1.16 in /opt/conda/lib/python3.7/site-packages (from aif360) (1.21.6)\nRequirement already satisfied: scikit-learn>=1.0 in /opt/conda/lib/python3.7/site-packages (from aif360) (1.0.2)\nRequirement already satisfied: pandas>=0.24.0 in /opt/conda/lib/python3.7/site-packages (from aif360) (1.3.5)\nRequirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.7/site-packages (from aif360) (1.7.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from aif360) (3.5.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->aif360) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.24.0->aif360) (2022.7.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0->aif360) (1.2.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn>=1.0->aif360) (3.1.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->aif360) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->aif360) (23.0)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->aif360) (4.38.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->aif360) (9.4.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->aif360) (1.4.4)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->aif360) (0.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->aif360) (4.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.24.0->aif360) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install BlackBoxAuditing","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:42:51.745057Z","iopub.execute_input":"2023-05-20T15:42:51.746238Z","iopub.status.idle":"2023-05-20T15:43:01.483011Z","shell.execute_reply.started":"2023-05-20T15:42:51.746124Z","shell.execute_reply":"2023-05-20T15:43:01.481847Z"},"trusted":true},"execution_count":90,"outputs":[{"name":"stdout","text":"Requirement already satisfied: BlackBoxAuditing in /opt/conda/lib/python3.7/site-packages (0.1.54)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from BlackBoxAuditing) (1.21.6)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.7/site-packages (from BlackBoxAuditing) (2.6.3)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from BlackBoxAuditing) (3.5.3)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from BlackBoxAuditing) (1.3.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->BlackBoxAuditing) (23.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->BlackBoxAuditing) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->BlackBoxAuditing) (9.4.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->BlackBoxAuditing) (3.0.9)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->BlackBoxAuditing) (2.8.2)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->BlackBoxAuditing) (1.4.4)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->BlackBoxAuditing) (4.38.0)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->BlackBoxAuditing) (2022.7.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->BlackBoxAuditing) (4.4.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->BlackBoxAuditing) (1.16.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install flwr","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:01.484371Z","iopub.execute_input":"2023-05-20T15:43:01.484693Z","iopub.status.idle":"2023-05-20T15:43:10.892005Z","shell.execute_reply.started":"2023-05-20T15:43:01.484660Z","shell.execute_reply":"2023-05-20T15:43:10.890085Z"},"trusted":true},"execution_count":91,"outputs":[{"name":"stdout","text":"Requirement already satisfied: flwr in /opt/conda/lib/python3.7/site-packages (1.4.0)\nRequirement already satisfied: iterators<0.0.3,>=0.0.2 in /opt/conda/lib/python3.7/site-packages (from flwr) (0.0.2)\nRequirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.48.2 in /opt/conda/lib/python3.7/site-packages (from flwr) (1.51.1)\nRequirement already satisfied: importlib-metadata<5.0.0,>=4.0.0 in /opt/conda/lib/python3.7/site-packages (from flwr) (4.11.4)\nRequirement already satisfied: protobuf<4.0.0,>=3.19.0 in /opt/conda/lib/python3.7/site-packages (from flwr) (3.20.3)\nRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /opt/conda/lib/python3.7/site-packages (from flwr) (1.21.6)\nRequirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->flwr) (4.4.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata<5.0.0,>=4.0.0->flwr) (3.11.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import dataset","metadata":{}},{"cell_type":"code","source":"data_path = ('/kaggle/input/adult-census-income/adult.csv')\ndf = pd.read_csv(data_path, encoding='latin-1')\ndata = pd.read_csv(data_path)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:10.894398Z","iopub.execute_input":"2023-05-20T15:43:10.894922Z","iopub.status.idle":"2023-05-20T15:43:10.987720Z","shell.execute_reply.started":"2023-05-20T15:43:10.894873Z","shell.execute_reply":"2023-05-20T15:43:10.986738Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"def create_alphas(dim):\n    alphas = {\n        'extremely homogeneous': [100000 for i in range(dim)],\n        'very homogeneous': [1000 for i in range(dim)],\n        'homogeneous': [10 for i in range(dim)],\n        'uniform': [1 for i in range(dim)],  # Eqivaut a un echantillonage aleatoire sample(random_state = 0)\n        'heterogeneous_2': [1 / 2 for i in range(dim)],\n        'heterogeneous_5': [1 / 5 for i in range(dim)],\n        'heterogeneous_10': [1 / 10 for i in range(dim)],\n        'very heterogeneous': [1 / 100 for i in range(dim)],  # inutilisable\n        'extremely heterogeneous': [1 / 1000 for i in range(dim)]  # inutilisable\n    }\n    return alphas","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:10.989948Z","iopub.execute_input":"2023-05-20T15:43:10.990799Z","iopub.status.idle":"2023-05-20T15:43:11.000179Z","shell.execute_reply.started":"2023-05-20T15:43:10.990722Z","shell.execute_reply":"2023-05-20T15:43:10.998889Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"# créer un graphique à deux sous-graphiques pour tracer l'évolution\n# de  (accuracy) et de la perte (loss) du modèle au cours de l'entraînement\n# Plot training & validation accuracy values\ndef plot_learningCurve(history, epoch, client_id):\n\n    epoch_range = range(1, epoch + 1)\n    figure, axis = plt.subplots(2, 1)\n    axis[0].plot(epoch_range, history.history['accuracy'])\n    axis[0].plot(epoch_range, history.history['val_accuracy'])\n    axis[0].set_title(\"Client \" + str(client_id) + \": Model accuracy\")\n    axis[0].set_ylabel('Accuracy')\n    axis[0].set_xlabel('Epoch')\n    axis[0].legend(['Train', 'Val'], loc='upper left')\n    # plt.show()\n    # Plot training & validation loss\n    axis[1].plot(epoch_range, history.history['loss'])\n    axis[1].plot(epoch_range, history.history['val_loss'])\n    axis[1].set_title(\"Client \" + str(client_id) + \": Model loss\")\n    axis[1].set_ylabel('Loss')\n    axis[1].set_xlabel('Epoch')\n    axis[1].legend(['Train', 'Val'], loc='upper left')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.001876Z","iopub.execute_input":"2023-05-20T15:43:11.002515Z","iopub.status.idle":"2023-05-20T15:43:11.022062Z","shell.execute_reply.started":"2023-05-20T15:43:11.002471Z","shell.execute_reply":"2023-05-20T15:43:11.020988Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":" #fournit un résumé de l'ensemble de données en imprimant sa taille, ses cinq premières entrées,\n# sa forme, ainsi qu'une vérification des valeurs nulles et un contrôle d'équilibrage de classes\ndef dataSet_summary(data):\n\n    print(data.size, \"entry in this Dataset\")\n    print(data.head())\n    print(data.shape)\n    print(\"Null values check : \")\n    print(\"\\n\", data.isnull().sum())\n    print(\"\\n \\nBalance check : \")\n\n    class_1 = data[data['income'] == '>50K']\n    class_0 = data[data['income'] == '<=50K']\n    ratio = min(class_0.size / class_1.size, class_1.size / class_0.size)\n    print(\"balance level : \", round(ratio, 5) * 100, \"%\")","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.023860Z","iopub.execute_input":"2023-05-20T15:43:11.024394Z","iopub.status.idle":"2023-05-20T15:43:11.042571Z","shell.execute_reply.started":"2023-05-20T15:43:11.024330Z","shell.execute_reply":"2023-05-20T15:43:11.041255Z"},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"# applique un codage binaire pour les colonnes spécifiées\ndef binary_encode(data, columns):\n\n    label_encoder = LabelEncoder()\n    for column in columns:\n        data[column] = label_encoder.fit_transform(data[column])\n    return data\n\n# Elle applique un codage one-hot pour les colonnes spécifiées\ndef onehot_encode(data, columns):\n    for column in columns:\n        dummies = pd.get_dummies(data[column])\n        data = pd.concat([data, dummies], axis=1)\n        data.drop(column, axis=1, inplace=True)\n\n    return data","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.047675Z","iopub.execute_input":"2023-05-20T15:43:11.048881Z","iopub.status.idle":"2023-05-20T15:43:11.057223Z","shell.execute_reply.started":"2023-05-20T15:43:11.048802Z","shell.execute_reply":"2023-05-20T15:43:11.056210Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"\n#Remplacer les '?' par np.NaN et Encoder les attributs de catégorie en attributs numériques\n#enlever les valeurs manquantes (NaN), retirer la colonne education, encoder les variables nominales avec un encodage one-hot\n# et encoder les variables binaires (Male, Female) en 0 et 1.\n# utilise la méthode LabelEncoder de la bibliothèque sklearn pour encoder la variable cible \"income\" en 0 et 1\ndef data_PreProcess(data):\n    \"\"\"\n    :param data:\n    :return: Data preprocessed -> Remplacer les valeurs en chaine de caractere par des colonnes\n    et les attributs binaires Male Female par des 0 et 1\n    Tranforme le label en 0 et en 1.\n    \"\"\"\n    data = data.replace('?', np.NaN)\n    data.drop('education', axis=1, inplace=True)\n    nominal_features = ['workclass', 'marital.status', 'occupation','race', 'relationship', 'native.country']\n    binary_features = ['sex']\n\n    data = onehot_encode(data, nominal_features)\n    data = binary_encode(data, binary_features)\n    # y = data['income']\n    # x = data.drop('income', axis=1)\n    # <= 50K ---> 0 et > 50K ---> 1\n    label_encoder = LabelEncoder()\n    # y = label_encoder.fit_transform(y)\n    data['income'] = label_encoder.fit_transform(data['income'])\n    # mapping de toutes les valeurs numériques vers l'intervalle [0, 1]\n    # normalized_x = (x - x.min()) / (x.max() - x.min())\n    normalized_data = (data - data.min()) / (data.max() - data.min())\n    # return pd.concat([normalized_x, y], axis=1)\n    return normalized_data","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.058597Z","iopub.execute_input":"2023-05-20T15:43:11.060029Z","iopub.status.idle":"2023-05-20T15:43:11.077223Z","shell.execute_reply.started":"2023-05-20T15:43:11.059968Z","shell.execute_reply":"2023-05-20T15:43:11.075640Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"\n# Le nombre d'individus échantillonnés est déterminé par la variable n_lines\n#renvoie un DataFrame contenant les données synthétiques échantillonnées\ndef Dirichelet_sampling(data, alphas, values, n_lines):\n    \"\"\"\n        Produit une dataset suivant la distribution de Dirichlet paramétrée par le vecteur alphas\n       sur les valeurs values\n        e.g. values = [Male, Female] --> Le nombre d'individus correspondant à Male et Female va suivre la\n        distrib Dir(alphas)\n    \"\"\"\n    # values = data[col].unique()\n    assert (n_lines <= len(data.axes[0]))\n    assert (len(values) == len(alphas))\n    print(len(data.axes[0]))\n    # sample a distribution from dir(alphas)\n    s = np.random.dirichlet(tuple(alphas), 1).tolist()[0]\n    print(s)\n    print(alphas)\n    groups = []\n    for i in range(len(values)):\n        if values[0] == 'Male' or values[0] == 'Female':\n            if round(n_lines * s[0]) > 0:\n                groups.append(data[data['sex'] == 1.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n            if round(n_lines * s[1]) > 0:\n                groups.append(data[data['sex'] == 0.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n        else:\n            if round(n_lines * s[i]) > 0:\n                groups.append(data[data[values[i]] == 1.0].sample(n=round(n_lines * s[i]), replace=True))\n            else:\n                groups.append(data[data[values[i]] == 1.0].sample(n=1))\n\n    return pd.concat(groups)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.078597Z","iopub.execute_input":"2023-05-20T15:43:11.079340Z","iopub.status.idle":"2023-05-20T15:43:11.092301Z","shell.execute_reply.started":"2023-05-20T15:43:11.079300Z","shell.execute_reply":"2023-05-20T15:43:11.091020Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"#découpe les données en client_dataset_size pièces et renvoie la token-ième pièce\n# splitting x into n_client pieces of size client_dataset_size rows\ndef dataset_slice(data, client_dataset_size, token):\n    \"\"\"\"\n        Fait un découpage simple de la dataset\n    \"\"\"\n    dataset_cols = len(data.axes[1])\n    d_client = data.iloc[token * client_dataset_size: (token + 1) * client_dataset_size, 0: dataset_cols]\n    return d_client","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.093898Z","iopub.execute_input":"2023-05-20T15:43:11.095222Z","iopub.status.idle":"2023-05-20T15:43:11.109635Z","shell.execute_reply.started":"2023-05-20T15:43:11.095173Z","shell.execute_reply":"2023-05-20T15:43:11.108334Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"#définit un modèle de réseau de neurones à deux couches cachées avec 16 neurones chacune, \n#une fonction d'activation ReLU\n# et une couche de sortie avec une fonction d'activation sigmoïde. \n#Le modèle est compilé avec l'optimiseur\n# Adam et une fonction de perte de cross-entropy binaire. \n#Trois métriques sont utilisées : l'accuracy, la précision et le rappel\ndef Adult_NN(input_shape):\n    inputs = tf.keras.Input(shape=input_shape)\n    x = tf.keras.layers.Dense(16, activation='relu')(inputs)\n    x = tf.keras.layers.Dense(16, activation='relu')(x)\n    outputs = tf.keras.layers.Dense(1, activation='relu')(x)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n    metrics = [\n        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n        tf.keras.metrics.Precision(name='Precision'),\n        tf.keras.metrics.Recall(name='recall')\n\n    ]\n\n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=metrics\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.111234Z","iopub.execute_input":"2023-05-20T15:43:11.111662Z","iopub.status.idle":"2023-05-20T15:43:11.130924Z","shell.execute_reply.started":"2023-05-20T15:43:11.111607Z","shell.execute_reply":"2023-05-20T15:43:11.129241Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"\n#Cette fonction crée un réseau de neurones dense avec quatre couches, chacune contenant 16 neurones.\n# La fonction d'activation utilisée est ReLU. Les poids et les biais sont initialisés à zéro. Le modèle est compilé avec\n# l'optimiseur Adamax et la perte est calculée avec la binary_crossentropy. Les métriques utilisées sont la BinaryAccuracy,\n# la Precision et le Recall\n# creer un model initialisé avec des poids nulls (ce model servira pour creer le modele global)\ndef Adult_NN_zero():\n    inputs = tf.keras.Input(shape=(88,))\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(inputs)\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n    outputs = tf.keras.layers.Dense(1, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    optimizer = tf.keras.optimizers.Adamax(learning_rate=0.00001)\n\n    metrics = [\n        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n        tf.keras.metrics.Precision(name='Precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=metrics\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.132519Z","iopub.execute_input":"2023-05-20T15:43:11.132974Z","iopub.status.idle":"2023-05-20T15:43:11.145713Z","shell.execute_reply.started":"2023-05-20T15:43:11.132931Z","shell.execute_reply":"2023-05-20T15:43:11.144850Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\n    True Positive Rate pour le calcul de EOD\n\"\"\"\n\n#calcule le taux de vrais positifs (TPR) pour un ensemble de données de test.\n# Le TPR est calculé en utilisant la classe TruePositives de Keras\n# doit etre égale a Recall\ndef compute_TPR(x_test, y_test, model):\n    tp_metric = tf.keras.metrics.TruePositives()\n    model.evaluate(x_test, y_test)\n    tp_metric.update_state(y_test, model.predict(x_test))\n    tp = tp_metric.result().numpy()\n    actual_positive = tf.math.count_nonzero(y_test == 1.0).numpy()\n    tpr = tp / actual_positive\n    return round(tpr, 3)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.147108Z","iopub.execute_input":"2023-05-20T15:43:11.147618Z","iopub.status.idle":"2023-05-20T15:43:11.165894Z","shell.execute_reply.started":"2023-05-20T15:43:11.147581Z","shell.execute_reply":"2023-05-20T15:43:11.164658Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\n    True Negative rates pour le calcul de EOD \n\"\"\"\n\n# Cette fonction calcule le taux de vrais négatifs (TNR) pour un ensemble de données de test.\n# Le TNR est calculé en utilisant la matrice de confusion\ndef compute_TNR(x_test, y_test, model):\n    y_pred = model.predict(x_test)\n    tn, fp, fn, tp = confusion_matrix(y_test, y_pred.argmax(axis=1)).ravel()\n    tnr = tn / (tn + fp)\n    return round(tnr, 3)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.167948Z","iopub.execute_input":"2023-05-20T15:43:11.169061Z","iopub.status.idle":"2023-05-20T15:43:11.179705Z","shell.execute_reply.started":"2023-05-20T15:43:11.169007Z","shell.execute_reply":"2023-05-20T15:43:11.178826Z"},"trusted":true},"execution_count":103,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\n    Proportions de prédictions Positives pour la calcul de PSD \n\"\"\"\n\n# calcule la proportion de prédictions positives (PP) pour un ensemble de données de test.\n# La PP est calculée en utilisant un seuil de décision de 0,5\ndef compute_PP(x_test, y_test, model):\n    y_pred = model.predict(x_test)\n    # Seuil entre décision poitive et décision négative.\n    positive_mask = tf.where(y_pred >= 0.5, 1, 0)\n    positive_count = np.count_nonzero(positive_mask)\n    total_count = y_pred.shape[0]\n    positive_proportion = positive_count / total_count\n    return round(positive_proportion, 3)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.180983Z","iopub.execute_input":"2023-05-20T15:43:11.182149Z","iopub.status.idle":"2023-05-20T15:43:11.205215Z","shell.execute_reply.started":"2023-05-20T15:43:11.182114Z","shell.execute_reply":"2023-05-20T15:43:11.203464Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"\n\"\"\"\n    Equal opportunity metric pour deux groupes P(\\hat{Y} = 1 | Y = 1, S=s_1) - P(\\hat{Y} = 1 | Y = 1, S=s_2)\n\"\"\"\n\n#calcule la métrique Equal Opportunity (EOD) pour deux groupes en fonction d'un attribut protégé et privilégié.\n# La métrique EOD est définie comme la différence entre le TPR du groupe privilégié et celui du groupe protégé\ndef EOD(model, x_client, y_client, protected, privileged):\n    if protected == 'Female' or privileged == 'Female':\n        protected_x = x_client[x_client['sex'] == 1.0]  # correspond a female\n        protected_y = y_client[x_client['sex'] == 1.0]\n\n        privileged_x = x_client[x_client['sex'] == 0.0]\n        privileged_y = y_client[x_client['sex'] == 0.0]\n\n    else:\n        protected_x = x_client[x_client[protected] == 1.0]\n        protected_y = y_client[x_client[protected] == 1.0]\n\n        privileged_x = x_client[x_client[privileged] == 1.0]\n        privileged_y = y_client[x_client[privileged] == 1.0]\n\n    tpr_protected = compute_TPR(protected_x, protected_y, model)\n    tpr_privilieged = compute_TPR(privileged_x, privileged_y, model)\n\n    # P(\\hat{Y} = 1 | Y = 1, S=s_1) - P(\\hat{Y} = 1 | Y = 1, S=s_2)\n    return tpr_privilieged - tpr_protected","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.206841Z","iopub.execute_input":"2023-05-20T15:43:11.207467Z","iopub.status.idle":"2023-05-20T15:43:11.223594Z","shell.execute_reply.started":"2023-05-20T15:43:11.207429Z","shell.execute_reply":"2023-05-20T15:43:11.222209Z"},"trusted":true},"execution_count":105,"outputs":[]},{"cell_type":"code","source":"\n#calcule la métrique de proportion de décisions positives égales (SPD) pour deux groupes en fonction d'un attribut\n# protégé et privilégié. La métrique SPD est définie comme la différence entre la PP du groupe privilégié et celle du groupe protégé\ndef SPD(model, x_client, y_client, protected, privileged):\n    if protected == 'Female' or privileged == 'Female':\n        protected_x = x_client[x_client['sex'] == 1.0]  # correspond a female\n        protected_y = y_client[x_client['sex'] == 1.0]\n\n        privileged_x = x_client[x_client['sex'] == 0.0]\n        privileged_y = y_client[x_client['sex'] == 0.0]\n    else:\n        protected_x = x_client[x_client[protected] == 1.0]\n        protected_y = y_client[x_client[protected] == 1.0]\n\n        privileged_x = x_client[x_client[privileged] == 1.0]\n        privileged_y = y_client[x_client[privileged] == 1.0]\n\n    pp_protected = compute_PP(protected_x, protected_y, model)\n    pp_privileged = compute_PP(privileged_x, privileged_y, model)\n    return pp_privileged - pp_protected","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.225170Z","iopub.execute_input":"2023-05-20T15:43:11.227035Z","iopub.status.idle":"2023-05-20T15:43:11.247633Z","shell.execute_reply.started":"2023-05-20T15:43:11.226964Z","shell.execute_reply":"2023-05-20T15:43:11.246482Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"\n#effectue l'apprentissage du modèle à partir de zéro sur un ensemble de données d'entraînement.\n# Elle divise l'ensemble de données en ensembles d'entraînement et de validation, entraîne le modèle sur l'ensemble d'entraînement,\n# et retourne le modèle entraîné.\n# La fonction prend également en entrée un identifiant de client (client_id)\ndef train(x, y, epch, client_id):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n    model = Adult_NN()\n    history = model.fit(x_train, y_train, validation_split=0.2, batch_size=32, epochs=epch, verbose=2)\n    plot_learningCurve(history, epch, client_id)\n    print(\"evaluation sur les données de test ...\")\n    model.evaluate(x_test, y_test)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.249068Z","iopub.execute_input":"2023-05-20T15:43:11.249857Z","iopub.status.idle":"2023-05-20T15:43:11.273021Z","shell.execute_reply.started":"2023-05-20T15:43:11.249812Z","shell.execute_reply":"2023-05-20T15:43:11.271164Z"},"trusted":true},"execution_count":107,"outputs":[]},{"cell_type":"code","source":"\n#effectue l'apprentissage du modèle à partir d'un modèle pré-entraîné. Elle divise l'ensemble de données en ensembles\n# d'entraînement et de validation, ajuste le modèle pré-entraîné sur l'ensemble d'entraînement, et retourne le modèle ajusté.\n# La fonction prend également en entrée un identifiant de client (client_id).\ndef train_from_model(model, x, y, epch, client_id):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n    history = model.fit(x_train, y_train, validation_split=0.2, batch_size=32, epochs=epch, verbose=1)\n    plot_learningCurve(history, epch, client_id)\n    model.evaluate(x_test, y_test)\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.274458Z","iopub.execute_input":"2023-05-20T15:43:11.275047Z","iopub.status.idle":"2023-05-20T15:43:11.288810Z","shell.execute_reply.started":"2023-05-20T15:43:11.275010Z","shell.execute_reply":"2023-05-20T15:43:11.287598Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"# def ML_train_from_model(model, x, y, epch, client_id):\n#     x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n#     history = model.fit(x_train, y_train)\n#     plot_learningCurve(history, epch, client_id)\n#     model.evaluate(x_test, y_test)\n#     return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.292722Z","iopub.execute_input":"2023-05-20T15:43:11.293289Z","iopub.status.idle":"2023-05-20T15:43:11.311367Z","shell.execute_reply.started":"2023-05-20T15:43:11.293249Z","shell.execute_reply":"2023-05-20T15:43:11.309859Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"# La fonction multiplie chaque élément de \"weight\" par \"scalar\" et retourne le résultat sous la forme d'une liste\ndef scale_model_weights(weight, scalar):\n    '''function for scaling a models weights'''\n    weight_final = []\n    steps = len(weight)\n    for i in range(steps):\n        weight_final.append(scalar * weight[i])\n    return weight_final","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.314048Z","iopub.execute_input":"2023-05-20T15:43:11.314505Z","iopub.status.idle":"2023-05-20T15:43:11.327157Z","shell.execute_reply.started":"2023-05-20T15:43:11.314456Z","shell.execute_reply":"2023-05-20T15:43:11.325545Z"},"trusted":true},"execution_count":110,"outputs":[]},{"cell_type":"code","source":"# Cette méthode prend une liste de poids d'un modèle multipliée par le facteur d'échelle et renvoie la somme pondérée\n# de ces poids. Elle calcule d'abord la moyenne des poids de chaque couche des modèles clients\n# Ensuite, elle somme les moyennes de chaque couche pour obtenir la somme pondérée de ces poids\ndef sum_scaled_weights(scaled_weight_list):\n    '''Return la somme des weights multipliés par le facteur de scaling'''\n    avg_grad = list()\n    # get the average grad accross all client gradients\n    for grad_list_tuple in zip(*scaled_weight_list):\n        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n        avg_grad.append(layer_mean)\n\n    return avg_grad","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.330344Z","iopub.execute_input":"2023-05-20T15:43:11.330858Z","iopub.status.idle":"2023-05-20T15:43:11.341020Z","shell.execute_reply.started":"2023-05-20T15:43:11.330817Z","shell.execute_reply":"2023-05-20T15:43:11.340131Z"},"trusted":true},"execution_count":111,"outputs":[]},{"cell_type":"code","source":"#Cette méthode prend en entrée une liste de modèles models, le nombre total de clients n,\n# une liste de poids de clients clients_weights et la forme de l'entrée input_shape.\n# Elle calcule les poids moyens de tous les modèles pondérés en fonction du poids de chaque client en utilisant\n# la méthode sum_scaled_weights() définie précédemment\n# Elle crée un nouveau modèle avec les poids moyens calculés et renvoie ce modèle\n\ndef FedAvg(models, n, clients_weights, input_shape): #input_shape =(nbre features, none)\n    scaled_weights = []\n\n    global_model = Adult_NN(input_shape)\n    for i in range(n):\n        scaled_weights.append(scale_model_weights(models[i].get_weights(), clients_weights[i]))  # multiplier chaque modele avec son weight\n\n    avg_weights = sum_scaled_weights(scaled_weights)\n\n    global_model.set_weights(avg_weights)\n    return global_model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.342375Z","iopub.execute_input":"2023-05-20T15:43:11.342903Z","iopub.status.idle":"2023-05-20T15:43:11.364953Z","shell.execute_reply.started":"2023-05-20T15:43:11.342870Z","shell.execute_reply":"2023-05-20T15:43:11.363270Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"\n#Cette méthode calcule les valeurs d'égalité des chances et de parité statistique pour chaque paire d'attributs sensibles.\n# Elle crée un diagramme à barres pour afficher ces valeurs et renvoie l'objet matplotlib.pyplot correspondant.\ndef plot_Fairness_Values(model, x_client, y_client, sensitive_attr, model_id, iteration):\n    eod_values = []\n    spd_values = []\n    labels = []\n\n    width = 0.15  # the width of the bars\n    multiplier = 0\n\n    fig, ax = plt.subplots(layout='constrained')\n    for i in range(len(sensitive_attr)):\n        for j in range(i, len(sensitive_attr)):\n            if sensitive_attr[i] != sensitive_attr[j]:\n                labels.append(sensitive_attr[i] + '/' + sensitive_attr[j])\n                eod_values.append(EOD(model, x_client, y_client, sensitive_attr[i], sensitive_attr[j]))\n                spd_values.append(SPD(model, x_client, y_client, sensitive_attr[i], sensitive_attr[j]))\n            #    offset = width * multiplier\n    x_axis = np.arange(len(labels))\n    rects = ax.bar(x_axis - 0.1, eod_values, 0.10, label='EOD')\n    ax.bar_label(rects, padding=3)\n    rects = ax.bar(x_axis + 0.1, spd_values, 0.10, label='SPD')\n    ax.bar_label(rects, padding=3)\n    ax.axhline(y=0.0, color='r', linestyle='-')\n    multiplier += 1\n\n    # plots\n    x_locations = np.arange(len(eod_values))  # the label locations\n    ax.set_ylabel('Valeurs')\n    ax.set_title(\n        'Equal opportunity / Statistical Parity sur les differents groupes [Model : ' + model_id + ', iteration : ' + iteration + ']')\n    ax.set_xticks(x_locations + width, labels, rotation=45)\n    ax.legend(loc='upper left', )\n    ax.set_ylim(-1, 1)\n    return plt","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.366781Z","iopub.execute_input":"2023-05-20T15:43:11.367461Z","iopub.status.idle":"2023-05-20T15:43:11.381285Z","shell.execute_reply.started":"2023-05-20T15:43:11.367410Z","shell.execute_reply":"2023-05-20T15:43:11.380048Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"\n#Cette méthode calcule les valeurs d'égalité des chances et de parité statistique pour chaque paire d'attributs sensibles.\n# Elle crée un diagramme à barres pour afficher ces valeurs et renvoie l'objet matplotlib.pyplot correspondant.\ndef plot_Fairness_Values(model, x_client, y_client, sensitive_attr, model_id, iteration):\n    eod_values = []\n    spd_values = []\n    labels = []\n\n    width = 0.15  # the width of the bars\n    multiplier = 0\n\n    fig, ax = plt.subplots(layout='constrained')\n    for i in range(len(sensitive_attr)):\n        for j in range(i, len(sensitive_attr)):\n            if sensitive_attr[i] != sensitive_attr[j]:\n                labels.append(sensitive_attr[i] + '/' + sensitive_attr[j])\n                eod_values.append(EOD(model, x_client, y_client, sensitive_attr[i], sensitive_attr[j]))\n                spd_values.append(SPD(model, x_client, y_client, sensitive_attr[i], sensitive_attr[j]))\n            #    offset = width * multiplier\n    x_axis = np.arange(len(labels))\n    rects = ax.bar(x_axis - 0.1, eod_values, 0.10, label='EOD')\n    ax.bar_label(rects, padding=3)\n    rects = ax.bar(x_axis + 0.1, spd_values, 0.10, label='SPD')\n    ax.bar_label(rects, padding=3)\n    ax.axhline(y=0.0, color='r', linestyle='-')\n    multiplier += 1\n\n    # plots\n    x_locations = np.arange(len(eod_values))  # the label locations\n    ax.set_ylabel('Valeurs')\n    ax.set_title(\n        'Equal opportunity / Statistical Parity sur les differents groupes [Model : ' + model_id + ', iteration : ' + iteration + ']')\n    ax.set_xticks(x_locations + width, labels, rotation=45)\n    ax.legend(loc='upper left', )\n    ax.set_ylim(-1, 1)\n    return plt","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.386865Z","iopub.execute_input":"2023-05-20T15:43:11.387195Z","iopub.status.idle":"2023-05-20T15:43:11.406516Z","shell.execute_reply.started":"2023-05-20T15:43:11.387159Z","shell.execute_reply":"2023-05-20T15:43:11.405555Z"},"trusted":true},"execution_count":114,"outputs":[]},{"cell_type":"code","source":"\n# crée un dictionnaire alphas contenant quatre valeurs différentes pour les facteurs d'échelle :\n# extremely homogeneous, very homogeneous, homogeneous et uniform.\n# Ces valeurs seront utilisées pour pondérer les poids des clients lors du calcul des poids moyens dans la méthode FedAvg()\n\n# La fonction extrait deux sous-ensembles de données \"attr_elements\" et \"non_attr_elements\" en fonction\n# de la valeur de \"attribute\". Elle compte ensuite le nombre d'éléments ayant un revenu positif dans chacun de\n# ces sous-ensembles, puis retourne un\n# tuple contenant le rapport de ces comptages par rapport à \"val_1\" et \"val_0\", respectivement\n# Retourne (P(Y=1 | S = 1), P(Y=1 | S = 0))\ndef positives_prop(data, val_1, val_0, attribute):\n    if attribute == 'Female':\n        attr_elements = data[data['sex'] == 1.0]\n        non_attr_elements = data[data['sex'] == 0.0]\n    else:\n        attr_elements = data[data[attribute] == 1.0]\n        non_attr_elements = data[data[attribute] == 0.0]\n    positive_attr_elements = attr_elements[attr_elements['income'] == 1.0]\n    positive_non_attr_elements = non_attr_elements[non_attr_elements['income'] == 1.0]\n    return (((len(positive_attr_elements.axes[0]) / len(data.axes[0])) / val_1),\n            ((len(positive_non_attr_elements.axes[0]) / len(data.axes[0])) / val_0))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.407661Z","iopub.execute_input":"2023-05-20T15:43:11.408301Z","iopub.status.idle":"2023-05-20T15:43:11.432206Z","shell.execute_reply.started":"2023-05-20T15:43:11.408271Z","shell.execute_reply":"2023-05-20T15:43:11.430794Z"},"trusted":true},"execution_count":115,"outputs":[]},{"cell_type":"code","source":"\n# prend en entrée un modèle \"model\", un dictionnaire \"d_client\", une chaîne de caractères \"attribute\" et\n# deux valeurs \"val_1\" et \"val_0\". La fonction extrait le vecteur de cibles \"y_test\" et la matrice de données\n# \"x_test\" à partir de \"d_clients\". Elle calcule ensuite les prédictions positives pour les deux groupes définis\n# par \"attribute\" à l'aide de la fonction \"compute_PP\", puis appelle la fonction \"positives_prop\" pour obtenir les\n# proportions positives. Enfin, la fonction calcule et\n# retourne la différence entre les produits des proportions positives et des prédictions positives pour les deux groupes.\ndef compute_mkGlobal(model, d_client, attribute, val_1, val_0):\n    y_test = d_clients[i]['income']\n    x_test = d_clients[i].drop('income', axis=1)\n\n    pp_gr1 = compute_PP(x_test[x_test[attribute] == 1.0], y_test[x_test[attribute] == 1.0], model)\n    pp_gr0 = compute_PP(x_test[x_test[attribute] == 0.0], y_test[x_test[attribute] == 0.0], model)\n\n    (term_gr1, term_gr0) = positives_prop(d_client, val_1, val_0, attribute)\n\n    return (pp_gr1 * term_gr1 - pp_gr0 * pp_gr0)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.433551Z","iopub.execute_input":"2023-05-20T15:43:11.434223Z","iopub.status.idle":"2023-05-20T15:43:11.454652Z","shell.execute_reply.started":"2023-05-20T15:43:11.434187Z","shell.execute_reply":"2023-05-20T15:43:11.453075Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/adult-census-income/adult.csv')\ndata.replace('?', np.NaN)\ndataSet_summary(data)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.458085Z","iopub.execute_input":"2023-05-20T15:43:11.458564Z","iopub.status.idle":"2023-05-20T15:43:11.553611Z","shell.execute_reply.started":"2023-05-20T15:43:11.458516Z","shell.execute_reply":"2023-05-20T15:43:11.552201Z"},"trusted":true},"execution_count":117,"outputs":[{"name":"stdout","text":"488415 entry in this Dataset\n   age workclass  fnlwgt     education  education.num marital.status  \\\n0   90         ?   77053       HS-grad              9        Widowed   \n1   82   Private  132870       HS-grad              9        Widowed   \n2   66         ?  186061  Some-college             10        Widowed   \n3   54   Private  140359       7th-8th              4       Divorced   \n4   41   Private  264663  Some-college             10      Separated   \n\n          occupation   relationship   race     sex  capital.gain  \\\n0                  ?  Not-in-family  White  Female             0   \n1    Exec-managerial  Not-in-family  White  Female             0   \n2                  ?      Unmarried  Black  Female             0   \n3  Machine-op-inspct      Unmarried  White  Female             0   \n4     Prof-specialty      Own-child  White  Female             0   \n\n   capital.loss  hours.per.week native.country income  \n0          4356              40  United-States  <=50K  \n1          4356              18  United-States  <=50K  \n2          4356              40  United-States  <=50K  \n3          3900              40  United-States  <=50K  \n4          3900              40  United-States  <=50K  \n(32561, 15)\nNull values check : \n\n age               0\nworkclass         0\nfnlwgt            0\neducation         0\neducation.num     0\nmarital.status    0\noccupation        0\nrelationship      0\nrace              0\nsex               0\ncapital.gain      0\ncapital.loss      0\nhours.per.week    0\nnative.country    0\nincome            0\ndtype: int64\n\n \nBalance check : \nbalance level :  31.719 %\n","output_type":"stream"}]},{"cell_type":"code","source":"attributes = {\n       'race': data['race'].unique(),\n       'sex': data['sex'].unique(),\n       'relationship' : data['relationship'].unique(),\n       'occupation' : data['occupation'].unique(),\n       'marital.status': data['marital.status'].unique()\n    }\npre_processed_data = data_PreProcess(data)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.555028Z","iopub.execute_input":"2023-05-20T15:43:11.555490Z","iopub.status.idle":"2023-05-20T15:43:11.700551Z","shell.execute_reply.started":"2023-05-20T15:43:11.555453Z","shell.execute_reply":"2023-05-20T15:43:11.699094Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"# Nombre de FL clients / iterations / epochs\nlearning_iterations = 5\nn_clients = 3\nepochs = 120","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.702069Z","iopub.execute_input":"2023-05-20T15:43:11.702463Z","iopub.status.idle":"2023-05-20T15:43:11.709629Z","shell.execute_reply.started":"2023-05-20T15:43:11.702423Z","shell.execute_reply":"2023-05-20T15:43:11.708060Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"# Definir l'attribut sur lequel l'analyse de l'équité sera faite\nattribute_to_manipulate = 'race'\ndataset_rows = len(data.axes[0])\nclient_dataset_size = round(dataset_rows / n_clients)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.711470Z","iopub.execute_input":"2023-05-20T15:43:11.711833Z","iopub.status.idle":"2023-05-20T15:43:11.723252Z","shell.execute_reply.started":"2023-05-20T15:43:11.711794Z","shell.execute_reply":"2023-05-20T15:43:11.722125Z"},"trusted":true},"execution_count":120,"outputs":[]},{"cell_type":"code","source":"# Données à enregistrer dans le fichier CSV\nheader = []\n# Ouvrir le fichier CSV en mode écriture\nwith open(\"fichier.csv\", 'w', newline='') as csvfile:\n        # Créer un objet csv.writer\n        writer = csv.writer(csvfile)\n\n        # Écrire l'en-tête\n        writer.writerow(header)\n\n        # Écrire les données\n        writer.writerows(data)\n\n        # Fermer le fichier\n        csvfile.close()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.724961Z","iopub.execute_input":"2023-05-20T15:43:11.725268Z","iopub.status.idle":"2023-05-20T15:43:11.735901Z","shell.execute_reply.started":"2023-05-20T15:43:11.725238Z","shell.execute_reply":"2023-05-20T15:43:11.734810Z"},"trusted":true},"execution_count":121,"outputs":[]},{"cell_type":"code","source":"pre_processed_data.race.unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:44:07.092994Z","iopub.execute_input":"2023-05-20T15:44:07.093348Z","iopub.status.idle":"2023-05-20T15:44:07.100440Z","shell.execute_reply.started":"2023-05-20T15:44:07.093314Z","shell.execute_reply":"2023-05-20T15:44:07.099474Z"},"trusted":true},"execution_count":126,"outputs":[{"execution_count":126,"output_type":"execute_result","data":{"text/plain":"array([1.  , 0.5 , 0.25, 0.75, 0.  ])"},"metadata":{}}]},{"cell_type":"code","source":"# Un jeu de parametres de la dstrib de dirichelet (alphas). selon des degrès d'homogenité\nalphas = create_alphas(len(data[attribute_to_manipulate].unique()))\nd_clients = []\ndisplay = 1\n# Ces deux valeurs correspondent a P(Y = 1 | A = 1) et P(Y = 1 | A = 0)\n(positive_prop_attr, positive_prop_non_attr) = positives_prop(pre_processed_data, 1, 1, 'White')","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.737335Z","iopub.execute_input":"2023-05-20T15:43:11.737638Z","iopub.status.idle":"2023-05-20T15:43:11.874131Z","shell.execute_reply.started":"2023-05-20T15:43:11.737609Z","shell.execute_reply":"2023-05-20T15:43:11.872689Z"},"trusted":true},"execution_count":122,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'White'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_28/4170058766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ces deux valeurs correspondent a P(Y = 1 | A = 1) et P(Y = 1 | A = 0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mpositive_prop_attr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_prop_non_attr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositives_prop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_processed_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'White'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_28/2194219333.py\u001b[0m in \u001b[0;36mpositives_prop\u001b[0;34m(data, val_1, val_0, attribute)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mnon_attr_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sex'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mattr_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mnon_attr_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mpositive_attr_elements\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_elements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mattr_elements\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'White'"],"ename":"KeyError","evalue":"'White'","output_type":"error"}]},{"cell_type":"code","source":"import math\n\ndef check_balance(data, attributes):\n    count = 0\n    n_subplots = len(attributes.keys())\n    n_cols = 1\n    n_rows = n_subplots\n    if n_subplots > 3:\n        n_cols = math.ceil(n_subplots/3)\n        n_rows = 3\n\n    plt.rcdefaults()\n    fig, ax = plt.subplots(n_rows, n_cols, figsize=(20, 14))\n    for column in attributes.keys():\n        if n_cols == 1:\n            # If there's only one column, use a one-dimensional array of subplots\n            curr_ax = ax[count]\n        else:\n            # If there's more than one column, use a two-dimensional array of subplots\n            curr_ax = ax[count // n_cols, count % n_cols]\n\n        values = attributes[column]\n        rates = []\n        # l'attribit sex est traité différemment\n        if column == 'sex':\n            rate = 100 * round(data[data['sex'] == 1.0].size / data.size, 2)\n            rates.append(rate)\n            print(\"Male rate is : \" + str(rate))\n            rate = 100 * round(data[data['sex'] == 0.0].size / data.size, 2)\n            rates.append(rate)\n            print(\"Female rate is : \" + str(rate))\n            values = ['Male', 'Female']\n        else:\n            for j in range(len(values)):\n                if values[j] != '?':\n                    rate = 100 * round(data[data[values[j]] == 1.0].size / data.size, 2)\n                    rates.append(rate)\n                    print(str(values[j]) + \" rate is : \", str(rate))\n                else:\n                    rates.append(0.0)\n\n        y_pos = np.arange(len(values))\n        error = np.random.rand(len(values))\n        curr_ax.barh(y_pos, rates, xerr=error, align='center')\n        curr_ax.set_yticks(y_pos, labels=values)\n        curr_ax.invert_yaxis()  # labels read top-to-bottom\n        if count == (len(attributes.keys()) - 1):\n            curr_ax.set_xlabel('Taux')\n        curr_ax.set_title('La distribution des valeurs pour \"' + column + '\"')\n        count += 1\n\n    return plt","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:44:19.646321Z","iopub.execute_input":"2023-05-20T15:44:19.646804Z","iopub.status.idle":"2023-05-20T15:44:19.663577Z","shell.execute_reply.started":"2023-05-20T15:44:19.646759Z","shell.execute_reply":"2023-05-20T15:44:19.661065Z"},"trusted":true},"execution_count":127,"outputs":[]},{"cell_type":"code","source":"#Créer un échantillon de Dirichlet pour chaque client, qui servira à\n# créer un ensemble de données d'entraînement pour chaque client\nfor i in range(n_clients):\n        d_clients.append(\n            Dirichelet_sampling(pre_processed_data, alphas['heterogeneous_2'], data[attribute_to_manipulate].unique(), # Dirichelet_sampling(data, alphas, values, n_lines)\n                                client_dataset_size))\n        print(\"\\nClient \", i, \" groups distribution : \")\n        curr_client_distrib = check_balance(d_clients[i], attributes)\n        if display:\n            curr_client_distrib.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:44:23.329514Z","iopub.execute_input":"2023-05-20T15:44:23.330176Z","iopub.status.idle":"2023-05-20T15:44:23.464349Z","shell.execute_reply.started":"2023-05-20T15:44:23.330117Z","shell.execute_reply":"2023-05-20T15:44:23.462893Z"},"trusted":true},"execution_count":128,"outputs":[{"name":"stdout","text":"32561\n[0.09466306018961759, 0.17499935359123914, 0.44630160045436407, 0.2310230002411319, 0.05301298552364727]\n[0.5, 0.5, 0.5, 0.5, 0.5]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'White'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_28/1020819185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m         d_clients.append(\n\u001b[1;32m      5\u001b[0m             Dirichelet_sampling(pre_processed_data, alphas['heterogeneous_2'], data[attribute_to_manipulate].unique(), # Dirichelet_sampling(data, alphas, values, n_lines)\n\u001b[0;32m----> 6\u001b[0;31m                                 client_dataset_size))\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nClient \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\" groups distribution : \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mcurr_client_distrib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_balance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_clients\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_28/1887976425.py\u001b[0m in \u001b[0;36mDirichelet_sampling\u001b[0;34m(data, alphas, values, n_lines)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_lines\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_lines\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                 \u001b[0mgroups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3458\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3459\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3460\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'White'"],"ename":"KeyError","evalue":"'White'","output_type":"error"}]},{"cell_type":"code","source":"def deep_NN(input_shape):\n    inputs = tf.keras.Input(shape=input_shape)\n    x = tf.keras.layers.Dense(128, activation='relu')(inputs)\n    x = tf.keras.layers.Dense(64, activation='relu')(x)\n    x = tf.keras.layers.Dense(32, activation='linear')(x)\n    x = tf.keras.layers.Dense(16, activation='linear')(x)\n    x = tf.keras.layers.Dense(8, activation='linear')(x)\n    outputs = tf.keras.layers.Dense(1, activation='relu')(x)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n    metrics = [\n        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n        tf.keras.metrics.Precision(name='Precision'),\n        tf.keras.metrics.Recall(name='recall')\n\n    ]\n\n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=metrics\n    )\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.879015Z","iopub.status.idle":"2023-05-20T15:43:11.879350Z","shell.execute_reply.started":"2023-05-20T15:43:11.879184Z","shell.execute_reply":"2023-05-20T15:43:11.879204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from aif360.datasets import BinaryLabelDataset\nfrom aif360.algorithms.preprocessing import Reweighing\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\ndef re(X_train,y_train_df):\n    train_dataset = BinaryLabelDataset(df=X_train.join(y_train_df), label_names=['income'], \n                                   protected_attribute_names=['race', 'sex'], \n                                   favorable_label=1, unfavorable_label=0)\n    privileged_groups = [{'race': 1}]  # Remplacez par vos propres valeurs\n    unprivileged_groups = [{'race': 0}]  # Remplacez par vos propres valeurs\n\n    # Application de la méthode de reweighing\n    rw = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n    train_dataset_reweighed = rw.fit_transform(train_dataset)\n    return train_dataset_reweighed ","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.880561Z","iopub.status.idle":"2023-05-20T15:43:11.880944Z","shell.execute_reply.started":"2023-05-20T15:43:11.880727Z","shell.execute_reply":"2023-05-20T15:43:11.880778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_client.columns","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.882107Z","iopub.status.idle":"2023-05-20T15:43:11.882454Z","shell.execute_reply.started":"2023-05-20T15:43:11.882270Z","shell.execute_reply":"2023-05-20T15:43:11.882288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Main loop\nepochs=2\nfor j in range(learning_iterations):\n        models = []\n        metric_values = []\n        mk_global_gr = []\n        for i in range(n_clients):\n            # n_client = 1 apprentissage centralisé.\n            if n_clients == 1:\n                d_client = pre_processed_data\n\n            y_client = d_clients[i]['income']\n            x_client = d_clients[i].drop('income', axis=1)\n            \n            d_clients_re=re(x_client,y_client)\n            y_client = d_clients_re[i]['income']\n            x_client = d_clients_re[i].drop('income', axis=1)\n            shape = (None, x_client.shape[1])\n\n            if j == 0:\n                models.append(train_from_model(Adult_NN(shape), x_client, y_client, epochs, i + 1))\n            else:\n                models.append(train_from_model(Adult_NN(shape), x_client, y_client,epochs, i + 1))\n\n            # calcul de la métrique EOD pour les groupes White Black\n            print(\"\\n\\n(Local) Fairness analysis : \")\n\n            fairness_plot = plot_Fairness_Values(models[i], x_client, y_client, data[attribute_to_manipulate].unique(),\n                                                str(i + 1), str(j + 1))\n#             group_plot = Eval_group_fairness(models[i], x_client, y_client, data[attribute_to_manipulate].unique(),\n#                                             str(i + 1), str(j + 1))\n            if display:\n                fairness_plot.show()\n\n#             if display:\n#                 group_plot.show()\n\n\n        # Agggregate pour vanilla FedAvg\n        FedAvg_global_model = FedAvg(models, n_clients, clients_weights=[1 / n_clients for i in range(n_clients)],\n                                     input_shape=shape)\n        # tester le model global sur\n        y = pre_processed_data['income']\n        x = pre_processed_data.drop('income', axis=1)\n        print(\"Global model [FedAvg] evaluation : \")\n        FedAvg_global_model.evaluate(x, y, verbose=2)\n        print(\"\\n\\n(Gloal) Fairness analysis : \")\n\n#         groups_plot1 = Eval_group_fairness(FedAvg_global_model, x, y, data[attribute_to_manipulate].unique(),\n#                                           'Global model with FairFed agg', str(j + 1))\n        fairness_plot1 = plot_Fairness_Values(FedAvg_global_model, x, y, data[attribute_to_manipulate].unique(),\n                                             'Global model with FairFed agg', str(j + 1))\n#         if display:\n#             groups_plot1.show()\n        if display:\n            fairness_plot1.show() ","metadata":{"execution":{"iopub.status.busy":"2023-05-20T15:43:11.883617Z","iopub.status.idle":"2023-05-20T15:43:11.883979Z","shell.execute_reply.started":"2023-05-20T15:43:11.883797Z","shell.execute_reply":"2023-05-20T15:43:11.883816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}