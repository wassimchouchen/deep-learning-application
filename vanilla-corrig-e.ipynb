{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-25T18:20:07.837553Z","iopub.execute_input":"2023-05-25T18:20:07.838133Z","iopub.status.idle":"2023-05-25T18:20:07.857781Z","shell.execute_reply.started":"2023-05-25T18:20:07.838094Z","shell.execute_reply":"2023-05-25T18:20:07.856358Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"/kaggle/input/adult-census-income/adult.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install flwr","metadata":{"execution":{"iopub.status.busy":"2023-05-25T18:20:07.859379Z","iopub.execute_input":"2023-05-25T18:20:07.860359Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Requirement already satisfied: flwr in /opt/conda/lib/python3.10/site-packages (1.4.0)\nRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (1.23.5)\nRequirement already satisfied: iterators<0.0.3,>=0.0.2 in /opt/conda/lib/python3.10/site-packages (from flwr) (0.0.2)\nRequirement already satisfied: grpcio!=1.52.0,<2.0.0,>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from flwr) (1.53.0)\nRequirement already satisfied: protobuf<4.0.0,>=3.19.0 in /opt/conda/lib/python3.10/site-packages (from flwr) (3.20.3)\n","output_type":"stream"}]},{"cell_type":"code","source":"import errno\n\nimport tensorflow as tf\nfrom tensorflow import initializers\nfrom tensorflow.keras import backend as K\nimport sklearn\nfrom tensorflow import keras\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.layers import Conv1D, MaxPool1D\nfrom tensorflow.keras.optimizers import Adam\n\nimport random\nimport pandas as pd\nimport numpy as np\nimport math\nimport os\nimport flwr as fl\nimport array\nfrom scipy.stats import dirichlet\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\n\nfrom imblearn.over_sampling import SMOTE\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# créer un graphique à deux sous-graphiques pour tracer l'évolution\n# de  (accuracy) et de la perte (loss) du modèle au cours de l'entraînement\n# Plot training & validation accuracy values\ndef plot_learningCurve(history, epoch, client_id):\n    # Plot training & validation accuracy values\n    epoch_range = range(1, epoch + 1)\n\n    figure, axis = plt.subplots(2, 1)\n\n    axis[0].plot(epoch_range, history.history['accuracy'])\n    axis[0].plot(epoch_range, history.history['val_accuracy'])\n    axis[0].set_title(\"Client \" + str(client_id) + \": Model accuracy\")\n    axis[0].set_ylabel('Accuracy')\n    axis[0].set_xlabel('Epoch')\n    axis[0].legend(['Train', 'Val'], loc='upper left')\n    # plt.show()\n\n    # Plot training & validation loss\n    axis[1].plot(epoch_range, history.history['loss'])\n    axis[1].plot(epoch_range, history.history['val_loss'])\n    axis[1].set_title(\"Client \" + str(client_id) + \": Model loss\")\n    axis[1].set_ylabel('Loss')\n    axis[1].set_xlabel('Epoch')\n    axis[1].legend(['Train', 'Val'], loc='upper left')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n #fournit un résumé de l'ensemble de données en imprimant sa taille, ses cinq premières entrées,\n# sa forme, ainsi qu'une vérification des valeurs nulles et un contrôle d'équilibrage de classes\ndef dataSet_summary(data):\n    print(data.size, \"entry in this Dataset\")\n    print(data.head())\n    print(data.shape)\n    print(\"Null values check : \")\n    print(\"\\n\", data.isnull().sum())\n    print(\"\\n \\nBalance check : \")\n\n    class_1 = data[data['income'] == '>50K']\n    class_0 = data[data['income'] == '<=50K']\n    ratio = min(class_0.size / class_1.size, class_1.size / class_0.size)\n    print(\"balance level : \", round(ratio, 5) * 100, \"%\")\n\n\n\"\"\"\"\nattributes est un dictionnaire dont les clés sont les noms des colonnes sont les valeurs possibles\n\"\"\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\n# crée un graphique à trois sous-graphiques pour visualiser\n# la distribution des valeurs de chaque attribut en pourcentage\n\ndef check_balance(data, attributes):\n    count = 0\n    plt.rcdefaults()\n    fig, ax = plt.subplots(3, 1)\n    for column in attributes.keys():\n        values = attributes[column]\n        rates = []\n        # l'attribit sex est traité différemment\n        if column == 'sex':\n            rate = 100 * round(data[data['sex'] == 1.0].size / data.size, 2)\n            rates.append(rate)\n            print(\"Male rate is : \" + str(rate))\n            rate = 100 * round(data[data['sex'] == 0.0].size / data.size, 2)\n            rates.append(rate)\n            print(\"Female rate is : \" + str(rate))\n            values = ['Male', 'Female']\n        else:\n            for j in range(len(values)):\n                if values[j] != '?':\n                    rate = 100 * round(data[data[values[j]] == 1.0].size / data.size, 2)\n                    rates.append(rate)\n                    print(str(values[j]) + \" rate is : \", str(rate))\n                else:\n                    rates.append(0.0)\n\n        y_pos = np.arange(len(values))\n        error = np.random.rand(len(values))\n        ax[count].barh(y_pos, rates, xerr=error, align='center')\n        ax[count].set_yticks(y_pos, labels=values)\n        ax[count].invert_yaxis()  # labels read top-to-bottom\n        if count == (len(attributes.keys()) - 1):\n            ax[count].set_xlabel('Taux')\n        ax[count].set_title('La distribution des valeurs pour \"' + column + '\"')\n        count += 1\n    return plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# applique un codage binaire pour les colonnes spécifiées\ndef binary_encode(data, columns):\n    label_encoder = LabelEncoder()\n    for column in columns:\n        data[column] = label_encoder.fit_transform(data[column])\n    return data\n\n\ndef onehot_encode(data, columns):\n    for column in columns:\n        dummies = pd.get_dummies(data[column])\n        data = pd.concat([data, dummies], axis=1)\n        data.drop(column, axis=1, inplace=True)\n\n    return data\n\n\n\"\"\"\n    Remplacer les '?' par np.NaN et Encoder les attributs de catégorie en attributs numériques  \n\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Remplacer les '?' par np.NaN et Encoder les attributs de catégorie en attributs numériques\n#enlever les valeurs manquantes (NaN), retirer la colonne education, encoder les variables nominales avec un encodage one-hot\n# et encoder les variables binaires (Male, Female) en 0 et 1.\n# utilise la méthode LabelEncoder de la bibliothèque sklearn pour encoder la variable cible \"income\" en 0 et 1\n\ndef data_PreProcess(data):\n    \"\"\"\n    :param data:\n    :return: Data preprocessed -> Remplacer les valeurs en chaine de caractere par des colonnes\n    et les attributs binaires Male Female par des 0 et 1\n    Tranforme le label en 0 et en 1.\n    \"\"\"\n    data = data.replace('?', np.NaN)\n    data.drop('education', axis=1, inplace=True)\n    nominal_features = ['workclass', 'marital.status', 'occupation', 'relationship', 'native.country']\n    binary_features = ['sex']\n\n    data = onehot_encode(data, nominal_features)\n    data = binary_encode(data, binary_features)\n    # y = data['income']\n    # x = data.drop('income', axis=1)\n    # <= 50K ---> 0 et > 50K ---> 1\n    label_encoder = LabelEncoder()\n    # y = label_encoder.fit_transform(y)\n    data['income'] = label_encoder.fit_transform(data['income'])\n    # mapping de toutes les valeurs numériques vers l'intervalle [0, 1]\n    # normalized_x = (x - x.min()) / (x.max() - x.min())\n    normalized_data = (data - data.min()) / (data.max() - data.min())\n    # return pd.concat([normalized_x, y], axis=1)\n    return normalized_data\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Le nombre d'individus échantillonnés est déterminé par la variable n_lines\n#renvoie un DataFrame contenant les données synthétiques échantillonnées\ndef Dirichelet_sampling(data, alphas, values, n_lines):\n    \"\"\"\n        Produit une dataset suivant la distribution de Dirichlet paramétrée par le vecteur alphas\n       sur les valeurs values\n        e.g. values = [Male, Female] --> Le nombre d'individus correspondant à Male et Female va suivre la\n        distrib Dir(alphas)\n    \"\"\"\n    # values = data[col].unique()\n    assert (n_lines <= len(data.axes[0]))\n    assert (len(values) == len(alphas))\n    print(len(data.axes[0]))\n    # sample a distribution from dir(alphas)\n    s = np.random.dirichlet(tuple(alphas), 1).tolist()[0]\n    print(s)\n    print(alphas)\n    groups = []\n    for i in range(len(values)):\n        if values[0] == 'Male' or values[0] == 'Female':\n            if round(n_lines * s[0]) > 0:\n                groups.append(data[data['sex'] == 1.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n            if round(n_lines * s[1]) > 0:\n                groups.append(data[data['sex'] == 0.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n        else:\n            if round(n_lines * s[i]) > 0:\n                groups.append(data[data[values[i]] == 1.0].sample(n=round(n_lines * s[i]), replace=True))\n            else:\n                groups.append(data[data[values[i]] == 1.0].sample(n=1))\n\n    return pd.concat(groups)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# splitting x into n_client pieces of size client_dataset_size rows\ndef dataset_slice(data, client_dataset_size, token):\n    \"\"\"\"\n        Fait un découpge simple de la dataset\n    \"\"\"\n    dataset_cols = len(data.axes[1])\n    d_client = data.iloc[token * client_dataset_size: (token + 1) * client_dataset_size, 0: dataset_cols]\n    return d_client","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#définit un modèle de réseau de neurones à deux couches cachées avec 16 neurones chacune, une fonction d'activation ReLU\n# et une couche de sortie avec une fonction d'activation sigmoïde. Le modèle est compilé avec l'optimiseur\n# Adam et une fonction de perte de cross-entropy binaire. Trois métriques sont utilisées : l'accuracy, la précision et le rappel\ndef Adult_NN(input_shape):\n    inputs = tf.keras.Input(shape=input_shape)\n    init_distrib= tf.initializers.HeUniform(seed=random.randint(0, 1000))\n    x = tf.keras.layers.Dense(16, activation='relu',bias_initializer = init_distrib, kernel_initializer = init_distrib)(inputs)\n\n    x = tf.keras.layers.Dense(16, activation='relu', bias_initializer = init_distrib, kernel_initializer = init_distrib)(x)\n    outputs = tf.keras.layers.Dense(1, activation='relu')(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n\n    metrics = [\n        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n        tf.keras.metrics.Precision(name='Precision'),\n        tf.keras.metrics.Recall(name='recall')\n\n    ]\n\n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=metrics\n    )\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cette fonction crée un réseau de neurones dense avec quatre couches, chacune contenant 16 neurones.\n# La fonction d'activation utilisée est ReLU. Les poids et les biais sont initialisés à zéro. Le modèle est compilé avec\n# l'optimiseur Adamax et la perte est calculée avec la binary_crossentropy. Les métriques utilisées sont la BinaryAccuracy,\n# la Precision et le Recall\n# creer un model initialisé avec des poids nulls (ce model servira pour creer le modele global)\n\ndef Adult_NN_zero():\n    inputs = tf.keras.Input(shape=(88,))\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(inputs)\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n    outputs = tf.keras.layers.Dense(1, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    optimizer = tf.keras.optimizers.Adamax(learning_rate=0.00001)\n\n    metrics = [\n        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n        tf.keras.metrics.Precision(name='Precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=metrics\n    )\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cette fonction crée un réseau de neurones dense avec quatre couches, chacune contenant 16 neurones.\n# La fonction d'activation utilisée est ReLU. Les poids et les biais sont initialisés à zéro. Le modèle est compilé avec\n# l'optimiseur Adamax et la perte est calculée avec la binary_crossentropy. Les métriques utilisées sont la BinaryAccuracy,\n# la Precision et le Recall\n# creer un model initialisé avec des poids nulls (ce model servira pour creer le modele global)\n\ndef Adult_NN_zero():\n    inputs = tf.keras.Input(shape=(88,))\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(inputs)\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n    x = tf.keras.layers.Dense(16, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n    outputs = tf.keras.layers.Dense(1, activation='relu', kernel_initializer='zero', bias_initializer='zero')(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n\n    optimizer = tf.keras.optimizers.Adamax(learning_rate=0.00001)\n\n    metrics = [\n        tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n        tf.keras.metrics.Precision(name='Precision'),\n        tf.keras.metrics.Recall(name='recall')\n    ]\n\n    model.compile(\n        optimizer=optimizer,\n        loss='binary_crossentropy',\n        metrics=metrics\n    )\n    return model\n\n\n\"\"\"\n    True Positive Rate pour le calcul de EOD\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calcule le taux de vrais positifs (TPR) pour un ensemble de données de test.\n# Le TPR est calculé en utilisant la classe TruePositives de Keras\n# doit etre égale a Recall\ndef compute_TPR(x_test, y_test, model):\n    tp_metric = tf.keras.metrics.TruePositives()\n    model.evaluate(x_test, y_test)\n    tp_metric.update_state(y_test, model.predict(x_test))\n    tp = tp_metric.result().numpy()\n    actual_positive = tf.math.count_nonzero(y_test == 1.0).numpy()\n    tpr = tp / actual_positive\n    return round(tpr, 3)\n\n\n\"\"\"\n    True Negative rates pour le calcul de EOD \n\"\"\"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cette fonction calcule le taux de vrais négatifs (TNR) pour un ensemble de données de test.\n# Le TNR est calculé en utilisant la matrice de confusion\ndef compute_TNR(x_test, y_test, model):\n    y_pred = model.predict(x_test)\n    tn, fp, fn, tp = confusion_matrix(y_test, y_pred.argmax(axis=1)).ravel()\n    tnr = tn / (tn + fp)\n    return round(tnr, 3)\n\n\n\"\"\"\n    Proportions de prédictions Positives pour la calcul de PSD \n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# calcule la proportion de prédictions positives (PP) pour un ensemble de données de test.\n# La PP est calculée en utilisant un seuil de décision de 0,5\ndef compute_PP(x_test, y_test, model):\n    y_pred = model.predict(x_test)\n    # Seuil entre décision poitive et décision négative.\n    positive_mask = tf.where(y_pred >= 0.5, 1, 0)\n    positive_count = np.count_nonzero(positive_mask)\n    total_count = y_pred.shape[0]\n    positive_proportion = positive_count / total_count\n    return round(positive_proportion, 3)\n\n\n\"\"\"\n    Equal opportunity metric pour deux groupes P(\\hat{Y} = 1 | Y = 1, S=s_1) - P(\\hat{Y} = 1 | Y = 1, S=s_2)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calcule la métrique Equal Opportunity (EOD) pour deux groupes en fonction d'un attribut protégé et privilégié.\n# La métrique EOD est définie comme la différence entre le TPR du groupe privilégié et celui du groupe protégé\ndef EOD(model, x_client, y_client, protected, privileged):\n    if protected == 'Female' or privileged == 'Female':\n        protected_x = x_client[x_client['sex'] == 1.0]  # correspond a female\n        protected_y = y_client[x_client['sex'] == 1.0]\n\n        privileged_x = x_client[x_client['sex'] == 0.0]\n        privileged_y = y_client[x_client['sex'] == 0.0]\n\n    else:\n        protected_x = x_client[x_client[protected] == 1.0]\n        protected_y = y_client[x_client[protected] == 1.0]\n\n        privileged_x = x_client[x_client[privileged] == 1.0]\n        privileged_y = y_client[x_client[privileged] == 1.0]\n\n    tpr_protected = compute_TPR(protected_x, protected_y, model)\n    tpr_privilieged = compute_TPR(privileged_x, privileged_y, model)\n\n    # P(\\hat{Y} = 1 | Y = 1, S=s_1) - P(\\hat{Y} = 1 | Y = 1, S=s_2)\n    return tpr_privilieged - tpr_protected","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#calcule la métrique de proportion de décisions positives égales (SPD) pour deux groupes en fonction d'un attribut\n# protégé et privilégié. La métrique SPD est définie comme la différence entre la PP du groupe privilégié et celle du groupe protégé\ndef SPD(model, x_client, y_client, protected, privileged):\n    if protected == 'Female' or privileged == 'Female':\n        protected_x = x_client[x_client['sex'] == 1.0]  # correspond a female\n        protected_y = y_client[x_client['sex'] == 1.0]\n\n        privileged_x = x_client[x_client['sex'] == 0.0]\n        privileged_y = y_client[x_client['sex'] == 0.0]\n    else:\n        protected_x = x_client[x_client[protected] == 1.0]\n        protected_y = y_client[x_client[protected] == 1.0]\n\n        privileged_x = x_client[x_client[privileged] == 1.0]\n        privileged_y = y_client[x_client[privileged] == 1.0]\n\n    pp_protected = compute_PP(protected_x, protected_y, model)\n    pp_privileged = compute_PP(privileged_x, privileged_y, model)\n    return pp_privileged - pp_protected","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#effectue l'apprentissage du modèle à partir de zéro sur un ensemble de données d'entraînement.\n# Elle divise l'ensemble de données en ensembles d'entraînement et de validation, entraîne le modèle sur l'ensemble d'entraînement,\n# et retourne le modèle entraîné.\n# La fonction prend également en entrée un identifiant de client (client_id)\ndef train(x, y, epch, client_id):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n    model = Adult_NN()\n    history = model.fit(x_train, y_train, validation_split=0.2, batch_size=32, epochs=epch, verbose=2)\n    plot_learningCurve(history, epch, client_id)\n    print(\"evaluation sur les données de test ...\")\n    model.evaluate(x_test, y_test)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#effectue l'apprentissage du modèle à partir d'un modèle pré-entraîné. Elle divise l'ensemble de données en ensembles\n# d'entraînement et de validation, ajuste le modèle pré-entraîné sur l'ensemble d'entraînement, et retourne le modèle ajusté.\n# La fonction prend également en entrée un identifiant de client (client_id).\ndef train_from_model(model, x, y, epch, client_id):\n    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, stratify=y)\n    history = model.fit(x_train, y_train, validation_split=0.2, batch_size=32, epochs=epch, verbose=1)\n    plot_learningCurve(history, epch, client_id)\n    model.evaluate(x_test, y_test)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# La fonction multiplie chaque élément de \"weight\" par \"scalar\" et retourne le résultat sous la forme d'une liste\ndef scale_model_weights(weight, scalar):\n    '''function for scaling a models weights'''\n    weight_final = []\n    steps = len(weight)\n    for i in range(steps):\n        weight_final.append(scalar * weight[i])\n    return weight_final","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Cette méthode prend une liste de poids d'un modèle multipliée par le facteur d'échelle et renvoie la somme pondérée\n# de ces poids. Elle calcule d'abord la moyenne des poids de chaque couche des modèles clients\n# Ensuite, elle somme les moyennes de chaque couche pour obtenir la somme pondérée de ces poids\ndef sum_scaled_weights(scaled_weight_list):\n    '''Return la somme des weights multipliés par le facteur de scaling'''\n    avg_grad = list()\n    # get the average grad accross all client gradients\n    for grad_list_tuple in zip(*scaled_weight_list):\n        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n        avg_grad.append(layer_mean)\n\n    return avg_grad","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cette méthode prend en entrée une liste de modèles models, le nombre total de clients n,\n# une liste de poids de clients clients_weights et la forme de l'entrée input_shape.\n# Elle calcule les poids moyens de tous les modèles pondérés en fonction du poids de chaque client en utilisant\n# la méthode sum_scaled_weights() définie précédemment\n# Elle crée un nouveau modèle avec les poids moyens calculés et renvoie ce modèle\ndef FedAvg(models, n, clients_weights, input_shape):\n    scaled_weights = []\n\n    global_model = Adult_NN(input_shape)\n    for i in range(n):\n        scaled_weights.append(scale_model_weights(models[i].get_weights(), clients_weights[i]))\n\n    avg_weights = sum_scaled_weights(scaled_weights)\n\n    global_model.set_weights(avg_weights)\n    return global_model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cette méthode calcule les valeurs d'égalité des chances et de parité statistique pour chaque paire d'attributs sensibles.\n# Elle crée un diagramme à barres pour afficher ces valeurs et renvoie l'objet matplotlib.pyplot correspondant.\ndef plot_Fairness_Values(model, x_client, y_client, sensitive_attr, model_id, iteration):\n    eod_values = []\n    spd_values = []\n    labels = []\n\n    width = 0.15  # the width of the bars\n    multiplier = 0\n\n    fig, ax = plt.subplots(layout='constrained')\n    for i in range(len(sensitive_attr)):\n        for j in range(i, len(sensitive_attr)):\n            if sensitive_attr[i] != sensitive_attr[j]:\n                labels.append(sensitive_attr[i] + '/' + sensitive_attr[j])\n                eod_values.append(EOD(model, x_client, y_client, sensitive_attr[i], sensitive_attr[j]))\n                spd_values.append(SPD(model, x_client, y_client, sensitive_attr[i], sensitive_attr[j]))\n            #    offset = width * multiplier\n    x_axis = np.arange(len(labels))\n    rects = ax.bar(x_axis - 0.1, eod_values, 0.10, label='EOD')\n    ax.bar_label(rects, padding=3)\n    rects = ax.bar(x_axis + 0.1, spd_values, 0.10, label='SPD')\n    ax.bar_label(rects, padding=3)\n    ax.axhline(y=0.0, color='r', linestyle='-')\n    multiplier += 1\n\n    # plots\n    x_locations = np.arange(len(eod_values))  # the label locations\n    ax.set_ylabel('Valeurs')\n    ax.set_title(\n        'Equal opportunity / Statistical Parity sur les differents groupes [Model : ' + model_id + ', iteration : ' + iteration + ']')\n    ax.set_xticks(x_locations + width, labels, rotation=45)\n    ax.legend(loc='upper left', )\n    ax.set_ylim(-1, 1)\n    return plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cette méthode évalue les performances du modèle pour chaque groupe d'attributs sensibles et crée un diagramme à barres pour\n# afficher les performances de chaque groupe. Elle renvoie l'objet matplotlib.pyplot correspondant\ndef Eval_group_fairness(model, x, y, sensitive_attr, model_id, iteration):\n    groups_x = []\n    groups_y = []\n    if sensitive_attr[0] != 'Male' and sensitive_attr[1] != 'Male':\n        # partitionnement\n        for i in range(len(sensitive_attr)):\n            print(\"evaluating for group : \", sensitive_attr[i])\n            groups_x.append(x[x[sensitive_attr[i]] == 1.0])\n            groups_y.append(y[x[sensitive_attr[i]] == 1.0])\n    # Male/Female est un attribut binaire et est traité différemment dans le preprocess\n    # -> une seule colomne est gardée (Female) pour des valeurs 0/1\n    else:\n        groups_x.append(x[x['sex'] == 1.0])  # correspond a female\n        groups_x.append(x[x['sex'] == 0.0])\n\n        groups_y.append(y[x['sex'] == 1.0])\n        groups_y.append(y[x['sex'] == 0.0])\n\n    group_evals = []\n    metrics = (\"Loss\", \"Accuracy\", \"Precision\", \"Recall/TPR\", \"PositiveProportion\")\n    for i in range(len(sensitive_attr)):\n        print(\"Performance du modele sur le groupe (\" + sensitive_attr[i] + \" = 1)\")\n        group_evals.append(model.evaluate(groups_x[i], groups_y[i], verbose=2))\n        group_evals[i].append(compute_PP(groups_x[i], groups_y[i], model))  # Ajouter la métrique faite en locale\n\n    x = np.arange(len(metrics))  # the label locations\n    width = 0.10  # the width of the bars\n    multiplier = 0\n\n    fig, ax = plt.subplots(layout='constrained')\n\n    for i in range(len(sensitive_attr)):\n        offset = width * multiplier\n        rects = ax.bar(x + offset, group_evals[i], width, label=sensitive_attr[i])\n        ax.bar_label(rects, padding=3)\n        multiplier += 1\n\n    # plots\n    ax.set_ylabel('Valeurs')\n    ax.set_title(\n        'Performance du modele sur les differents groupes [Model : ' + model_id + ', iteration : ' + iteration + ']')\n    ax.set_xticks(x + width, metrics)\n    ax.legend(loc='upper left')\n    ax.set_ylim(0, 1.5)\n    return plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# crée un dictionnaire alphas contenant quatre valeurs différentes pour les facteurs d'échelle :\n# extremely homogeneous, very homogeneous, homogeneous et uniform.\n# Ces valeurs seront utilisées pour pondérer les poids des clients lors du calcul des poids moyens dans la méthode FedAvg()\ndef create_alphas(dim): # dim est le nombre de categories dans la race\n    alphas = {\n        'extremely homogeneous': [100000 for i in range(dim)],\n        'very homogeneous': [1000 for i in range(dim)],\n        'homogeneous': [10 for i in range(dim)],\n        'uniform': [1 for i in range(dim)],  # Eqivaut a un echantillonage aleatoire sample(random_state = 0)\n        'heterogeneous_2': [1 / 2 for i in range(dim)],\n        'heterogeneous_5': [1 / 5 for i in range(dim)],\n        'heterogeneous_10': [1 / 10 for i in range(dim)],\n        'very heterogeneous': [1 / 100 for i in range(dim)],  # inutilisable\n        'extremely heterogeneous': [1 / 1000 for i in range(dim)]  # inutilisable\n    }\n    return alphas\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# La fonction extrait deux sous-ensembles de données \"attr_elements\" et \"non_attr_elements\" en fonction\n# de la valeur de \"attribute\". Elle compte ensuite le nombre d'éléments ayant un revenu positif dans chacun de\n# ces sous-ensembles, puis retourne un\n# tuple contenant le rapport de ces comptages par rapport à \"val_1\" et \"val_0\", respectivement\n# Retourne (P(Y=1 | S = 1), P(Y=1 | S = 0))\ndef positives_prop(data, val_1, val_0, attribute):\n    if attribute == 'Female':\n        attr_elements = data[data['sex'] == 1.0]\n        non_attr_elements = data[data['sex'] == 0.0]\n    else:\n        attr_elements = data[data[attribute] == 1.0]\n        non_attr_elements = data[data[attribute] == 0.0]\n    positive_attr_elements = attr_elements[attr_elements['income'] == 1.0]\n    positive_non_attr_elements = non_attr_elements[non_attr_elements['income'] == 1.0]\n    return (((len(positive_attr_elements.axes[0]) / len(data.axes[0])) / val_1),\n            ((len(positive_non_attr_elements.axes[0]) / len(data.axes[0])) / val_0))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prend en entrée un modèle \"model\", un dictionnaire \"d_client\", une chaîne de caractères \"attribute\" et\n# deux valeurs \"val_1\" et \"val_0\". La fonction extrait le vecteur de cibles \"y_test\" et la matrice de données\n# \"x_test\" à partir de \"d_clients\". Elle calcule ensuite les prédictions positives pour les deux groupes définis\n# par \"attribute\" à l'aide de la fonction \"compute_PP\", puis appelle la fonction \"positives_prop\" pour obtenir les\n# proportions positives. Enfin, la fonction calcule et\n# retourne la différence entre les produits des proportions positives et des prédictions positives pour les deux groupes.\ndef compute_mkGlobal(model, d_client, attribute, val_1, val_0):\n    y_test = d_clients[i]['income']\n    x_test = d_clients[i].drop('income', axis=1)\n\n    pp_gr1 = compute_PP(x_test[x_test[attribute] == 1.0], y_test[x_test[attribute] == 1.0], model)\n    pp_gr0 = compute_PP(x_test[x_test[attribute] == 0.0], y_test[x_test[attribute] == 0.0], model)\n    (term_gr1, term_gr0) = positives_prop(d_client, val_1, val_0, attribute)\n\n    return (pp_gr1 * term_gr1 - pp_gr0 * pp_gr0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = ('/kaggle/input/adult-census-income/adult.csv')\ndata = pd.read_csv(path, encoding='latin-1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata.replace('?', np.NaN)\ndataSet_summary(data)\nattributes = {\n'race': data['race'].unique(),\n        #'sex': data['sex'].unique(),\n        #   'relationship' : data['relationship'].unique(),\n        #   'occupation' : data['occupation'].unique(),\n       # 'marital.status': data['marital.status'].unique()\n}\npre_processed_data = data_PreProcess(data)\n    # Nombre de FL clients / iterations / epochs\nlearning_iterations = 5\nn_clients = 3\nepochs = 10\n    # Definir l'attribut sur lequel l'analyse de l'équité sera faite\nattribute_to_manipulate = 'race'\ndataset_rows = len(data.axes[0])\nclient_dataset_size = round(dataset_rows / n_clients)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"   # Un jeu de parametres de la dstrib de dirichelet (alphas). selon des degrès d'homogenité\nalphas = create_alphas(len(data[attribute_to_manipulate].unique()))\nd_clients = []\ndisplay = 1\n    # Ces deux valeurs correspondent a P(Y = 1 | A = 1) et P(Y = 1 | A = 0)\n(positive_prop_attr, positive_prop_non_attr) = positives_prop(pre_processed_data, 1, 1, 'White')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[attribute_to_manipulate].unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alphas","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(positive_prop_attr, positive_prop_non_attr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor i in range(n_clients):\n    d_clients.append(Dirichelet_sampling(pre_processed_data, alphas['heterogeneous_2'], data[attribute_to_manipulate].unique(),client_dataset_size))\n    print(\"\\nClient \", i, \" groups distribution : \")\n    curr_client_distrib = check_balance(d_clients[i], attributes)\n    if display:\n        curr_client_distrib.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install aif360 ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from aif360.datasets import BinaryLabelDataset\nfrom aif360.algorithms.preprocessing import Reweighing\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n\n\ndef rew(X_train,y_train_df):\n        # Création des jeux de données d'entraînement et de test avec AIF360\n        train_dataset = BinaryLabelDataset(df=X_train.join(y_train_df), label_names=['income'], \n                                           protected_attribute_names=['race', 'sex'], \n                                           favorable_label=1, unfavorable_label=0)\n\n\n\n        # Définition des groupes privilégiés et non privilégiés\n        privileged_groups = [{'race': 1}]  # Remplacez par vos propres valeurs\n        unprivileged_groups = [{'race': 0}]  # Remplacez par vos propres valeurs\n\n        # Application de la méthode de reweighing\n        rw = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n        train_dataset_reweighed = rw.fit_transform(train_dataset)\n\n\n        # Calcul des mesures de performance\n        accuracy = accuracy_score(test_dataset.labels.ravel(), y_pred)\n        precision = precision_score(test_dataset.labels.ravel(), y_pred)\n        recall = recall_score(test_dataset.labels.ravel(), y_pred)\n        f1 = f1_score(test_dataset.labels.ravel(), y_pred)\n\n        print(\"Exactitude:\", accuracy)\n        print(\"Précision:\", precision)\n        print(\"Rappel:\", recall)\n        print(\"Score F1:\", f1)\n        return train_dataset_reweighed.features, train_dataset_reweighed.labels.ravel()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_PreProcess_race(data):\n\n    nominal_features = ['race']\n\n    data = onehot_encode(data, nominal_features)\n#     normalized_data = (data - data.min()) / (data.max() - data.min())\n    # return pd.concat([normalized_x, y], axis=1)\n    return data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for j in range(learning_iterations):\n    models = []\n    metric_values = []\n    mk_global_gr = []\n    shape=()\n    for i in range(len(d_clients)):\n            # n_client = 1 apprentissage centralisé.\n        if n_clients == 1:\n            d_client = pre_processed_data\n\n        y_client = d_clients[i]['income']\n        x_client = d_clients[i].drop('income', axis=1)\n        x_client,y_client= rew(x_client,y_client)\n        x_client = pre_processed_data(x_client)\n        shape = (None, x_client.shape[1])\n\n        if j == 0:\n            models.append(train_from_model(Adult_NN(shape), x_client, y_client, epochs, i + 1))\n        else:\n            models.append(train_from_model(FedAvg_global_model, x_client, y_client, epochs, i + 1))\n\n            # calcul de la métrique EOD pour les groupes White Black\n        print(\"\\n\\n(Local) Fairness analysis : \")\n\n        fairness_plot = plot_Fairness_Values(models[i], x_client, y_client, data[attribute_to_manipulate].unique(), str(i + 1), str(j + 1))\n        group_plot = Eval_group_fairness(models[i], x_client, y_client, data[attribute_to_manipulate].unique(),str(i + 1), str(j + 1))\n        if display:\n             fairness_plot.show()\n\n        if display:\n             group_plot.show()\n  # Agggregate pour vanilla FedAvg\n\n    FedAvg_global_model = FedAvg(models, n_clients, clients_weights=[1 / n_clients for i in range(n_clients)], input_shape=shape)\n        # tester le model global sur\n    y = pre_processed_data['income']\n    x = pre_processed_data.drop('income', axis=1)\n    print(\"Global model [FedAvg] evaluation : \")\n    FedAvg_global_model.evaluate(x, y, verbose=2)\n    print(\"\\n\\n(Gloal) Fairness analysis : \")\n\n    groups_plot1 = Eval_group_fairness(FedAvg_global_model, x, y, data[attribute_to_manipulate].unique(),\n                                           'Global model with FairFed agg', str(j + 1))\n    fairness_plot1 = plot_Fairness_Values(FedAvg_global_model, x, y, data[attribute_to_manipulate].unique(),\n                                              'Global model with FairFed agg', str(j + 1))\n    if display:\n        groups_plot1.show()\n    if display:\n        fairness_plot1.show()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}