{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Python libraries","metadata":{}},{"cell_type":"code","source":"!pip install flwr","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.801875Z","iopub.status.idle":"2023-05-20T16:00:05.802392Z","shell.execute_reply.started":"2023-05-20T16:00:05.802126Z","shell.execute_reply":"2023-05-20T16:00:05.802151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow.compat.v1 as tf\nsess = tf.Session()\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nprint(os.listdir(\"../input\"))\nimport errno\nimport tensorflow as tf\nimport csv\nfrom keras import backend as K\nimport sklearn\nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Flatten, Dense, Dropout, BatchNormalization\nfrom keras.layers import Conv1D, MaxPool1D\nfrom keras.optimizers import Adam\nimport random\nimport pandas as pd\nimport numpy as np\nimport math\nimport os\nimport flwr as fl\nimport array\nfrom scipy.stats import dirichlet\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import preprocessing\n\nfrom imblearn.over_sampling import SMOTE","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-05-22T23:09:59.147295Z","iopub.execute_input":"2023-05-22T23:09:59.147738Z","iopub.status.idle":"2023-05-22T23:10:09.315173Z","shell.execute_reply.started":"2023-05-22T23:09:59.147712Z","shell.execute_reply":"2023-05-22T23:10:09.313731Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"['adult-census-income']\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflwr\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfl\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01marray\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dirichlet\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'flwr'"],"ename":"ModuleNotFoundError","evalue":"No module named 'flwr'","output_type":"error"}]},{"cell_type":"code","source":"!pip install aif360 ","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.806275Z","iopub.status.idle":"2023-05-20T16:00:05.806823Z","shell.execute_reply.started":"2023-05-20T16:00:05.806521Z","shell.execute_reply":"2023-05-20T16:00:05.806575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install BlackBoxAuditing","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.808294Z","iopub.status.idle":"2023-05-20T16:00:05.808876Z","shell.execute_reply.started":"2023-05-20T16:00:05.808583Z","shell.execute_reply":"2023-05-20T16:00:05.808617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import dataset","metadata":{}},{"cell_type":"code","source":"path = ('/kaggle/input/adult-census-income/adult.csv')\ndf = pd.read_csv(path, encoding='latin-1')","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:10:18.862207Z","iopub.execute_input":"2023-05-22T23:10:18.862709Z","iopub.status.idle":"2023-05-22T23:10:18.997370Z","shell.execute_reply.started":"2023-05-22T23:10:18.862673Z","shell.execute_reply":"2023-05-22T23:10:18.996075Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.race.unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:10:21.613826Z","iopub.execute_input":"2023-05-22T23:10:21.614184Z","iopub.status.idle":"2023-05-22T23:10:21.631538Z","shell.execute_reply.started":"2023-05-22T23:10:21.614157Z","shell.execute_reply":"2023-05-22T23:10:21.630533Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"array(['White', 'Black', 'Asian-Pac-Islander', 'Other',\n       'Amer-Indian-Eskimo'], dtype=object)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"### Check shape of dataset","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.811977Z","iopub.status.idle":"2023-05-20T16:00:05.812488Z","shell.execute_reply.started":"2023-05-20T16:00:05.812226Z","shell.execute_reply":"2023-05-20T16:00:05.812251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that there are 32561 instances and 15 attributes in the data set.","metadata":{}},{"cell_type":"markdown","source":"### Preview dataset","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.813688Z","iopub.status.idle":"2023-05-20T16:00:05.814201Z","shell.execute_reply.started":"2023-05-20T16:00:05.813937Z","shell.execute_reply":"2023-05-20T16:00:05.813961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.race.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.820220Z","iopub.status.idle":"2023-05-20T16:00:05.820820Z","shell.execute_reply.started":"2023-05-20T16:00:05.820522Z","shell.execute_reply":"2023-05-20T16:00:05.820565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### View summary of dataframe","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.822675Z","iopub.status.idle":"2023-05-20T16:00:05.823224Z","shell.execute_reply.started":"2023-05-20T16:00:05.822939Z","shell.execute_reply":"2023-05-20T16:00:05.822965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Summary of the dataset shows that there are no missing values. But the preview shows that the dataset contains values coded as `?`. So, I will encode `?` as NaN values.","metadata":{}},{"cell_type":"markdown","source":"### Encode `?` as `NaNs`","metadata":{}},{"cell_type":"code","source":"df[df == '?'] = np.nan","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.824769Z","iopub.status.idle":"2023-05-20T16:00:05.825296Z","shell.execute_reply.started":"2023-05-20T16:00:05.825025Z","shell.execute_reply":"2023-05-20T16:00:05.825050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.826697Z","iopub.status.idle":"2023-05-20T16:00:05.827221Z","shell.execute_reply.started":"2023-05-20T16:00:05.826951Z","shell.execute_reply":"2023-05-20T16:00:05.826978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.828728Z","iopub.status.idle":"2023-05-20T16:00:05.829255Z","shell.execute_reply.started":"2023-05-20T16:00:05.828985Z","shell.execute_reply":"2023-05-20T16:00:05.829013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Impute missing values with mode","metadata":{}},{"cell_type":"code","source":"for col in ['workclass', 'occupation', 'native.country']:\n    df[col].fillna(df[col].mode()[0], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.830863Z","iopub.status.idle":"2023-05-20T16:00:05.831383Z","shell.execute_reply.started":"2023-05-20T16:00:05.831114Z","shell.execute_reply":"2023-05-20T16:00:05.831139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check again for missing values","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.833037Z","iopub.status.idle":"2023-05-20T16:00:05.833572Z","shell.execute_reply.started":"2023-05-20T16:00:05.833282Z","shell.execute_reply":"2023-05-20T16:00:05.833306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ndef race_Dirichelet_sampling(data, alphas, values, n_lines):\n    assert (n_lines <= len(data))\n    assert (len(values) == len(alphas))\n\n    s = np.random.dirichlet(tuple(alphas), 1).tolist()[0]\n    groups = []\n\n    for i in range(len(values)):\n        if round(n_lines * s[i]) > 0:\n            groups.append(data[data['race'] == values[i]].sample(n=round(n_lines * s[i]), replace=True))\n        else:\n            groups.append(data[data['race'] == values[i]].sample(n=1))\n\n    return pd.concat(groups)\nalphas = [1, 2, 3, 1, 1]  \nvalues = ['White', 'Black', 'Asian-Pac-Islander', 'Other', 'Amer-Indian-Eskimo']\nn_lines = 1000 \nresult_dataset = race_Dirichelet_sampling(df, alphas, values, n_lines)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:16:53.194448Z","iopub.execute_input":"2023-05-22T23:16:53.194830Z","iopub.status.idle":"2023-05-22T23:16:53.201249Z","shell.execute_reply.started":"2023-05-22T23:16:53.194802Z","shell.execute_reply":"2023-05-22T23:16:53.200288Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"alphas = [1, 2, 3, 1, 1]  \nvalues = ['White', 'Black', 'Asian-Pac-Islander', 'Other', 'Amer-Indian-Eskimo']\nn_lines = 1000 \nresult_dataset = race_Dirichelet_sampling(df, alphas, values, n_lines)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:17:11.179649Z","iopub.execute_input":"2023-05-22T23:17:11.179984Z","iopub.status.idle":"2023-05-22T23:17:11.217308Z","shell.execute_reply.started":"2023-05-22T23:17:11.179961Z","shell.execute_reply":"2023-05-22T23:17:11.215851Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"df.race.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:17:46.474595Z","iopub.execute_input":"2023-05-22T23:17:46.474920Z","iopub.status.idle":"2023-05-22T23:17:46.487197Z","shell.execute_reply.started":"2023-05-22T23:17:46.474895Z","shell.execute_reply":"2023-05-22T23:17:46.485940Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"White                 27816\nBlack                  3124\nAsian-Pac-Islander     1039\nAmer-Indian-Eskimo      311\nOther                   271\nName: race, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"df.race.value_counts()\nresult_dataset.race.value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-05-22T23:17:38.227587Z","iopub.execute_input":"2023-05-22T23:17:38.228017Z","iopub.status.idle":"2023-05-22T23:17:38.239655Z","shell.execute_reply.started":"2023-05-22T23:17:38.227974Z","shell.execute_reply":"2023-05-22T23:17:38.238591Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Asian-Pac-Islander    459\nBlack                 403\nAmer-Indian-Eskimo     90\nOther                  47\nWhite                   1\nName: race, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"def Dirichelet_sampling(data, alphas, values, n_lines):\n    \"\"\"\n        Produit une dataset suivant la distribution de Dirichlet paramétrée par le vecteur alphas\n       sur les valeurs values\n        e.g. values = [Male, Female] --> Le nombre d'individus correspondant à Male et Female va suivre la\n        distrib Dir(alphas)\n    \"\"\"\n    # values = data[col].unique()\n    assert (n_lines <= len(data.axes[0]))\n    assert (len(values) == len(alphas))\n    print(len(data.axes[0]))\n    # sample a distribution from dir(alphas)\n    s = np.random.dirichlet(tuple(alphas), 1).tolist()[0]\n    print(s)\n    print(alphas)\n    groups = []\n    for i in range(len(values)):\n        if values[0] == 'Male' or values[0] == 'Female':\n            if round(n_lines * s[0]) > 0:\n                groups.append(data[data['sex'] == 1.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n            if round(n_lines * s[1]) > 0:\n                groups.append(data[data['sex'] == 0.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n        else:\n            if round(n_lines * s[i]) > 0:\n                groups.append(data[data[values[i]] == 1.0].sample(n=round(n_lines * s[i]), replace=True))\n            else:\n                groups.append(data[data[values[i]] == 1.0].sample(n=1))\n\n    return pd.concat(groups)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.835048Z","iopub.status.idle":"2023-05-20T16:00:05.835600Z","shell.execute_reply.started":"2023-05-20T16:00:05.835298Z","shell.execute_reply":"2023-05-20T16:00:05.835323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.race.unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.838776Z","iopub.status.idle":"2023-05-20T16:00:05.839311Z","shell.execute_reply.started":"2023-05-20T16:00:05.839043Z","shell.execute_reply":"2023-05-20T16:00:05.839070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we can see that there are no missing values in the dataset.","metadata":{}},{"cell_type":"markdown","source":"### Setting feature vector and target variable","metadata":{}},{"cell_type":"code","source":"X = df.drop(['income'], axis=1)\ny = df['income']","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.841192Z","iopub.status.idle":"2023-05-20T16:00:05.841762Z","shell.execute_reply.started":"2023-05-20T16:00:05.841460Z","shell.execute_reply":"2023-05-20T16:00:05.841486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.unique(),y.nunique()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.843919Z","iopub.status.idle":"2023-05-20T16:00:05.844456Z","shell.execute_reply.started":"2023-05-20T16:00:05.844183Z","shell.execute_reply":"2023-05-20T16:00:05.844210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.846214Z","iopub.status.idle":"2023-05-20T16:00:05.846771Z","shell.execute_reply.started":"2023-05-20T16:00:05.846464Z","shell.execute_reply":"2023-05-20T16:00:05.846490Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split data into separate training and test set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.848271Z","iopub.status.idle":"2023-05-20T16:00:05.848821Z","shell.execute_reply.started":"2023-05-20T16:00:05.848528Z","shell.execute_reply":"2023-05-20T16:00:05.848573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"### Encode categorical variables: LabelEncoder","metadata":{}},{"cell_type":"markdown","source":"![](https://ai-ml-analytics.com/wp-content/uploads/2020/08/encoding-3.png)","metadata":{}},{"cell_type":"code","source":"from sklearn import preprocessing\n\ncategorical = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\nfor feature in categorical:\n        le = preprocessing.LabelEncoder()\n        X_train[feature] = le.fit_transform(X_train[feature])\n        X_test[feature] = le.transform(X_test[feature])","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.850191Z","iopub.status.idle":"2023-05-20T16:00:05.850745Z","shell.execute_reply.started":"2023-05-20T16:00:05.850443Z","shell.execute_reply":"2023-05-20T16:00:05.850467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = pd.concat([X_train, X_test], axis=0)\ny = pd.concat([y_train, y_test], axis=0)\ndff = pd.concat([X, y], axis=1)\ndff=dff.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.852419Z","iopub.status.idle":"2023-05-20T16:00:05.853000Z","shell.execute_reply.started":"2023-05-20T16:00:05.852720Z","shell.execute_reply":"2023-05-20T16:00:05.852745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.race.unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.854935Z","iopub.status.idle":"2023-05-20T16:00:05.855468Z","shell.execute_reply.started":"2023-05-20T16:00:05.855190Z","shell.execute_reply":"2023-05-20T16:00:05.855218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d={\"White\":1,\"Black\":0,\"Asian-Pac-Islander\":0,\"Other\":0,'Amer-Indian-Eskimo':0}","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.857079Z","iopub.status.idle":"2023-05-20T16:00:05.857643Z","shell.execute_reply.started":"2023-05-20T16:00:05.857336Z","shell.execute_reply":"2023-05-20T16:00:05.857363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(5,df.shape[0]):\n    print(i)\n    print(df.loc[i,\"race\"])\n    df.loc[i,\"race\"] = d[df.loc[i,\"race\"]]","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.858914Z","iopub.status.idle":"2023-05-20T16:00:05.859443Z","shell.execute_reply.started":"2023-05-20T16:00:05.859169Z","shell.execute_reply":"2023-05-20T16:00:05.859194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Dirichelet_sampling(data, alphas, values, n_lines):\n    \"\"\"\n        Produit une dataset suivant la distribution de Dirichlet paramétrée par le vecteur alphas\n       sur les valeurs values\n        e.g. values = [Male, Female] --> Le nombre d'individus correspondant à Male et Female va suivre la\n        distrib Dir(alphas)\n    \"\"\"\n    # values = data[col].unique()\n    assert (n_lines <= len(data.axes[0]))\n    assert (len(values) == len(alphas))\n    print(len(data.axes[0]))\n    # sample a distribution from dir(alphas)\n    s = np.random.dirichlet(tuple(alphas), 1).tolist()[0]\n    print(s)\n    print(alphas)\n    groups = []\n    for i in range(len(values)):\n        if values[0] == 'white' :\n            if round(n_lines * s[0]) > 0:\n                groups.append(data[data['race'] == 1.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['race'] == 1.0].sample(n=1))\n\n            if round(n_lines * s[1]) > 0:\n                groups.append(data[data['race'] == 0.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['race'] == 1.0].sample(n=1))\n\n        else:\n            if round(n_lines * s[i]) > 0:\n                groups.append(data[data[values[i]] == 1.0].sample(n=round(n_lines * s[i]), replace=True))\n            else:\n                groups.append(data[data[values[i]] == 1.0].sample(n=1))\n\n    return pd.concat(groups)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.860876Z","iopub.status.idle":"2023-05-20T16:00:05.861406Z","shell.execute_reply.started":"2023-05-20T16:00:05.861141Z","shell.execute_reply":"2023-05-20T16:00:05.861166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Dirichelet_sampling(data, alphas, values, n_lines):\n    \"\"\"\n        Produit une dataset suivant la distribution de Dirichlet paramétrée par le vecteur alphas\n       sur les valeurs values\n        e.g. values = [Male, Female] --> Le nombre d'individus correspondant à Male et Female va suivre la\n        distrib Dir(alphas)\n    \"\"\"\n    # values = data[col].unique()\n    assert (n_lines <= len(data.axes[0]))\n    assert (len(values) == len(alphas))\n    print(len(data.axes[0]))\n    # sample a distribution from dir(alphas)\n    s = np.random.dirichlet(tuple(alphas), 1).tolist()[0]\n    print(s)\n    print(alphas)\n    groups = []\n    for i in range(len(values)):\n        if values[0] == 'Male' or values[0] == 'Female':\n            if round(n_lines * s[0]) > 0:\n                groups.append(data[data['sex'] == 1.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n            if round(n_lines * s[1]) > 0:\n                groups.append(data[data['sex'] == 0.0].sample(n=round(n_lines * s[0]), replace=True))\n            else:\n                groups.append(data[data['sex'] == 1.0].sample(n=1))\n\n        else:\n            if round(n_lines * s[i]) > 0:\n                groups.append(data[data[values[i]] == 1.0].sample(n=round(n_lines * s[i]), replace=True))\n            else:\n                groups.append(data[data[values[i]] == 1.0].sample(n=1))\n\n    return pd.concat(groups)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.862769Z","iopub.status.idle":"2023-05-20T16:00:05.863311Z","shell.execute_reply.started":"2023-05-20T16:00:05.863043Z","shell.execute_reply":"2023-05-20T16:00:05.863068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"values = ['White', 'Black', 'Asian-Pac-Islander', 'Other',\n       'Amer-Indian-Eskimo']\ndf1 = Dirichelet_sampling(dff, [0.2,0.8], values, 11000)\ndf2 = Dirichelet_sampling(dff, [0.7,0.9], values, 10000)\ndf3 = Dirichelet_sampling(dff, [0.6,0.3], values, 10000)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.865194Z","iopub.status.idle":"2023-05-20T16:00:05.865820Z","shell.execute_reply.started":"2023-05-20T16:00:05.865451Z","shell.execute_reply":"2023-05-20T16:00:05.865478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.race.unique()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.868055Z","iopub.status.idle":"2023-05-20T16:00:05.868464Z","shell.execute_reply.started":"2023-05-20T16:00:05.868267Z","shell.execute_reply":"2023-05-20T16:00:05.868287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1.shape,df2.shape, df3.shape","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.870120Z","iopub.status.idle":"2023-05-20T16:00:05.870527Z","shell.execute_reply.started":"2023-05-20T16:00:05.870331Z","shell.execute_reply":"2023-05-20T16:00:05.870351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\ny_train = le.fit_transform(y_train)\ny_test = le.transform(y_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.871811Z","iopub.status.idle":"2023-05-20T16:00:05.872213Z","shell.execute_reply.started":"2023-05-20T16:00:05.872028Z","shell.execute_reply":"2023-05-20T16:00:05.872046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Scaling","metadata":{}},{"cell_type":"markdown","source":"![](https://cdn-images-1.medium.com/max/370/1*Nlgc_wq2b-VfdawWX9MLWA.png)","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X.columns)\n\nX_test = pd.DataFrame(scaler.transform(X_test), columns = X.columns)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.873169Z","iopub.status.idle":"2023-05-20T16:00:05.873528Z","shell.execute_reply.started":"2023-05-20T16:00:05.873345Z","shell.execute_reply":"2023-05-20T16:00:05.873362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.874495Z","iopub.status.idle":"2023-05-20T16:00:05.874929Z","shell.execute_reply.started":"2023-05-20T16:00:05.874741Z","shell.execute_reply":"2023-05-20T16:00:05.874761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Modeling + Fairness","metadata":{}},{"cell_type":"markdown","source":"**Remove the 'race' and 'sex' columns from the dataset to remove any potential biases or discriminatory factors**","metadata":{}},{"cell_type":"code","source":"X_trainn = X_train.drop(['race', 'sex'], axis=1)\nX_testt = X_test.drop(['race', 'sex'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.876103Z","iopub.status.idle":"2023-05-20T16:00:05.876479Z","shell.execute_reply.started":"2023-05-20T16:00:05.876296Z","shell.execute_reply":"2023-05-20T16:00:05.876313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\nmodel = DecisionTreeRegressor()\nmodel.fit(X_trainn, y_train)\n\ny_pred = model.predict(X_testt)\n\nmse = mean_squared_error(y_test, y_pred)\nprint('Mean Squared Error:', mse)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.879521Z","iopub.status.idle":"2023-05-20T16:00:05.879929Z","shell.execute_reply.started":"2023-05-20T16:00:05.879734Z","shell.execute_reply":"2023-05-20T16:00:05.879752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# adversarial debiasing :\nis an in-processing technique for fairness in machine learning that tries to learn a fair classifier by adding an adversary to the training process.\n\nThe goal is to train a model that is both accurate and fair with respect to some protected attributes, such as race or gender. Adversarial debiasing adds a new step to the training process, where an adversarial network is trained to predict the protected attribute from the hidden layers of the main network. This adversarial network tries to maximize the error in predicting the protected attribute while the main network tries to minimize it.\n\nBy doing so, the main network learns to encode the input features in a way that is less informative about the protected attributes, which leads to a fairer classifier.","metadata":{}},{"cell_type":"code","source":"!pip install aif360\n\nfrom aif360.datasets import StandardDataset\nfrom aif360.algorithms.inprocessing import AdversarialDebiasing","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.881277Z","iopub.status.idle":"2023-05-20T16:00:05.881676Z","shell.execute_reply.started":"2023-05-20T16:00:05.881468Z","shell.execute_reply":"2023-05-20T16:00:05.881485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n\ny_train_df = pd.DataFrame({'income': y_train})\n\ndataset_train = StandardDataset(\n    df=X_train.join(y_train_df),\n    label_name='income',\n    favorable_classes=[1],\n    protected_attribute_names=['race', 'sex'],\n    privileged_classes=[['1'], ['1']]\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.884948Z","iopub.status.idle":"2023-05-20T16:00:05.885355Z","shell.execute_reply.started":"2023-05-20T16:00:05.885160Z","shell.execute_reply":"2023-05-20T16:00:05.885179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.compat.v1.disable_eager_execution()\ndebias_model = AdversarialDebiasing(\n    unprivileged_groups=[{'race': 0, 'sex': 0}],\n    privileged_groups=[{'race': 1, 'sex': 1}],\n    scope_name='adversarial_debiasing',\n    sess=sess\n)\ndebias_model.fit(dataset_train)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.886714Z","iopub.status.idle":"2023-05-20T16:00:05.887102Z","shell.execute_reply.started":"2023-05-20T16:00:05.886905Z","shell.execute_reply":"2023-05-20T16:00:05.886923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test_df = pd.DataFrame({'income': y_test})\ndataset_test = StandardDataset(\n    df=X_test.join(y_test_df),\n    label_name='income',\n    favorable_classes=[1],\n    protected_attribute_names=['race', 'sex'],\n    privileged_classes=[['1'], ['1']]\n)\ndataset_debiased = debias_model.predict(dataset_test)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.888865Z","iopub.status.idle":"2023-05-20T16:00:05.889240Z","shell.execute_reply.started":"2023-05-20T16:00:05.889052Z","shell.execute_reply":"2023-05-20T16:00:05.889069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the performance of the debiased model\ny_pred = dataset_debiased.labels\ny_true = dataset_test.labels.ravel()\nprint(\"Accuracy score:\", accuracy_score(y_true, y_pred))\nprint(\"Balanced accuracy score:\", balanced_accuracy_score(y_true, y_pred))\nprint(\"F1 score:\", f1_score(y_true, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.890672Z","iopub.status.idle":"2023-05-20T16:00:05.891037Z","shell.execute_reply.started":"2023-05-20T16:00:05.890856Z","shell.execute_reply":"2023-05-20T16:00:05.890873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Accuracy score: measures the proportion of correctly classified instances among all instances. It is computed as the number of true positives plus true negatives divided by the total number of instances. It is not suitable for imbalanced datasets, where the classes have very different sizes.\n\nBalanced accuracy score: a modified version of accuracy score that takes into account the class imbalance by computing the average of the sensitivity (true positive rate) and specificity (true negative rate). It is computed as (sensitivity + specificity) / 2.\n\nF1 score: measures the trade-off between precision and recall. It is the harmonic mean of precision and recall, computed as 2 * (precision * recall) / (precision + recall). It is a good metric for imbalanced datasets, where the focus is on correctly identifying the minority class.","metadata":{}},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Disparate Impact Remover\nis a pre-processing algorithm used to mitigate the effects of sensitive attributes (such as race or gender) on the outcomes of machine learning models. The algorithm works by adjusting the distribution of the sensitive attribute in the dataset to achieve a desired level of fairness.\n\nThe Disparate Impact Remover algorithm works by creating a new dataset in which the sensitive attribute (such as race or gender) is balanced across the different values of the outcome variable. This is achieved by adjusting the probability of selecting each example in the training dataset, such that the overall proportion of the sensitive attribute is the same across all possible outcomes. This approach is based on the intuition that if the dataset is balanced with respect to the sensitive attribute, then the machine learning model will not be able to discriminate based on this attribute.","metadata":{}},{"cell_type":"code","source":"from aif360.datasets import BinaryLabelDataset\nfrom aif360.algorithms.preprocessing import DisparateImpactRemover\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.892925Z","iopub.status.idle":"2023-05-20T16:00:05.893469Z","shell.execute_reply.started":"2023-05-20T16:00:05.893194Z","shell.execute_reply":"2023-05-20T16:00:05.893222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BinaryLabelDataset(df=X_train.join(y_train_df), label_names=['income'], \n                                   protected_attribute_names=['race', 'sex'], \n                                   favorable_label=1, unfavorable_label=0)\ntest_dataset = BinaryLabelDataset(df=X_test.join(y_test_df), label_names=['income'], \n                                  protected_attribute_names=['race', 'sex'], \n                                  favorable_label=1, unfavorable_label=0)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.894937Z","iopub.status.idle":"2023-05-20T16:00:05.895413Z","shell.execute_reply.started":"2023-05-20T16:00:05.895210Z","shell.execute_reply":"2023-05-20T16:00:05.895230Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DIR = DisparateImpactRemover(repair_level=1.0, sensitive_attribute='race')\ntrain_repaired_dataset = DIR.fit_transform(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.896882Z","iopub.status.idle":"2023-05-20T16:00:05.897398Z","shell.execute_reply.started":"2023-05-20T16:00:05.897135Z","shell.execute_reply":"2023-05-20T16:00:05.897159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(train_repaired_dataset.features, train_repaired_dataset.labels.ravel())","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.900428Z","iopub.status.idle":"2023-05-20T16:00:05.901015Z","shell.execute_reply.started":"2023-05-20T16:00:05.900741Z","shell.execute_reply":"2023-05-20T16:00:05.900767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = rfc.predict(test_dataset.features)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.902098Z","iopub.status.idle":"2023-05-20T16:00:05.902474Z","shell.execute_reply.started":"2023-05-20T16:00:05.902292Z","shell.execute_reply":"2023-05-20T16:00:05.902310Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy = accuracy_score(test_dataset.labels.ravel(), y_pred)\nprecision = precision_score(test_dataset.labels.ravel(), y_pred)\nrecall = recall_score(test_dataset.labels.ravel(), y_pred)\nf1 = f1_score(test_dataset.labels.ravel(), y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 score:\", f1)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.904242Z","iopub.status.idle":"2023-05-20T16:00:05.904634Z","shell.execute_reply.started":"2023-05-20T16:00:05.904426Z","shell.execute_reply":"2023-05-20T16:00:05.904444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****","metadata":{}},{"cell_type":"markdown","source":"# Learning fair representations (LFR) \nis a technique for learning representations of data that are optimized to remove or reduce the impact of sensitive attributes such as race or gender. It is a type of pre-processing technique that can be applied to the data before it is used to train a machine learning model.\n\nThe goal of LFR is to find a representation of the data that separates the information that is relevant to the prediction task from the information that is associated with the sensitive attribute. This representation can then be used as input to a machine learning model that can make predictions without relying on the sensitive attribute.","metadata":{}},{"cell_type":"code","source":"from aif360.datasets import StandardDataset\nfrom aif360.algorithms.postprocessing import CalibratedEqOddsPostprocessing\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.905590Z","iopub.status.idle":"2023-05-20T16:00:05.905980Z","shell.execute_reply.started":"2023-05-20T16:00:05.905792Z","shell.execute_reply":"2023-05-20T16:00:05.905811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset  = StandardDataset(\n    df=X_train.join(y_train_df),\n    label_name='income',\n    favorable_classes=[1],\n    protected_attribute_names=['race', 'sex'],\n    privileged_classes=[['1'], ['1']])\ntest_dataset  = StandardDataset(\n    df=X_test.join(y_test_df),\n    label_name='income',\n    favorable_classes=[1],\n    protected_attribute_names=['race', 'sex'],\n    privileged_classes=[['1'], ['1']])\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.906949Z","iopub.status.idle":"2023-05-20T16:00:05.907318Z","shell.execute_reply.started":"2023-05-20T16:00:05.907138Z","shell.execute_reply":"2023-05-20T16:00:05.907155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfc = RandomForestClassifier()\nrfc.fit(train_dataset.features, train_dataset.labels.ravel())\ny_pred = rfc.predict(test_dataset.features)\naccuracy = accuracy_score(test_dataset.labels.ravel(), y_pred)\nprecision = precision_score(test_dataset.labels.ravel(), y_pred)\nrecall = recall_score(test_dataset.labels.ravel(), y_pred)\nf1 = f1_score(test_dataset.labels.ravel(), y_pred)\n\nprint(\"Accuracy:\", accuracy)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 score:\", f1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.908786Z","iopub.status.idle":"2023-05-20T16:00:05.909152Z","shell.execute_reply.started":"2023-05-20T16:00:05.908971Z","shell.execute_reply":"2023-05-20T16:00:05.908989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reweighing","metadata":{}},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from aif360.datasets import BinaryLabelDataset\nfrom aif360.algorithms.preprocessing import Reweighing\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Création des jeux de données d'entraînement et de test avec AIF360\ntrain_dataset = BinaryLabelDataset(df=X_train.join(y_train_df), label_names=['income'], \n                                   protected_attribute_names=['race', 'sex'], \n                                   favorable_label=1, unfavorable_label=0)\n\ntest_dataset = BinaryLabelDataset(df=X_test.join(y_test_df), label_names=['income'], \n                                  protected_attribute_names=['race', 'sex'], \n                                  favorable_label=1, unfavorable_label=0)\n\n# Définition des groupes privilégiés et non privilégiés\nprivileged_groups = [{'race': 1}]  # Remplacez par vos propres valeurs\nunprivileged_groups = [{'race': 0}]  # Remplacez par vos propres valeurs\n\n# Application de la méthode de reweighing\nrw = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\ntrain_dataset_reweighed = rw.fit_transform(train_dataset)\n\n# Entraînement d'un modèle de RandomForestClassifier sur les données reweighed\nrfc = RandomForestClassifier()\nrfc.fit(train_dataset_reweighed.features, train_dataset_reweighed.labels.ravel())\n\n# Prédictions sur l'ensemble de test\nX_test_reweighed = rw.transform(test_dataset)\ny_pred = rfc.predict(X_test_reweighed.features)\n\n# Calcul des mesures de performance\naccuracy = accuracy_score(test_dataset.labels.ravel(), y_pred)\nprecision = precision_score(test_dataset.labels.ravel(), y_pred)\nrecall = recall_score(test_dataset.labels.ravel(), y_pred)\nf1 = f1_score(test_dataset.labels.ravel(), y_pred)\n\nprint(\"Exactitude:\", accuracy)\nprint(\"Précision:\", precision)\nprint(\"Rappel:\", recall)\nprint(\"Score F1:\", f1)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.911395Z","iopub.status.idle":"2023-05-20T16:00:05.911795Z","shell.execute_reply.started":"2023-05-20T16:00:05.911607Z","shell.execute_reply":"2023-05-20T16:00:05.911625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset_reweighed","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.912831Z","iopub.status.idle":"2023-05-20T16:00:05.913194Z","shell.execute_reply.started":"2023-05-20T16:00:05.913016Z","shell.execute_reply":"2023-05-20T16:00:05.913033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def re(X_train,y_train_df ,X_test,y_test_df):\n    train_dataset = BinaryLabelDataset(df=X_train.join(y_train_df), label_names=['income'], \n                                   protected_attribute_names=['race', 'sex'], \n                                   favorable_label=1, unfavorable_label=0)\n\n    test_dataset = BinaryLabelDataset(df=X_test.join(y_test_df), label_names=['income'], \n                                  protected_attribute_names=['race', 'sex'], \n                                  favorable_label=1, unfavorable_label=0)\n    privileged_groups = [{'race': 1}]  # Remplacez par vos propres valeurs\n    unprivileged_groups = [{'race': 0}]  # Remplacez par vos propres valeurs\n\n    # Application de la méthode de reweighing\n    rw = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n    train_dataset_reweighed = rw.fit_transform(train_dataset)\n    X_test_reweighed = rw.transform(test_dataset)\n    return train_dataset_reweighed X_test_reweighed\n","metadata":{"execution":{"iopub.status.busy":"2023-05-20T16:00:05.914337Z","iopub.status.idle":"2023-05-20T16:00:05.914721Z","shell.execute_reply.started":"2023-05-20T16:00:05.914525Z","shell.execute_reply":"2023-05-20T16:00:05.914555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}